<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta charset="utf-8">

  
  <title>Gradient Descent based Optimization Algorithms for Deep Learning Models Training</title>
  
  <link rel="canonical" href="https://stephen-cheng.github.io/2024/10/18/Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training/">
  
  <meta name="description" content="Stephen Cheng &amp;nbsp;  IntroGradient descent is an optimisation method for finding the minimum of a function. It is commonly used in deep learning mode">
  
  
  <meta name="keywords" content="AI, Tech, CS">
  
  <meta name="author" content="Stephen">
  
  
  
  <meta property="og:site_name" content="Stephen&#39;s Blog" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Gradient Descent based Optimization Algorithms for Deep Learning Models Training" />
  
  <meta property="og:description" content="Stephen Cheng &amp;nbsp;  IntroGradient descent is an optimisation method for finding the minimum of a function. It is commonly used in deep learning mode">
  
  <meta property="og:url" content="https://stephen-cheng.github.io/2024/10/18/Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Gradient Descent based Optimization Algorithms for Deep Learning Models Training">
  
  <meta name="twitter:description" content="Stephen Cheng &amp;nbsp;  IntroGradient descent is an optimisation method for finding the minimum of a function. It is commonly used in deep learning mode">
  
  
  
  
  <meta name="twitter:url" content="https://stephen-cheng.github.io/2024/10/18/Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training/" />

  <!-- Mobile Specific Metas
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">ğŸŒ‘</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>â˜€ï¸</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Stephen&#39;s Blog
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/archives" class="ml">Archives</a>
          
        
          
          <a href="/about" class="ml">About</a>
          
        
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Gradient Descent based Optimization Algorithms for Deep Learning Models Training</h2>

  <center>Stephen Cheng</center>
<p>&nbsp;</p>

<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Gradient descent is an optimisation method for finding the minimum of a function. It is commonly used in deep learning models to update the weights of the neural network through backpropagation. Understanding different optimization algorithms and their strengths and weaknesses is crucial for any data scientist training deep learning models. Selecting the right optimizer for the task at hand is paramount to achieving the best possible training results in the shortest amount of time. Next, weâ€™ll explore the most commonly used deep learning optimization algorithms, including Gradient Descent, Stochastic Gradient Descent, and the Adam optimizer. By the end of this article, youâ€™ll have a clear idea of how to choose the best algorithm for training your models.</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_1.jpg" alt=""></p>
<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>Gradient Descent is an algorithm designed to minimize a function by iteratively moving towards the minimum value of the function. Itâ€™s akin to a hiker trying to find the lowest point in a valley shrouded in fog. The hiker starts at a random location and can only feel the slope of the ground beneath their feet. To reach the valleyâ€™s lowest point, the hiker takes steps in the direction of the steepest descent. All deep learning model optimization algorithms widely used today are based on Gradient Descent. </p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_2.jpg" alt=""></p>
<h4 id="How-it-Works"><a href="#How-it-Works" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with random values for the modelâ€™s weights.</li>
<li>Gradient computation: Calculate the gradient of the cost function with respect to each parameter. The gradient is a vector that points in the direction of the steepest increase of the function. In the context of optimization, weâ€™re interested in the negative gradient, which points towards the direction of the steepest decrease.</li>
<li>Update parameters: Adjust the modelâ€™s parameters in the direction opposite to the gradient. This step is done by subtracting a fraction of the gradient from the current values of the parameters. The size of this step is determined by the learning rate, a hyperparameter that controls how fast or slow we move toward the optimal weights.</li>
</ul>
<h4 id="Mathematical-Representation"><a href="#Mathematical-Representation" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The update rule for each parameter ğ’˜ can be mathematically represented as:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_3.jpg" alt=""></p>
<p>where <em>w</em> represents the modelâ€™s parameters (weights) and <em>ğ›¼</em> is the learning rate. <em>Î”ğ‘¤ğ½(w)</em> is the gradient of the cost function <em>ğ½(w)</em> with respect to w.</p>
<p>The learning rate is a crucial hyperparameter that needs to be chosen carefully. If itâ€™s too small, the algorithm will converge very slowly. If itâ€™s too large, the algorithm might overshoot the minimum and fail to converge.</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_4.jpg" alt=""></p>
<h2 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h2><p>Stochastic Gradient Descent (SGD) is a variant of the traditional Gradient Descent optimization algorithm that introduces randomness into the optimization process to improve convergence speed and potentially escape local minima. To understand the intuition behind SGD, we can again invoke the analogy of a hiker descending a foggy valley. If Gradient Descent represents a cautious hiker who carefully evaluates the slope around them before taking a step, Stochastic Gradient Descent is akin to a more impulsive hiker who decides their next step based only on the slope of the ground immediately beneath their feet. This approach can lead to a quicker descent but might involve more meandering.</p>
<h4 id="How-it-Works-1"><a href="#How-it-Works-1" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with a random set of parameters for the model.</li>
<li>Gradient computation: Instead of calculating the gradient of the cost function over the entire training data, SGD computes the gradient based on a single randomly selected training example.</li>
<li>Update parameters: Update the modelâ€™s parameters using this computed gradient. The parameters are adjusted in the direction opposite to the gradient, similar to basic Gradient Descent.</li>
</ul>
<h4 id="Mathematical-Representation-1"><a href="#Mathematical-Representation-1" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule in SGD is similar to that of Gradient Descent but applies to a single example <em>i</em>:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_5.jpg" alt=""></p>
<p>Here, <em>w</em> represents the modelâ€™s parameters (weights), <em>ğ›¼</em> is the learning rate, and <em>âˆ†ğ˜¸ğ˜‘ğ˜ª(ğ˜¸)</em> is the gradient of the cost function <em>ğ½i(w)</em> for the <em>ith</em> training example with respect to <em>w</em>.</p>
<h2 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h2><p>Mini-batch Gradient Descent strikes a balance between the thorough, calculated approach of Gradient Descent and the unpredictable, swift nature of Stochastic Gradient Descent (SGD). Imagine a group of hikers navigating through a foggy valley. Each hiker independently assesses a small, distinct section of the surrounding area before the group decides on the best direction to take. Based on a broader but still limited view of the terrain, this collective decision-making process allows for a more informed and steady progression toward the valleyâ€™s lowest point compared to an individual hikerâ€™s erratic journey.</p>
<h4 id="How-it-Works-2"><a href="#How-it-Works-2" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with initial random values for the modelâ€™s parameters.</li>
<li>Gradient computation: Instead of calculating the gradient using the entire dataset (as in Gradient Descent) or a single example (as in SGD), Mini-batch Gradient Descent computes the gradient using a small subset of the training data, known as a mini-batch.</li>
<li>Update parameters: Adjust the parameters in the direction opposite to the computed gradient. This adjustment is made based on the gradient derived from the mini-batch, aiming to reduce the cost function.</li>
</ul>
<h4 id="Mathematical-Representation-2"><a href="#Mathematical-Representation-2" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule for Mini-batch Gradient Descent can be represented as:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_6.jpg" alt=""></p>
<p>where <em>ğ‘¤</em> represents the modelâ€™s parameters (weights), <em>ğ›¼</em> is the learning rate, and <em>âˆ†ğ˜¸ğ˜‘ğ˜ª(ğ˜¸)</em> is the gradient of the cost function <em>ğ˜‘ğ˜®ğ˜ªğ˜¯ğ˜ª-ğ˜£ğ˜¢ğ˜µğ˜¤ğ˜©(ğ˜¸)</em> for the current <em>mini-batch</em> of training samples with respect to <em>w</em>.</p>
<h2 id="AdaGrad-Adaptive-Gradient-Algorithm"><a href="#AdaGrad-Adaptive-Gradient-Algorithm" class="headerlink" title="AdaGrad (Adaptive Gradient Algorithm)"></a>AdaGrad (Adaptive Gradient Algorithm)</h2><p>AdaGrad (Adaptive Gradient Algorithm) introduces an innovative twist to the conventional Gradient Descent optimization technique by dynamically adapting the learning rate, allowing for a more nuanced and effective optimization process. Imagine a scenario where our group of hikers, navigating the foggy valley, now has access to a map highlighting areas of varying difficulty. With this map, they can adjust their pace â€” taking smaller steps in steep, difficult terrain and larger strides in flatter regions â€” to optimize their path toward the valleyâ€™s bottom.</p>
<h4 id="How-it-Works-3"><a href="#How-it-Works-3" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Begin with random values for the modelâ€™s parameters and initialize a gradient accumulation variable, typically a vector of zeros, of the same size as the parameters.</li>
<li>Gradient computation: Square and accumulate the gradients in the gradient accumulation variable, which consequently tracks the sum of squares of the gradients for each parameter.</li>
<li>Adjust learning rate: Modify the learning rate for each parameter inversely proportional to the square root of its accumulated gradient, ensuring parameters with smaller gradients to have larger updates.</li>
<li>Update parameters: Update each parameter using its adjusted learning rate and the computed gradient.</li>
</ul>
<h4 id="Mathematical-Representation-3"><a href="#Mathematical-Representation-3" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule for AdaGrad can be represented as:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_7.jpg" alt=""></p>
<p>Where <em>w</em> represents the modelâ€™s parameters (weights), <em>ğ›¼</em> is the initial learning rate, <em>ğ˜</em> is the accumulation of the squared gradients, <em>âˆˆ</em> is a small smoothing term to prevent division by zero, and <em>âˆ†ğ˜¸ğ˜‘(ğ˜¸)</em> is the gradient of the cost function <em>ğ½(w)</em> for the training samples with respect to <em>w</em>.</p>
<h2 id="RMSprop-Root-Mean-Square-Propagation"><a href="#RMSprop-Root-Mean-Square-Propagation" class="headerlink" title="RMSprop (Root Mean Square Propagation)"></a>RMSprop (Root Mean Square Propagation)</h2><p>RMSprop (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm designed to address AdaGradâ€™s diminishing learning rates issue. Continuing with the analogy of hikers navigating a foggy valley, RMSprop equips our hikers with an adaptive tool that allows them to maintain a consistent pace despite the terrainâ€™s complexity. This tool evaluates the recent terrain and adjusts their steps accordingly, ensuring they neither get stuck in difficult areas due to excessively small steps nor overshoot their target with overly large steps. RMSprop achieves this by modulating the learning rate based on a moving average of the squared gradients. </p>
<h4 id="How-it-Works-4"><a href="#How-it-Works-4" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with random initial values for the modelâ€™s parameters and initialize a running average of squared gradients, typically as a vector of zeros of the same size as the parameters.</li>
<li>Compute gradient: Calculate the gradient of the cost function with respect to each parameter using a selected subset of the training data (mini-batch).</li>
<li>Update squared gradient average: Update the running average of squared gradients using a decay factor, <em>Î³</em>, often set to 0.9. This moving average emphasizes more recent gradients, preventing the learning rate from diminishing too rapidly.</li>
<li>Adjust learning rate: Scale down the gradient by the square root of the updated running average, normalizing the updates and allowing for a consistent pace of learning across parameters.</li>
<li>Update parameters: Apply the adjusted gradients to update the modelâ€™s parameters.</li>
</ul>
<h4 id="Mathematical-Representation-4"><a href="#Mathematical-Representation-4" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule for RMSprop can be represented as follows:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_8.jpg" alt=""></p>
<p>Here, <em>ğ˜¸</em> represents the parameters, <em>Î±</em> is the initial learning rate, <em>ğ˜Œ[ğ˜¨Â²]â‚œ</em> is the running average of squared gradients at a certain time, <em>âˆˆ</em> is a small smoothing term to prevent division by zero, and <em>âˆ†ğ˜¸ğ˜‘(ğ˜¸)</em> is the gradient of the cost function <em>ğ˜‘(ğ˜¸)</em> with respect to <em>ğ˜¸</em>.</p>
<h2 id="AdaDelta"><a href="#AdaDelta" class="headerlink" title="AdaDelta"></a>AdaDelta</h2><p>AdaDelta is an extension of AdaGrad that seeks to reduce its aggressively decreasing learning rate. Imagine our group of hikers now has an advanced tool that not only adapts to recent terrain changes but also ensures their gear weight doesnâ€™t hinder their progress. This tool dynamically adjusts their stride length, ensuring they can maintain a steady pace without the burden of past terrain slowing them down. Similarly, AdaDelta modifies the learning rate based on a window of recent gradients rather than accumulating all past squared gradients. This approach allows for a more robust and adaptive learning rate adjustment over time.</p>
<h4 id="How-it-Works-5"><a href="#How-it-Works-5" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with random initial parameters and two state variables, one for accumulating gradients and another for accumulating parameter updates, both initially set to zero.</li>
<li>Compute gradient: Determine the gradient of the cost function with respect to each parameter using a subset of the training data (mini-batch).</li>
<li>Accumulate gradients: Update the first state variable with the squared gradients, applying a decay factor to maintain a focus on recent gradients.</li>
<li>Compute update: Determine the parameter updates based on the square root of the accumulated updates state variable divided by the square root of the accumulated gradients state variable, adding a small constant to avoid division by zero.</li>
<li>Accumulate updates: Update the second state variable with the squared parameter updates.</li>
<li>Update parameters: Modify the modelâ€™s parameters using the computed updates.</li>
</ul>
<h4 id="Mathematical-Representation-5"><a href="#Mathematical-Representation-5" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule for AdaDelta is more complex due to its iterative nature but can be generalized as:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_9.jpg" alt=""></p>
<p>Where <em>ğ˜¸</em> represents the parameters, <em>ğ˜™ğ˜”ğ˜š[ğ˜¶]â‚œâ‚‹â‚</em> is the root mean square of parameter updates up to the previous time step, <em>ğ˜™ğ˜”ğ˜š[ğ˜¨]â‚œ</em> is the root mean square of gradients at the current time step, and <em>âˆ†ğ˜¸ğ˜‘(ğ˜¸)</em> is the gradient of the cost function <em>ğ˜‘(ğ˜¸)</em> with respect to <em>ğ˜¸</em>.</p>
<h2 id="Adam-Adaptive-Moment-Estimation"><a href="#Adam-Adaptive-Moment-Estimation" class="headerlink" title="Adam (Adaptive Moment Estimation)"></a>Adam (Adaptive Moment Estimation)</h2><p>Adam (Adaptive Moment Estimation) combines the best properties of AdaGrad and RMSprop to provide an optimization algorithm that can handle sparse gradients on noisy problems. Using our hiking analogy, imagine that the hikers now have access to a state-of-the-art navigation tool that not only adapts to the terrainâ€™s difficulty but also keeps track of their direction to ensure smooth progress. This tool adjusts their pace based on both the recent and accumulated gradients, ensuring they efficiently navigate towards the valleyâ€™s bottom without veering off course. Adam achieves this by maintaining estimates of the first and second moments of the gradients, thus providing an adaptive learning rate mechanism.</p>
<h4 id="How-it-Works-6"><a href="#How-it-Works-6" class="headerlink" title="How it Works"></a>How it Works</h4><ul>
<li>Initialization: Start with random initial parameter values and initialize a first moment vector (m) and a second moment vector (v). Each â€œmoment vectorâ€ stores aggregated information about the gradients of the cost function with respect to the modelâ€™s parameters. The first moment vector accumulates the means (or the first moments) of the gradients, acting like a momentum by averaging past gradients to determine the direction to update the parameters. The second moment vector accumulates the variances (or second moments) of the gradients, helping adjust the size of the updates by considering the variability of past gradients.</li>
<li>Compute gradient: For each mini-batch, compute the gradients of the cost function with respect to the parameters.</li>
<li>Update moments: Update the first moment vector (m) with the bias-corrected moving average of the gradients. Similarly, update the second moment vector (v) with the bias-corrected moving average of the squared gradients.</li>
<li>Adjust learning rate: Calculate the adaptive learning rate for each parameter using the updated first and second moment vectors, ensuring effective parameter updates.</li>
<li>Update parameters: Use the adaptive learning rates to update the modelâ€™s parameters.</li>
</ul>
<h4 id="Mathematical-Representation-6"><a href="#Mathematical-Representation-6" class="headerlink" title="Mathematical Representation"></a>Mathematical Representation</h4><p>The parameter update rule for Adam can be expressed as:</p>
<p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_10.jpg" alt=""></p>
<p>Where <em>ğ˜¸</em> represents the parameters, <em>Î±</em> is the learning rate, and <em>ğ˜®â‚œ</em> and <em>ğ˜·â‚œ</em> are bias-corrected estimates of first and second moments of the gradients, respectively.</p>
<h2 id="Cheat-Sheet-of-Mathematical-Representation-of-Optimizers"><a href="#Cheat-Sheet-of-Mathematical-Representation-of-Optimizers" class="headerlink" title="Cheat Sheet of Mathematical Representation of Optimizers"></a>Cheat Sheet of Mathematical Representation of Optimizers</h2><p><img src="https://raw.githubusercontent.com/stephen-cheng/images/refs/heads/master/blog/2024/1018_11.jpg" alt=""></p>
<h2 id="Comparisons-between-Different-Optimization-Algorithms"><a href="#Comparisons-between-Different-Optimization-Algorithms" class="headerlink" title="Comparisons between Different Optimization Algorithms"></a>Comparisons between Different Optimization Algorithms</h2><table>
<thead>
<tr>
<th>Algorithm</th>
<th>Pros</th>
<th>Cons</th>
<th>When to use</th>
</tr>
</thead>
<tbody><tr>
<td>Gradient Descent</td>
<td>Simple and easy to implement</td>
<td>Computationally expensive on large datasets; May get stuck in local minima</td>
<td>Small datasets; When simplicity and clarity are preferred</td>
</tr>
<tr>
<td>SGD</td>
<td>Fast; Handles large datasets well</td>
<td>High variance in updates can lead to instability</td>
<td>Large datasets; Online or incremental learning scenarios</td>
</tr>
<tr>
<td>Mini-batch Gradient Descent</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mini-batch Gradient Descent</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mini-batch Gradient Descent</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mini-batch Gradient Descent</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mini-batch Gradient Descent</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>

  <p><a class="classtest-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a>, <a class="classtest-link" href="/tags/Gradient-Descent/" rel="tag">Gradient Descent</a>, <a class="classtest-link" href="/tags/Optimization-Algorithms/" rel="tag">Optimization Algorithms</a> â€” Oct 18, 2024</p>
  


        </div>
        <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div>
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with â¤ï¸ and â˜€ï¸
        <!-- <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io"> -->
        <!-- <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg> -->
        <!-- </a> -->
        
        on <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/stephen-cheng" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://linkedin.com/in/stephen-cheng" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
        <a class="ml-0 footer-link icon" href="https://facebook.com/stephen.cheeng" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Facebook">
          <svg class="facebook svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M8.258 4.458c0-0.144 0.02-0.455 0.06-0.931c0.043-0.477 0.223-0.976 0.546-1.5c0.32-0.522 0.839-0.991 1.561-1.406 C11.144 0.208 12.183 0 13.539 0h3.82v4.163h-2.797c-0.277 0-0.535 0.104-0.768 0.309c-0.231 0.205-0.35 0.4-0.35 0.581v2.59h3.914 c-0.041 0.507-0.086 1-0.138 1.476l-0.155 1.258c-0.062 0.425-0.125 0.819-0.187 1.182h-3.462v11.542H8.258V11.558H5.742V7.643 h2.516V4.458z"/></svg>
        </a>
      

      
      <a class="ml-0 footer-link icon" href="https://instagram.com/stephen.cheeng" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

      

    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>