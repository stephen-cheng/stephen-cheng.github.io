<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Stephen Cheng</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:type" content="website">
<meta property="og:title" content="Stephen Cheng">
<meta property="og:url" content="https://stephen-cheng.github.io/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Stephen Cheng">
<meta property="article:tag" content="AI">
<meta property="article:tag" content=" Tech">
<meta property="article:tag" content=" CS">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Stephen Cheng" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Stephen Cheng</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">AI | Tech</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
          <a class="main-nav-link" href="/">Home</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://stephen-cheng.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-table-detection-with-detectron2-n-maskrcnn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/22/table-detection-with-detectron2-n-maskrcnn/" class="article-date">
  <time datetime="2020-11-22T17:13:38.000Z" itemprop="datePublished">2020-11-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer-Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/22/table-detection-with-detectron2-n-maskrcnn/">Table Detection with Detectron2 &amp; Mask R-CNN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202011/20201122/0.png" alt=""></p>
<p><a href="https://github.com/facebookresearch/detectron2" target="_blank" rel="noopener">Detectron2</a> is Facebook AI Research’s new software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, <a href="https://github.com/facebookresearch/Detectron/" target="_blank" rel="noopener">Detectron</a>, and it originates from <a href="https://github.com/facebookresearch/maskrcnn-benchmark/" target="_blank" rel="noopener">Mask R-CNN</a>.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202011/20201122/1.gif" alt=""></p>
<p>Table detection is a crucial step in many document analysis applications as tables are used for presenting essential information to the reader in a structured manner. It is a hard problem due to varying layouts and encodings of the tables. Researchers have proposed numerous techniques for table detection based on layout analysis of documents. Most of these techniques fail to generalize because they rely on hand engineered features which are not robust to layout variations. In this post, we propose a detectron2 based method for table detection.</p>
<h3 id="Why-use-detectron2"><a href="#Why-use-detectron2" class="headerlink" title="Why use detectron2?"></a>Why use detectron2?</h3><ul>
<li>It is powered by the PyTorch deep learning framework.</li>
<li>It Include more features such as panoptic segmentation, Densepose, Cascade R-CNN, rotated bounding boxes, PointRend, DeepLab, etc.</li>
<li>It can be used as a library to support different projects on top of it.</li>
<li>It trains very faster.</li>
<li>The Models can be exported to torchscript format or caffe2 format for deployment.</li>
</ul>
<h3 id="How-to-implement"><a href="#How-to-implement" class="headerlink" title="How to implement?"></a>How to implement?</h3><p>The implemented <a href="https://github.com/steven-cheng-com/table_detection_with_detectron2_n_mask_rcnn" target="_blank" rel="noopener">CODE</a> contains THREE parts:</p>
<ol>
<li>Create custom COCO dataset</li>
</ol>
<p>You can run the <code>voc2coco.py</code> script to generate a COCO data formatted JSON file.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python voc2coco.py ./dataset/annotations ./dataset/coco/output.json</span><br></pre></td></tr></table></figure>

<p>Then you can run the following Jupyter notebook to visualize the coco annotations.</p>
<p><code>COCO_Image_Viewer.ipynb</code></p>
<ol start="2">
<li>Training</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python table_detect_train.py</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Evaluation</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python table_detect_test.py</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/11/22/table-detection-with-detectron2-n-maskrcnn/" data-id="clpllv7wm001wt4xv10h11t9j" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Object-Detection/" rel="tag">Object-Detection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Table-Detection/" rel="tag">Table-Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/" class="article-date">
  <time datetime="2020-10-19T06:19:41.000Z" itemprop="datePublished">2020-10-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/">Grammatical-Error-Correction Sequence Tagging System with an Pretrained BERT-like Transformer Encoder</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202010/20201019/0.png" alt=""></p>
<p>Here a simple and efficient GEC (Grammatical Error Correction) sequence tagger using a Transformer encoder is introduced. It is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. In addition, a custom token-level transformation to map input tokens to target corrections is designed. The original paper can be found <a href="https://arxiv.org/pdf/2005.12592.pdf" target="_blank" rel="noopener">here</a>.</p>
<p>Thus the GEC sequence tagging system here consists of three training stages: pretraining on synthetic data, fine-tuning on an errorful parallel corpus, and finally, fine-tuning on a combination of errorful and error-free parallel corpora.</p>
<p>The GEC sequence tagging system incorporates a pre-trained Transformer encoder, those encoders from XLNet and RoBERTa<br>outperform three other cutting-edge Transformer encoders (ALBERT, BERT, and GPT-2).</p>
<h3 id="Use-Case"><a href="#Use-Case" class="headerlink" title="Use Case"></a>Use Case</h3><p>The original code of the GEC sequence tagging model is <a href="https://github.com/steven-cheng-com/grammar_correction_with_bert" target="_blank" rel="noopener">here</a>, more details of running code are also included.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/" data-id="clpllv7v40006t4xv4a6q7cwu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Grammatical-Error-Correction/" rel="tag">Grammatical-Error-Correction</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformers/" rel="tag">Transformers</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spelling-correction-with-soft-masked-bert" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/06/spelling-correction-with-soft-masked-bert/" class="article-date">
  <time datetime="2020-09-06T16:47:42.000Z" itemprop="datePublished">2020-09-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/06/spelling-correction-with-soft-masked-bert/">Spelling Correction with Soft-Masked BERT</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202009/20200906/0.jpg" alt=""></p>
<p>Sotf-Masked BERT is a novel neural architecture to address the aforementioned issue, which consists of a network for error detection and a network for error correction based on BERT, with the former being connected to the latter with what we call soft-masking technique. The method uses ‘Soft-Masked BERT’ is general, and it may be employed in other language detection-correction problems not just focusing on CSC (Chinese Spelling error Correction) domain as it’s proposed in the original <a href="https://arxiv.org/pdf/2005.07421.pdf" target="_blank" rel="noopener">paper</a>.</p>
<h3 id="The-Architecture-of-Soft-Masked-BERT"><a href="#The-Architecture-of-Soft-Masked-BERT" class="headerlink" title="The Architecture of Soft-Masked BERT"></a>The Architecture of Soft-Masked BERT</h3><p>Soft-Masked BERT is composed of a detection network based on Bi-GRU and a correction network based on BERT. The detection network predicts the probabilities of errors and the correction network predicts the probabilities of error corrections, while the former passes its prediction results to the latter using soft masking.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202009/20200906/1.png" alt=""></p>
<p> The Model first creates an embedding for each character in the input sentence, referred to as input embedding. Next, it takes the sequence of embeddings as input and outputs the probabilities of errors for the sequence of characters (embeddings) using the detection network. After that it calculates the weighted sum of the input embeddings and [MASK] embeddings weighted by the error probabilities. The calculated embeddings mask the likely errors in the sequence in a soft way. Then it takes the sequence of soft-masked embeddings as input and outputs the probabilities of error corrections using the correction network, which is a BERT model whose final layer consists of a softmax function for all characters. There is also a residual connection between the input embeddings and the embeddings at the final layer.</p>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><p>Different with the original Sort-Masked BERT paper running models on Chinese dataset, here we modify a bit of code and use it in the English dataset.</p>
<ul>
<li>Dataset</li>
</ul>
<p>The data that we will use for this project will be 20 popular books from <a href="http://www.gutenberg.org/ebooks/search/?sort_order=downloads" target="_blank" rel="noopener">Project Gutenberg</a>.</p>
<ul>
<li>Prerequired packages</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>Parameters</li>
</ul>
<p>The length of each sentence is between 4 and 200. So,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">max_len = 32</span><br><span class="line">min_len = 2</span><br></pre></td></tr></table></figure>

<ul>
<li>code</li>
</ul>
<p>You can find the code on <a href="https://github.com/steven-cheng-com/Spelling_Correction_with_Soft-Masked_BERT" target="_blank" rel="noopener">Github</a></p>
<h3 id="How-to-run"><a href="#How-to-run" class="headerlink" title="How to run?"></a>How to run?</h3><ul>
<li>Prepare Data:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python data_prepare.py</span><br></pre></td></tr></table></figure>

<ul>
<li>Process Data:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python data_process.py</span><br></pre></td></tr></table></figure>

<ul>
<li>Train Models:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<ul>
<li>Test Models:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python test.py</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/09/06/spelling-correction-with-soft-masked-bert/" data-id="clpllv7wm001tt4xv0y99cclk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spelling-correction-with-python-spellchecker" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/16/spelling-correction-with-python-spellchecker/" class="article-date">
  <time datetime="2020-08-16T18:52:42.000Z" itemprop="datePublished">2020-08-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/16/spelling-correction-with-python-spellchecker/">Spelling Correction with Python Spellchecker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202008/20200816/0.jpg" alt=""></p>
<p>Spelling checking or spelling correction is a basic requirement in any text processing or analysis. The python package <code>pyspellchecker</code> provides us this feature to find the words that may have been mis-spelled and also suggest the possible corrections. <code>pyspellchecker</code> supports multiple languages including English, Spanish, German, French, and Portuguese. And it supports Python 3 and Python 2.7. <code>pyspellchecker</code> allows for the setting of the Levenshtein Distance to check. For longer words, it is highly recommended to use a distance of 1 and not the default 2.</p>
<h3 id="How-to-install"><a href="#How-to-install" class="headerlink" title="How to install?"></a>How to install?</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyspellchecker</span><br></pre></td></tr></table></figure>

<h3 id="How-to-use"><a href="#How-to-use" class="headerlink" title="How to use?"></a>How to use?</h3><ul>
<li>With the default Word Frequency list</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spellchecker <span class="keyword">import</span> SpellChecker</span><br><span class="line"></span><br><span class="line">spell = SpellChecker()</span><br><span class="line"></span><br><span class="line"><span class="comment"># find those words that may be misspelled</span></span><br><span class="line">misspelled = spell.unknown([<span class="string">'let'</span>, <span class="string">'us'</span>, <span class="string">'wlak'</span>,<span class="string">'on'</span>,<span class="string">'the'</span>,<span class="string">'groun'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> misspelled:</span><br><span class="line">    <span class="comment"># Get the one `most likely` answer</span></span><br><span class="line">    print(spell.correction(word))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get a list of `likely` options</span></span><br><span class="line">    print(spell.candidates(word))</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">group</span><br><span class="line">&#123;'group', 'ground', 'groan', 'grout', 'grown', 'groin'&#125;</span><br><span class="line">walk</span><br><span class="line">&#123;'flak', 'weak', 'walk'&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>With the customized Word Frequency list</li>
</ul>
<p>You can add additional text to generate a more appropriate list for your use case.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spellchecker <span class="keyword">import</span> SpellChecker</span><br><span class="line"></span><br><span class="line">spell = SpellChecker()  <span class="comment"># loads default word frequency list</span></span><br><span class="line">spell.word_frequency.load_text_file(<span class="string">'./word_frequency.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if you just want to make sure some words are not flagged as misspelled</span></span><br><span class="line">spell.word_frequency.load_words([<span class="string">'microsoft'</span>, <span class="string">'apple'</span>, <span class="string">'google'</span>])</span><br><span class="line">spell.known([<span class="string">'microsoft'</span>, <span class="string">'google'</span>])  <span class="comment"># will return both now!</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Set the distance parameter</li>
</ul>
<p>If the words that you wish to check are long, it is recommended to reduce the distance to 1. This can be accomplished either when initializing the spell check class or after the fact.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spellchecker <span class="keyword">import</span> SpellChecker</span><br><span class="line"></span><br><span class="line">spell = SpellChecker(distance=<span class="number">1</span>)  <span class="comment"># set at initialization</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># do some work on longer words</span></span><br><span class="line"></span><br><span class="line">spell.distance = <span class="number">2</span>  <span class="comment"># set the distance parameter back to the default</span></span><br></pre></td></tr></table></figure>

<h3 id="Additional-Methods"><a href="#Additional-Methods" class="headerlink" title="Additional Methods"></a>Additional Methods</h3><p><code>candidates(word)</code>: Returns a set of possible candidates for the misspelled word</p>
<p><code>word_probability(word)</code>: The frequency of the given word out of all words in the frequency list</p>
<p><code>correction(word)</code>: Returns the most probable result for the misspelled word</p>
<p><code>known([words])</code>: Returns those words that are in the word frequency list</p>
<p><code>unknown([words])</code>: Returns those words that are not in the frequency list</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/08/16/spelling-correction-with-python-spellchecker/" data-id="clpllv7wh001kt4xvd0s24dts" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spelling-correction-with-pretrained-bert" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/18/spelling-correction-with-pretrained-bert/" class="article-date">
  <time datetime="2020-07-18T14:47:52.000Z" itemprop="datePublished">2020-07-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/07/18/spelling-correction-with-pretrained-bert/">Spelling Correction with The Pretrained BERT Model</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png" alt=""></p>
<p>BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering, Natural Language Inference, and others. BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models.</p>
<p>BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).</p>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><ul>
<li>Import necessary libraris</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pytesseract <span class="keyword">import</span> image_to_string</span><br><span class="line"><span class="keyword">from</span> enchant.checker <span class="keyword">import</span> SpellChecker</span><br><span class="line"><span class="keyword">from</span> difflib <span class="keyword">import</span> SequenceMatcher</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForMaskedLM</span><br></pre></td></tr></table></figure>

<ul>
<li>Process images by using OCR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">imagename = <span class="string">'1.png'</span></span><br><span class="line">pil_img = Image.open(imagename)</span><br><span class="line">text = image_to_string(pil_img)</span><br><span class="line">text_original = str(text)</span><br><span class="line"></span><br><span class="line">print(text)</span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.imshow(np.asarray(pil_img))</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/1.png" alt=""></p>
<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as con@gmer spending</span><br><span class="line">Strengthened, manufacturing activity cont@™ed to rise, and producers</span><br><span class="line">scheduled more investment in plant and equipment.</span><br></pre></td></tr></table></figure>

<ul>
<li>Process text and mask incorrect words</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># text cleanup</span></span><br><span class="line">rep = &#123;<span class="string">'\n'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\\'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\"'</span>: <span class="string">'"'</span>,</span><br><span class="line">       <span class="string">'-'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'"'</span>: <span class="string">' " '</span>,</span><br><span class="line">       <span class="string">','</span>:<span class="string">' , '</span>,</span><br><span class="line">       <span class="string">'.'</span>:<span class="string">' . '</span>,</span><br><span class="line">       <span class="string">'!'</span>:<span class="string">' ! '</span>,</span><br><span class="line">       <span class="string">'?'</span>:<span class="string">' ? '</span>,</span><br><span class="line">       <span class="string">"n't"</span>: <span class="string">" not"</span>,</span><br><span class="line">       <span class="string">"'ll"</span>: <span class="string">" will"</span>,</span><br><span class="line">       <span class="string">'*'</span>:<span class="string">' * '</span>,</span><br><span class="line">       <span class="string">'('</span>: <span class="string">' ( '</span>,</span><br><span class="line">       <span class="string">')'</span>: <span class="string">' ) '</span>,</span><br><span class="line">       <span class="string">"s'"</span>: <span class="string">"s '"</span>&#125;</span><br><span class="line"></span><br><span class="line">rep = dict((re.escape(k), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> rep.items())</span><br><span class="line">pattern = re.compile(<span class="string">"|"</span>.join(rep.keys()))</span><br><span class="line">text = pattern.sub(<span class="keyword">lambda</span> m: rep[re.escape(m.group(<span class="number">0</span>))], text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_personslist</span><span class="params">(text)</span>:</span></span><br><span class="line">    personslist = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> nltk.sent_tokenize(text):</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):</span><br><span class="line">            <span class="keyword">if</span> isinstance(chunk, nltk.tree.Tree) <span class="keyword">and</span> chunk.label() == <span class="string">'PERSON'</span>:</span><br><span class="line">                personslist.insert(<span class="number">0</span>, (chunk.leaves()[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> list(set(personslist))</span><br><span class="line">personslist = get_personslist(text)</span><br><span class="line">ignorewords = personslist + [<span class="string">"!"</span>, <span class="string">","</span>, <span class="string">"."</span>, <span class="string">"\""</span>, <span class="string">"?"</span>, <span class="string">'('</span>, <span class="string">')'</span>, <span class="string">'*'</span>, <span class="string">"''"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to find incorrect words</span></span><br><span class="line">d = SpellChecker(<span class="string">"en_US"</span>)</span><br><span class="line">words = text.split()</span><br><span class="line">incorrectwords = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> <span class="keyword">not</span> d.check(w) <span class="keyword">and</span> w <span class="keyword">not</span> <span class="keyword">in</span> ignorewords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to get suggested replacements</span></span><br><span class="line">suggestedwords = [d.suggest(w) <span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># replace incorrect words with [MASK]</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords:</span><br><span class="line">    text = text.replace(w, <span class="string">'[MASK]'</span>)</span><br><span class="line"></span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as [MASK] spending Strengthened ,  manufacturing activity [MASK] to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

<h3 id="Use-the-pretrained-BERT-model-to-predict-words"><a href="#Use-the-pretrained-BERT-model-to-predict-words" class="headerlink" title="Use the pretrained BERT model to predict words"></a>Use the pretrained BERT model to predict words</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenize text</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">tokenized_text = tokenizer.tokenize(text)</span><br><span class="line">indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)</span><br><span class="line">MASKIDS = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">'[MASK]'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the segments tensors</span></span><br><span class="line">segs = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">"."</span>]</span><br><span class="line">segments_ids = []</span><br><span class="line">prev = <span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> k, s <span class="keyword">in</span> enumerate(segs):</span><br><span class="line">    segments_ids = segments_ids + [k] * (s-prev)</span><br><span class="line">    prev = s</span><br><span class="line">segments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))</span><br><span class="line">segments_tensors = torch.tensor([segments_ids])</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare Torch inputs</span></span><br><span class="line">tokens_tensors = torch.tensor([indexed_tokens])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load pre-trained model</span></span><br><span class="line">model = BertForMaskedLM.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict all tokens</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    predictions = model(tokens_tensors, segments_tensors)</span><br></pre></td></tr></table></figure>

<ul>
<li>Match with proposals from SpellChecker</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_word</span><span class="params">(text_original, predictions, MASKIDS)</span>:</span></span><br><span class="line">    pred_words = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(MASKIDS)):</span><br><span class="line">        preds = torch.topk(predictions[<span class="number">0</span>, MASKIDS[i]], k=<span class="number">50</span>)</span><br><span class="line">        indices = preds.indices.tolist()</span><br><span class="line">        pred_list = tokenizer.convert_ids_to_tokens(indices)</span><br><span class="line">        sugg_list = suggestedwords[i]</span><br><span class="line">        sim_max = <span class="number">0</span></span><br><span class="line">        predicted_token = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> word1 <span class="keyword">in</span> pred_list:</span><br><span class="line">            <span class="keyword">for</span> word2 <span class="keyword">in</span> sugg_list:</span><br><span class="line">                s = SequenceMatcher(<span class="literal">None</span>, word1, word2).ratio()</span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> s &gt; sim_max:</span><br><span class="line">                    sim_max = s</span><br><span class="line">                    predicted_token = word1</span><br><span class="line">        text_original = text_original.replace(<span class="string">'[MASK]'</span>, predicted_token, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> text_original</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text_refined = predict_word(text, predictions, MASKIDS)</span><br><span class="line">print(text_refined)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as consumer spending Strengthened ,  manufacturing activity continued to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/07/18/spelling-correction-with-pretrained-bert/" data-id="clpllv7wk001mt4xv1uk656s5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Spelling-Corrector-from-Scratch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Spelling-Corrector-from-Scratch/" class="article-date">
  <time datetime="2020-06-19T17:25:39.000Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Spelling-Corrector-from-Scratch/">Spelling Corrector from Scratch</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202006/20200619/0.jpg" alt=""></p>
<p>To a entry-level NLP learner, an industrial-strength spell corrector are quite complex, but writing a toy spelling corrector from scratch that achieves 80% or 90% accuracy at a processing speed of tens of words per second in a few dozens of lines of code is possible.</p>
<p>Here is the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">words</span><span class="params">(text)</span>:</span> <span class="keyword">return</span> re.findall(<span class="string">r'\w+'</span>, text.lower())</span><br><span class="line"></span><br><span class="line">WORDS = Counter(words(open(<span class="string">'book.txt'</span>).read()))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">P</span><span class="params">(word, N=sum<span class="params">(WORDS.values<span class="params">()</span>)</span>)</span>:</span></span><br><span class="line">    <span class="string">"Probability of `word`."</span></span><br><span class="line">    <span class="keyword">return</span> WORDS[word] / N</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correction</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="string">"Most probable spelling correction for word."</span></span><br><span class="line">    <span class="keyword">return</span> max(candidates(word), key=P)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">candidates</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="string">"Generate possible spelling corrections for word."</span></span><br><span class="line">    <span class="keyword">return</span> (known([word]) <span class="keyword">or</span> known(edits1(word)) <span class="keyword">or</span> known(edits2(word)) <span class="keyword">or</span> [word])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">known</span><span class="params">(words)</span>:</span></span><br><span class="line">    <span class="string">"The subset of `words` that appear in the dictionary of WORDS."</span></span><br><span class="line">    <span class="keyword">return</span> set(w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> w <span class="keyword">in</span> WORDS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits1</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="string">"All edits that are one edit away from `word`."</span></span><br><span class="line">    letters    = <span class="string">'abcdefghijklmnopqrstuvwxyz'</span></span><br><span class="line">    splits     = [(word[:i], word[i:])    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(word) + <span class="number">1</span>)]</span><br><span class="line">    deletes    = [L + R[<span class="number">1</span>:]               <span class="keyword">for</span> L, R <span class="keyword">in</span> splits <span class="keyword">if</span> R]</span><br><span class="line">    transposes = [L + R[<span class="number">1</span>] + R[<span class="number">0</span>] + R[<span class="number">2</span>:] <span class="keyword">for</span> L, R <span class="keyword">in</span> splits <span class="keyword">if</span> len(R)&gt;<span class="number">1</span>]</span><br><span class="line">    replaces   = [L + c + R[<span class="number">1</span>:]           <span class="keyword">for</span> L, R <span class="keyword">in</span> splits <span class="keyword">if</span> R <span class="keyword">for</span> c <span class="keyword">in</span> letters]</span><br><span class="line">    inserts    = [L + c + R               <span class="keyword">for</span> L, R <span class="keyword">in</span> splits <span class="keyword">for</span> c <span class="keyword">in</span> letters]</span><br><span class="line">    <span class="keyword">return</span> set(deletes + transposes + replaces + inserts)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits2</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="string">"All edits that are two edits away from `word`."</span></span><br><span class="line">    <span class="keyword">return</span> (e2 <span class="keyword">for</span> e1 <span class="keyword">in</span> edits1(word) <span class="keyword">for</span> e2 <span class="keyword">in</span> edits1(e1))</span><br></pre></td></tr></table></figure>

<p>The <code>book.txt</code> dataset could be any English e-book.</p>
<p>The function correction(word) returns a likely spelling correction:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; correction(<span class="string">'speling'</span>)</span></span><br><span class="line">'spelling'</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; correction(<span class="string">'korrectud'</span>)</span></span><br><span class="line">'corrected'</span><br></pre></td></tr></table></figure>

<h3 id="How-does-it-work"><a href="#How-does-it-work" class="headerlink" title="How does it work?"></a>How does it work?</h3><p>The above function uses a <a href="https://en.wikipedia.org/wiki/Levenshtein_distance" target="_blank" rel="noopener">Levenshtein Distance</a> algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results.</p>
<p>The <code>correction(A)</code> function tries to choose the most likely spelling correction for A. There is no way to know for sure (for example, should “lates” be corrected to “late” or “latest” or “lattes” or …?), which suggests we use probabilities. We are trying to find the correction B, out of all possible candidate corrections, that maximizes the probability that B is the intended correction, given the original word A.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://norvig.com/spell-correct.html" target="_blank" rel="noopener">Peter Norvig’s blog</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/06/19/Spelling-Corrector-from-Scratch/" data-id="clpllv7w40011t4xv68u929jk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/" class="article-date">
  <time datetime="2020-04-20T17:20:22.000Z" itemprop="datePublished">2020-04-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Deep-Learning/">Deep-Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/">Convert Pre-trained Model from MXNet to PyTorch or TensorFlow</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/0.png" alt=""></p>
<p>Currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models. Sometimes, when you find a fantastic GitHub repository which share a pre-trained model on a framework which you are not familiar with. For example, you are an expert PyTorch deep learning code developer, meanwhile you find a great code with its pre-trained model on MXNet; and you want to modify this model according to your needs. Thus, deep learning model conversion tools are extremely needed. As each framework has its own structure, converting a model between two different frameworks requires a great knowledge of both of them. However, There are many fantastic model conversion tools such as <a href="https://onnx.ai/" target="_blank" rel="noopener">ONNX</a>, <a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a>, and etc. for converting and visualizing deep models between a wide collection of frameworks.  </p>
<h3 id="Model-Convertors"><a href="#Model-Convertors" class="headerlink" title="Model Convertors"></a>Model Convertors</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/1.jpg" alt=""></p>
<ul>
<li>ONNX</li>
</ul>
<p><a href="http://onnx.ai/" target="_blank" rel="noopener">ONNX</a> is an effort to unify converters for neural networks in order to bring some sanity to the NN world. Released by Facebook and Microsoft.</p>
<ul>
<li>MMdnn</li>
</ul>
<p><a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a> (Model Management Deep Neural Network) is supported by Microsoft, By using MMdnn, one can convert each model from the origin framework to a standard Intermediate Representation (IR), and then convert the IR format to the target framework structure. It can convert models between CaffeEmit, CNTK, CoreML, Keras, MXNet, ONNX, PyTorch and TensorFlow.</p>
<ul>
<li>PyTorch convertor  </li>
</ul>
<p><a href="https://github.com/ruotianluo/pytorch-resnet" target="_blank" rel="noopener">PyTorch convertor</a> can convert models to PyTorch model.</p>
<ul>
<li>TensorFlow convertor  </li>
</ul>
<p><a href="https://github.com/goranrauker/convert-to-tensorflow" target="_blank" rel="noopener">TensorFlow convertor</a> can convert models to TensorFlow model.</p>
<ul>
<li>Keras convertor  </li>
</ul>
<p><a href="https://github.com/qxcv/caffe2keras" target="_blank" rel="noopener">Keras convertor</a> can convert models to Keras model.</p>
<ul>
<li>MXNet convertor</li>
</ul>
<p><a href="https://github.com/nicklhy/ResNet_caffe2mxnet" target="_blank" rel="noopener">MXNet convertor</a> can convert models to MXNet model.</p>
<ul>
<li>Caffe convertor</li>
</ul>
<p><a href="https://github.com/longcw/pytorch2caffe" target="_blank" rel="noopener">Caffe convertor</a> can convert models to Caffe model.</p>
<ul>
<li>Caffe2 convertor</li>
</ul>
<p><a href="https://caffe2.ai/docs/caffe-migration.html#caffe-to-caffe2" target="_blank" rel="noopener">Caffe2 convertor</a> can convert models to Caffe2 model.</p>
<ul>
<li>CNTK convertor</li>
</ul>
<p><a href="https://github.com/Microsoft/CNTK/tree/master/bindings/python/cntk/contrib/crosstalkcaffe" target="_blank" rel="noopener">CNTK convertor</a> can convert models to CNTK model.</p>
<ul>
<li>Theano/Lasagne convertor</li>
</ul>
<p><a href="https://github.com/an-kumar/caffe-theano-conversion" target="_blank" rel="noopener">Theano/Lasagne convertor</a> can convert models to Theano/Lasagne model.</p>
<ul>
<li>Darknet convertor  </li>
</ul>
<p><a href="https://github.com/marvis/pytorch-caffe-darknet-convert" target="_blank" rel="noopener">Darknet convertor</a> can convert models to Darknet model.</p>
<ul>
<li>Torch convertor  </li>
</ul>
<p><a href="https://github.com/kmatzen/googlenet-caffe2torch" target="_blank" rel="noopener">Torch convertor</a> can convert models to Torch model.</p>
<ul>
<li>Neon convertor  </li>
</ul>
<p><a href="https://github.com/NervanaSystems/caffe2neon" target="_blank" rel="noopener">Neon convertor</a> can convert models to Neon model.</p>
<ul>
<li>CoreML convertor</li>
</ul>
<p><a href="https://developer.apple.com/documentation/coreml" target="_blank" rel="noopener">CoreML convertor</a> can convert models to coreML model.</p>
<ul>
<li>Paddle convertor  </li>
</ul>
<p><a href="https://github.com/PaddlePaddle/X2Paddle" target="_blank" rel="noopener">Paddle convertor</a> can convert models to Paddle model.</p>
<ul>
<li>Chainer convertor  </li>
</ul>
<p>Chainer convertor can convert models to Chainer model.</p>
<h3 id="A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch"><a href="#A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch" class="headerlink" title="A Demo of Model Convertion from MXNet to PyTorch"></a>A Demo of Model Convertion from MXNet to PyTorch</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/2.png" alt=""></p>
<p>Here is an appropriate example to convert the Full ImageNet pre-trained model from MXNet to PyTorch via MMdnn convertor. ImageNet is an image database organized according to the WordNet hierarchy, in which each node of the hierarchy is depicted by hundreds and thousands of images. Since 2010, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a competition where research teams evaluate their algorithms on the given data set, and compete to achieve higher accuracy on several visual recognition tasks. A common reason to train a network on ImageNet data is to use it for transfer learning (including feature extraction or fine-tuning other models). Having a pre-trained model which is trained on such a huge training data set (i.e., full ImageNet), would be a really valuable network. It can speed up the convergence early in the training phase, and also improves the target task accuracy in some scenarios.</p>
<ul>
<li>Prerequisites:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade mmdnn</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade torch torchvision</span><br></pre></td></tr></table></figure>

<ul>
<li>Download pre-trained models:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_base_model_url = <span class="string">'http://data.mxnet.io/models/'</span></span><br><span class="line">_default_model_info = &#123;</span><br><span class="line">    <span class="string">'imagenet11k-resnet-152'</span>: &#123;<span class="string">'symbol'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-symbol.json'</span>,</span><br><span class="line">                             <span class="string">'params'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-0000.params'</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_file</span><span class="params">(url, local_fname=None, force_write=False)</span>:</span></span><br><span class="line">    <span class="comment"># requests is not default installed</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="keyword">if</span> local_fname <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        local_fname = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> force_write <span class="keyword">and</span> os.path.exists(local_fname):</span><br><span class="line">        <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line">    dir_name = os.path.dirname(local_fname)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dir_name != <span class="string">""</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_name):</span><br><span class="line">            <span class="keyword">try</span>:  <span class="comment"># try to create the directory if it doesn't exists</span></span><br><span class="line">                os.makedirs(dir_name)</span><br><span class="line">            <span class="keyword">except</span> OSError <span class="keyword">as</span> exc:</span><br><span class="line">                <span class="keyword">if</span> exc.errno != errno.EEXIST:</span><br><span class="line">                    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    r = requests.get(url, stream=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">assert</span> r.status_code == <span class="number">200</span>, <span class="string">"failed to open %s"</span> % url</span><br><span class="line">    <span class="keyword">with</span> open(local_fname, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size=<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">if</span> chunk:  <span class="comment"># filter out keep-alive new chunks</span></span><br><span class="line">                f.write(chunk)</span><br><span class="line">    <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_model</span><span class="params">(model_name, dst_dir=<span class="string">'./'</span>, meta_info=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> meta_info <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        meta_info = _default_model_info</span><br><span class="line">    meta_info = dict(meta_info)</span><br><span class="line">    <span class="keyword">if</span> model_name <span class="keyword">not</span> <span class="keyword">in</span> meta_info:</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">None</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_dir):</span><br><span class="line">        os.mkdir(dst_dir)</span><br><span class="line">    meta = dict(meta_info[model_name])</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'symbol'</span> <span class="keyword">in</span> meta, <span class="string">"missing symbol url"</span></span><br><span class="line">    model_name = os.path.join(dst_dir, model_name)</span><br><span class="line">    download_file(meta[<span class="string">'symbol'</span>], model_name+<span class="string">'-symbol.json'</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'params'</span> <span class="keyword">in</span> meta, <span class="string">"mssing parameter file url"</span></span><br><span class="line">    download_file(meta[<span class="string">'params'</span>], model_name+<span class="string">'-0000.params'</span>)</span><br><span class="line">    <span class="keyword">return</span> (model_name, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># ***** Download synset (i.e., Synonym Set):</span></span><br><span class="line">    synset_url = <span class="string">'http://data.mxnet.io.s3-website-us-west-1.amazonaws.com/models/imagenet-11k/synset.txt'</span></span><br><span class="line">    download_file(synset_url, <span class="string">'synset.txt'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ***** Download Model:</span></span><br><span class="line">    download_model(<span class="string">'imagenet11k-resnet-152'</span>, dst_dir=<span class="string">'./'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>Converting Full ImageNet Pre-trained Model from MXNet to PyTorch:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.convertToIR -f mxnet -n imagenet11k-resnet-152-symbol.json -w imagenet11k-resnet-152-0000.params -d resnet152 --inputShape 3,224,224</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.IRToCode -f pytorch --IRModelPath resnet152.pb --dstModelPath kit_imagenet.py --IRWeightPath resnet152.npy -dw kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion.examples.pytorch.imagenet_test --dump resnet152Full.pth -n kit_imagenet.py -w kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<ul>
<li>Testing the Converted Model:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.keras.api.keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ************** Parameters:</span></span><br><span class="line">num_predictions = <span class="number">5</span>  <span class="comment"># Top-k Results</span></span><br><span class="line">model_address = <span class="string">'resnet152Full.pth'</span>  <span class="comment"># for loading models</span></span><br><span class="line">lexicon_address = <span class="string">'synset.txt'</span></span><br><span class="line">test_image_address = <span class="string">'seagull.jpg'</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Converted Model:</span></span><br><span class="line">model = torch.load(model_address).to(device)</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read Input Image and Apply Pre-process:</span></span><br><span class="line">img = image.load_img(test_image_address, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x[..., ::<span class="number">-1</span>]  <span class="comment"># transform image from RGB to BGR</span></span><br><span class="line">x = np.transpose(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">x = np.expand_dims(x, <span class="number">0</span>).copy()</span><br><span class="line">x = torch.from_numpy(x)</span><br><span class="line">x = x.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Full-ImageNet Dictionary (i.e., lexicon):</span></span><br><span class="line"><span class="keyword">with</span> open(lexicon_address, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    labels = [l.rstrip() <span class="keyword">for</span> l <span class="keyword">in</span> f]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make prediction (forward pass):</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(x)</span><br><span class="line">max, argmax = output.data.squeeze().max(<span class="number">0</span>)</span><br><span class="line">class_id = argmax.item()</span><br><span class="line">class_name = labels[class_id]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the top-5 Results:</span></span><br><span class="line">h_x = output.data.squeeze()</span><br><span class="line">probs, idx = h_x.sort(<span class="number">0</span>, <span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'Top-5 Results: '</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_predictions):</span><br><span class="line">    print(<span class="string">'&#123;:.2f&#125;% -&gt; &#123;&#125;'</span>.format(probs[i] * <span class="number">100.0</span>, labels[idx[i]]))</span><br><span class="line">str_final_label = <span class="string">'The Image is a '</span> + class_name[<span class="number">10</span>:] + <span class="string">'.'</span></span><br><span class="line">print(str_final_label)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/" data-id="clpllv7ut0002t4xvbl9y6f9w" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pre-trained-Model/" rel="tag">Pre-trained-Model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TenforFlow/" rel="tag">TenforFlow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/22/automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering/" class="article-date">
  <time datetime="2020-03-22T14:32:33.000Z" itemprop="datePublished">2020-03-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/22/automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering/">Automatic Clustering with Silhouette Analysis on Agglomerative Hierarchical Clustering</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>

<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202003/20200322/0.png" alt=""></p>
<p>Automatic clustering algorithms are algorithms that can perform clustering without prior knowledge of data sets, and determine the optimal number of clusters even in the presence of noise and outlier points.</p>
<h3 id="Silhouette-Analysis"><a href="#Silhouette-Analysis" class="headerlink" title="Silhouette Analysis"></a>Silhouette Analysis</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202003/20200322/1.png" alt=""></p>
<p>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters. The silhouette score is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters. Thus silhouette analysis can be used to choose an optimal number for clusters automatically.</p>
<h3 id="Agglomerative-Hierarchical-Clustering"><a href="#Agglomerative-Hierarchical-Clustering" class="headerlink" title="Agglomerative Hierarchical Clustering"></a>Agglomerative Hierarchical Clustering</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202003/20200322/2.gif" alt=""></p>
<p>Hierarchical clustering algorithms fall into 2 branches: top-down or bottom-up. Bottom-up algorithms treat each data point as a single cluster at the outset and then successively merge (or agglomerate) pairs of clusters until all clusters have been merged into a single cluster that contains all data points. Bottom-up hierarchical clustering is therefore called hierarchical agglomerative clustering or HAC. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample.</p>
<p><b>The Steps of Hierarchical clustering:</b></p>
<ol>
<li><p>We start by treating each data point as a single cluster i.e. if there are N data points in our dataset then we have N clusters. We then select a distance metric that measures the distance between two clusters. As an example, we will use average linkage which defines the distance between two clusters to be the average distance between data points in the first cluster and data points in the second cluster.</p>
</li>
<li><p>On each iteration, two clusters are combined into one. The two clusters to be combined are selected as those with the smallest average linkage. I.e. according to our selected distance metric, these two clusters have the smallest distance between each other and therefore are the most similar and should be combined.</p>
</li>
<li><p>Step 2 is repeated until we reach the root of the tree that one cluster contains all data points. In this way we can select how many clusters we want in the end simply by choosing when to stop combining the clusters i.e. when we stop building the tree!</p>
</li>
</ol>
<h3 id="Automatic-Clustering"><a href="#Automatic-Clustering" class="headerlink" title="Automatic Clustering"></a>Automatic Clustering</h3><p>Since hierarchical clustering does not require us to specify the number of clusters and we can even select which number of clusters looks best since we are building a tree. Here we use the silhouette score to help us determine choosing the optimal number of clusters for clustering task automatically. An example of auto-clustering with silhouette analysis on agglomerative hierarchical clustering is shown as follows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AgglomerativeClustering</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, normalize</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"><span class="keyword">import</span> scipy.cluster.hierarchy <span class="keyword">as</span> shc</span><br></pre></td></tr></table></figure>
<p>Load and clean the data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X = pd.read_csv(<span class="string">'customer_info.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dropping the CUST_ID column from the data</span></span><br><span class="line">X = X.drop(<span class="string">'CUST_ID'</span>, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Handling the missing values</span></span><br><span class="line">X.fillna(method =<span class="string">'ffill'</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>Preprocess the data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scaling the data so that all the features become comparable</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalizing the data so that the data approximately  </span></span><br><span class="line"><span class="comment"># follows a Gaussian distribution</span></span><br><span class="line">X_normalized = normalize(X_scaled)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Converting the numpy array into a pandas DataFrame</span></span><br><span class="line">X_normalized = pd.DataFrame(X_normalized)</span><br></pre></td></tr></table></figure>

<p>Reduce the dimensionality:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">2</span>)</span><br><span class="line">X_new = pca.fit_transform(X_normalized)</span><br><span class="line">df_new = pd.DataFrame(X_new)</span><br><span class="line">df_new.columns = [<span class="string">'P1'</span>, <span class="string">'P2'</span>]</span><br></pre></td></tr></table></figure>

<p>Visualize the dendograms:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize =(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">'Visualising Clustering'</span>)</span><br><span class="line">Dendrogram = shc.dendrogram((shc.linkage(df_new, method =<span class="string">'ward'</span>)))</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202003/20200322/3.png" alt=""></p>
<p>Evaluate the clustering models:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">k = range(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ac_list = [AgglomerativeClustering(n_clusters = i) <span class="keyword">for</span> i <span class="keyword">in</span> k]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Appending the silhouette scores</span></span><br><span class="line">silhouette_scores = &#123;&#125;</span><br><span class="line">silhouette_scores.fromkeys(k)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(k):</span><br><span class="line">    silhouette_scores[j] = silhouette_score(df_new,</span><br><span class="line">                        ac_list[i].fit_predict(df_new))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plotting</span></span><br><span class="line">y = list(silhouette_scores.values())</span><br><span class="line">plt.bar(k, y)</span><br><span class="line">plt.xlabel(<span class="string">'Number of clusters'</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">'S(i)'</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202003/20200322/4.png" alt=""></p>
<p>From the result above, we can conclude that 3 clusters obtain the highest silhouette score so the optimal number of clusters is 3 in this case. The complete <code>code</code> and <code>dataset</code> can be found <a href="https://github.com/steven-cheng-com/auto_clustering_with_silhouette_analysis" target="_blank" rel="noopener">here</a></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://en.wikipedia.org/wiki/Automatic_clustering_algorithms" target="_blank" rel="noopener">Wikipedia-Automatic clustering algorithms</a><br>[2] <a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html</a><br>[3] <a href="https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68" target="_blank" rel="noopener">The 5 Clustering Algorithms Data Scientists Need to Know</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/03/22/automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering/" data-id="clpllv7wd001gt4xve81c6stb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hierarchical-Clustering/" rel="tag">Hierarchical-Clustering</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Silhouette/" rel="tag">Silhouette</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-object-detection-with-luminoth-step-by-step" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/14/object-detection-with-luminoth-step-by-step/" class="article-date">
  <time datetime="2020-02-14T22:19:36.000Z" itemprop="datePublished">2020-02-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer-Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/14/object-detection-with-luminoth-step-by-step/">Object Detection with Luminoth Step by Step</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202002/20200214/0.jpg" alt=""></p>
<p>Luminoth is an open source toolkit for computer vision. It supports object detection and it’s built in Python, using TensorFlow. The code is open source and available on <a href="https://github.com/tryolabs/luminoth" target="_blank" rel="noopener">GitHub</a>.</p>
<h3 id="Detecting-Objects-with-a-Pre-trained-Model"><a href="#Detecting-Objects-with-a-Pre-trained-Model" class="headerlink" title="Detecting Objects with a Pre-trained Model"></a>Detecting Objects with a Pre-trained Model</h3><p>The first thing is being familiarized with the Luminoth CLI tool, that is, the tool that you interact with using the lumi command. This is the main gate to Luminoth, allowing you to train new models, evaluate them, use them for predictions, manage the checkpoints and more.</p>
<p>If we want Luminoth to predict the objects present in one of  pictures (image.jpg). The way to do that is by running the following command:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi predict image.jpg</span><br></pre></td></tr></table></figure>

<p>The result will be like this:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Found 1 files to predict.</span><br><span class="line">Neither checkpoint not config specified, assuming `accurate`.</span><br><span class="line">Checkpoint not found. Check remote repository? [y/N]:</span><br></pre></td></tr></table></figure>

<p>Since you didn’t tell Luminoth what an “object” is for you, nor have taught it how to recognize said objects. So one way to do this is to use a pre-trained model that has been trained to detect popular types of objects. E.g., it can be a model trained with COCO dataset or Pascal VOC. What’s more, each pre-trained model might be associated with a different algorithm. The checkpoints correspond to the weights of a particular model (Faster R-CNN or SSD), trained with a particular dataset. The case of “accurate” is just a label for a particular Deep Learning model underneath, here, Faster R-CNN, trained with images from the COCO dataset.</p>
<p>After the checkpoint download, with these commands we can output everything (a resulting image and a json file) to a preds directory:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir preds</span><br><span class="line">lumi predict image.jpg -f preds/objects.json -d preds/</span><br></pre></td></tr></table></figure>

<h3 id="Exploring-the-Pre-trained-Checkpoints"><a href="#Exploring-the-Pre-trained-Checkpoints" class="headerlink" title="Exploring the Pre-trained Checkpoints"></a>Exploring the Pre-trained Checkpoints</h3><p>First, run the lumi checkpoint refresh command, so Luminoth knows about the checkpoints that it has available for download. After refreshing the local index, you can list the available checkpoints running lumi checkpoint list:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================================================================</span><br><span class="line">|           id |                  name |       alias | source |         status |</span><br><span class="line">================================================================================</span><br><span class="line">| e1c2565b51e9 |   Faster R-CNN w/COCO |    accurate | remote |     DOWNLOADED |</span><br><span class="line">| aad6912e94d9 |      SSD w/Pascal VOC |        fast | remote | NOT_DOWNLOADED |</span><br><span class="line">================================================================================</span><br></pre></td></tr></table></figure>

<p>Here, you can see the “accurate” checkpoint and another “fast” checkpoint that is the SSD model trained with Pascal VOC dataset. Let’s get some information about the “accurate” checkpoint by the following command:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi checkpoint info e1c2565b51e9</span><br></pre></td></tr></table></figure>
<p>or</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi checkpoint info accurate</span><br></pre></td></tr></table></figure>

<p>If getting predictions for an image or video using a specific checkpoint (e.g., fast) you can do so by using the –checkpoint parameter:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi predict img.jpg --checkpoint fast -f preds/objects.json -d preds/</span><br></pre></td></tr></table></figure>

<h3 id="Playing-Around-with-the-Built-in-Interface"><a href="#Playing-Around-with-the-Built-in-Interface" class="headerlink" title="Playing Around with the Built-in Interface"></a>Playing Around with the Built-in Interface</h3><p>Luminoth includes a simple web frontend so you can play around with detected objects in images using different thresholds. To launch this, simply type lumi server web and then open your browser at <a href="http://localhost:5000" target="_blank" rel="noopener">http://localhost:5000</a>. If you are running on an external VM, you can do lumi server web –host 0.0.0.0 –port <port> to open in a custom port.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202002/20200214/1.jpg" alt=""></p>
<h3 id="Building-Custom-dataset"><a href="#Building-Custom-dataset" class="headerlink" title="Building Custom dataset"></a>Building Custom dataset</h3><p>In order to use a custom dataset, we must first transform whatever format your data is in, to TFRecords files (one for each split — train, val, test). Luminoth reads datasets natively only in TensorFlow’s TFRecords format. This is a binary format that will let Luminoth consume the data very efficiently. Fortunately, Luminoth provides several CLI tools for transforming popular dataset format (such as Pascal VOC, ImageNet, COCO, CSV, etc.) into TFRecords.</p>
<p>We should start by downloading the <a href="https://storage.googleapis.com/openimages/web/download.html" target="_blank" rel="noopener">annotation files</a> (<a href="https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv" target="_blank" rel="noopener">this</a> and <a href="https://storage.googleapis.com/openimages/2018_04/train/train-annotations-human-imagelabels-boxable.csv" target="_blank" rel="noopener">this</a>, for train) and the <a href="https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv" target="_blank" rel="noopener">class description</a> file.</p>
<p>After we get the class-descriptions-boxable.csv file, we can go over all the classes available in the OpenImages dataset and see which ones are related to traffic dataset. The following were hand-picked after examining the full file:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/m/015qff,Traffic light</span><br><span class="line">/m/0199g,Bicycle</span><br><span class="line">/m/01bjv,Bus</span><br><span class="line">/m/01g317,Person</span><br><span class="line">/m/04_sv,Motorcycle</span><br><span class="line">/m/07r04,Truck</span><br><span class="line">/m/0h2r6,Van</span><br><span class="line">/m/0k4j,Car</span><br></pre></td></tr></table></figure>

<p>Luminoth includes a dataset reader that can take OpenImages format, the dataset reader expects a particular directory layout so it knows where the files are located. In this case, files corresponding to the examples must be in a folder named like their split (train, test, …). So, you should have the following:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── class-descriptions-boxable.csv</span><br><span class="line">└── train</span><br><span class="line">    ├── train-annotations-bbox.csv</span><br><span class="line">    └── train-annotations-human-imagelabels-boxable.csv</span><br></pre></td></tr></table></figure>

<p>Then run the following command:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lumi dataset transform \</span><br><span class="line">      --type openimages \</span><br><span class="line">      --data-dir . \</span><br><span class="line">      --output-dir ./out \</span><br><span class="line">      --split train  \</span><br><span class="line">      --class-examples 100 \</span><br><span class="line">      --only-classes=/m/015qff,/m/0199g,/m/01bjv,/m/01g317,/m/04_sv,/m/07r04,/m/0h2r6,/m/0k4j</span><br></pre></td></tr></table></figure>

<p>This will generate TFRecord file for the train split:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Saved 360 records to "./out/train.tfrecords"</span><br><span class="line">INFO:tensorflow:Composition per class (train):</span><br><span class="line">INFO:tensorflow:        Person (/m/01g317): 380</span><br><span class="line">INFO:tensorflow:        Car (/m/0k4j): 255</span><br><span class="line">INFO:tensorflow:        Bicycle (/m/0199g): 126</span><br><span class="line">INFO:tensorflow:        Bus (/m/01bjv): 106</span><br><span class="line">INFO:tensorflow:        Traffic light (/m/015qff): 105</span><br><span class="line">INFO:tensorflow:        Truck (/m/07r04): 101</span><br><span class="line">INFO:tensorflow:        Van (/m/0h2r6): 100</span><br><span class="line">INFO:tensorflow:        Motorcycle (/m/04_sv): 100</span><br></pre></td></tr></table></figure>

<h3 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h3><p>Training orchestration, including the model to be used, the dataset location and training schedule, is specified in a YAML config file. This file will be consumed by Luminoth and merged to the default configuration, to start the training session.</p>
<p>You can see a minimal config file example in <a href="https://github.com/tryolabs/luminoth/blob/master/examples/sample_config.yml" target="_blank" rel="noopener">sample_config.yml</a>. This file illustrates the entries you’ll most probably need to modify, which are:</p>
<p>1) train.run_name: the run name for the training session, used to identify it.<br>2) train.job_dir: directory in which both model checkpoints and summaries (for TensorBoard consumption) will be saved. The actual files will be stored under <job_dir>/<run_name>.<br>3) dataset.dir: directory from which to read the TFRecord files.<br>4) model.type: model to use for object detection (fasterrcnn, or ssd).<br>5) network.num_classes: number of classes to predict (depends on your dataset).</p>
<p>For looking at all the possible configuration options, mostly related to the model itself, you can check the <a href="https://github.com/tryolabs/luminoth/blob/master/luminoth/models/fasterrcnn/base_config.yml" target="_blank" rel="noopener">base_config.yml</a> file.</p>
<h5 id="Building-the-config-file-for-the-dataset"><a href="#Building-the-config-file-for-the-dataset" class="headerlink" title="Building the config file for the dataset"></a>Building the config file for the dataset</h5><p>Probably the most important setting for training is the learning rate. You will most likely want to tune this depending on your dataset, and you can do it via the train.learning_rate setting in the configuration. For example, this would be a good setting for training on the full COCO dataset:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">learning_rate:</span><br><span class="line">  decay_method: piecewise_constant</span><br><span class="line">  boundaries: [250000, 450000, 600000]</span><br><span class="line">  values: [0.0003, 0.0001, 0.00003, 0.00001]</span><br></pre></td></tr></table></figure>

<p>To get to this, you will need to run some experiments and see what works best.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">train:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Run name <span class="keyword">for</span> the training session.</span></span><br><span class="line">  run_name: traffic</span><br><span class="line">  job_dir: &lt;change this directory&gt;</span><br><span class="line">  learning_rate:</span><br><span class="line">    decay_method: piecewise_constant</span><br><span class="line">    # Custom dataset for Luminoth Tutorial</span><br><span class="line">    boundaries: [90000, 160000, 250000]</span><br><span class="line">    values: [0.0003, 0.0001, 0.00003, 0.00001]</span><br><span class="line">dataset:</span><br><span class="line">  type: object_detection</span><br><span class="line">  dir: &lt;directory with your dataset&gt;</span><br><span class="line">model:</span><br><span class="line">  type: fasterrcnn</span><br><span class="line">  network:</span><br><span class="line">    num_classes: 8</span><br><span class="line">  anchors:</span><br><span class="line">    # Add one more scale to be better at detecting small objects</span><br><span class="line">    scales: [0.125, 0.25, 0.5, 1, 2]</span><br></pre></td></tr></table></figure>

<h5 id="Running-the-training"><a href="#Running-the-training" class="headerlink" title="Running the training"></a>Running the training</h5><p>Assuming you already have both your dataset (TFRecords) and the config file ready, you can start your training session by running the command as follows:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi train -c config.yml</span><br></pre></td></tr></table></figure>

<p>You can use the <code>-o</code> option to override any configuration option using dot notation (e.g. -o model.rpn.proposals.nms_threshold=0.8). If you are using a CUDA-based GPU, you can select the GPU to use by setting the <code>CUDA_VISIBLE_DEVICES</code> environment variable.</p>
<h5 id="Storing-checkpoints-partial-weights"><a href="#Storing-checkpoints-partial-weights" class="headerlink" title="Storing checkpoints (partial weights)"></a>Storing checkpoints (partial weights)</h5><p>As the training progresses, Luminoth will periodically save a checkpoint with the current weights of the model. The files will be output in your <job_dir>/<run_name> folder. By default, they will be saved every 600 seconds of training, but you can configure this with the train.save_checkpoint_secs setting in your config file. The default is to only store the latest checkpoint (that is, when a checkpoint is generated, the previous checkpoint gets deleted) in order to conserve storage.</p>
<h3 id="Evaluating-Models"><a href="#Evaluating-Models" class="headerlink" title="Evaluating Models"></a>Evaluating Models</h3><p>Generally, datasets (like OpenImages, which we just used) provide “splits”. The “train” split is the largest, and the one from which the model actually does the learning. Then, you have the “validation” (or “val”) split, which consists of different images, in which you can draw metrics of your model’s performance, in order to better tune your hyperparameters. Finally, a “test” split is provided in order to conduct the final evaluation of how your model would perform in the real world once it is trained.</p>
<h5 id="Building-a-validation-dataset"><a href="#Building-a-validation-dataset" class="headerlink" title="Building a validation dataset"></a>Building a validation dataset</h5><p>Let’s start by building TFRecords from the validation split of <a href="https://storage.googleapis.com/openimages/web/download.html" target="_blank" rel="noopener">OpenImages</a>. For this, we can download the files with the annotations and use the same lumi dataset transform that we used to build our training data.</p>
<p>In your dataset folder (where the class-descriptions-boxable.csv is located), run the following commands:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir validation</span><br><span class="line">wget -P validation https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv</span><br><span class="line">wget -P validation https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-human-imagelabels-boxable.csv</span><br></pre></td></tr></table></figure>

<p>After the downloads finish, we can build the TFRecords with the following:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lumi dataset transform \</span><br><span class="line">      --type openimages \</span><br><span class="line">      --data-dir . \</span><br><span class="line">      --output-dir ./out \</span><br><span class="line">      --split validation  \</span><br><span class="line">      --class-examples 100 \</span><br><span class="line">      --only-classes=/m/015qff,/m/0199g,/m/01bjv,/m/01g317,/m/04_sv,/m/07r04,/m/0h2r6,/m/0k4j</span><br></pre></td></tr></table></figure>

<h5 id="The-lumi-eval-command"><a href="#The-lumi-eval-command" class="headerlink" title="The lumi eval command"></a>The lumi eval command</h5><p>In Luminoth, lumi eval will make a run through your chosen dataset split (ie. validation or test), and run the model through every image, and then compute metrics like loss and mAP. If you are lucky and happen to have more than one GPU in your machine, it is advisable to run both train and eval at the same time.</p>
<p>Start by running the evaluation:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi eval --split validation -c custom.yml</span><br></pre></td></tr></table></figure>

<h5 id="The-mAP-metrics"><a href="#The-mAP-metrics" class="headerlink" title="The mAP metrics"></a>The mAP metrics</h5><p>Mean Average Precision (mAP) is the metric commonly used to evaluate object detection task. It computes how well your classifier works across all classes, mAP will be a number between 0 and 1, and the higher the better. Moreover, it can be calculated across different IoU (Intersection over Union) thresholds. For example, Pascal VOC challenge metric uses 0.5 as threshold (notation <a href="mailto:mAP@0.5">mAP@0.5</a>), and COCO dataset uses mAP at different thresholds and averages them all out (notation mAP@[0.5:0.95]). Luminoth will print out several of these metrics, specifying the thresholds that were used under this notation.</p>
<h3 id="Using-TensorBoard-for-Visualizing"><a href="#Using-TensorBoard-for-Visualizing" class="headerlink" title="Using TensorBoard for Visualizing"></a>Using TensorBoard for Visualizing</h3><p><a href="https://www.tensorflow.org/guide/summaries_and_tensorboard" target="_blank" rel="noopener">TensorBoard</a> is a very good tool for this, allowing you to see plenty of plots with the training related metrics. By default, Luminoth writes TensorBoard summaries during training, so you can leverage this tool without any effort:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir &lt;job_dir&gt;/&lt;run_name&gt;</span><br></pre></td></tr></table></figure>

<p>If you are running from an external VM, make sure to use <code>--host 0.0.0.0</code> and <code>--port</code> if you need other one than the default 6006.</p>
<h5 id="What-to-look-for"><a href="#What-to-look-for" class="headerlink" title="What to look for"></a>What to look for</h5><p>First, go to the “Scalars” tab. You are going to see several tags.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202002/20200214/2.png" alt=""></p>
<h5 id="validation-losses"><a href="#validation-losses" class="headerlink" title="validation_losses"></a>validation_losses</h5><p>Here, you will get the same loss values that Luminoth computes for the train, but for the chosen dataset split (validation, in this case). As in the case of train, you should mostly look at validation_losses/no_reg_loss.</p>
<p>These will be the mAP metrics that will help you judge how well your model perform:</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202002/20200214/3.png" alt=""></p>
<p>The mAP values refer to the entire dataset split, so it will not jump around as much as other metrics.</p>
<h5 id="Manually-inspecting-with-lumi-server-web"><a href="#Manually-inspecting-with-lumi-server-web" class="headerlink" title="Manually inspecting with lumi server web"></a>Manually inspecting with lumi server web</h5><p>You can also use lumi server web command that we have seen before and try your partially trained model in a bunch of novel images. For this, you can launch it with a config file like:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lumi server web -c config.yml</span><br></pre></td></tr></table></figure>

<p>Here you can also use –host and –port options.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202002/20200214/4.jpg" alt=""></p>
<h3 id="Creating-and-Sharing-Your-Own-Checkpoints"><a href="#Creating-and-Sharing-Your-Own-Checkpoints" class="headerlink" title="Creating and Sharing Your Own Checkpoints"></a>Creating and Sharing Your Own Checkpoints</h3><h5 id="Creating-a-checkpoint"><a href="#Creating-a-checkpoint" class="headerlink" title="Creating a checkpoint"></a>Creating a checkpoint</h5><p>We can create checkpoints and set some metadata like name, alias, etc. This time, we are going to create the checkpoint for our traffic model:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lumi checkpoint create \</span><br><span class="line">    config.yml \</span><br><span class="line">    -e name="OpenImages Traffic" \</span><br><span class="line">    -e alias=traffic</span><br></pre></td></tr></table></figure>

<p>You can verify that you do indeed have the checkpoint when running lumi checkpoint list, which should get you an output similar to this:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">================================================================================</span><br><span class="line">|           id |                  name |       alias | source |         status |</span><br><span class="line">================================================================================</span><br><span class="line">| e1c2565b51e9 |   Faster R-CNN w/COCO |    accurate | remote |     DOWNLOADED |</span><br><span class="line">| aad6912e94d9 |      SSD w/Pascal VOC |        fast | remote |     DOWNLOADED |</span><br><span class="line">| cb0e5d92a854 |    OpenImages Traffic |     traffic |  local |          LOCAL |</span><br><span class="line">================================================================================</span><br></pre></td></tr></table></figure>

<p>Moreover, if you inspect the <code>~/.luminoth/checkpoints/</code> folder, you will see that now you have a folder that corresponds to your newly created checkpoint. Inside this folder are the actual weights of the model, plus some metadata and the configuration file that was used during training.</p>
<h5 id="Sharing-checkpoints"><a href="#Sharing-checkpoints" class="headerlink" title="Sharing checkpoints"></a>Sharing checkpoints</h5><p>Simply run <code>lumi checkpoint export cb0e5d92a854</code>. You will get a file named cb0e5d92a854.tar in your current directory, which you can easily share to somebody else. By running <code>lumi checkpoint import cb0e5d92a854.tar</code>, the checkpoint will be listed locally.</p>
<h3 id="Using-Luminoth-with-Python"><a href="#Using-Luminoth-with-Python" class="headerlink" title="Using Luminoth with Python"></a>Using Luminoth with Python</h3><p>Calling Luminoth from your Python app is very straightforward.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> luminoth <span class="keyword">import</span> Detector, read_image, vis_objects</span><br><span class="line"></span><br><span class="line">image = read_image(<span class="string">'traffic-image.png'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># If no checkpoint specified, will assume `accurate` by default. In this case,</span></span><br><span class="line"><span class="comment"># we want to use our traffic checkpoint. The Detector can also take a config</span></span><br><span class="line"><span class="comment"># object.</span></span><br><span class="line">detector = Detector(checkpoint=<span class="string">'traffic'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Returns a dictionary with the detections.</span></span><br><span class="line">objects = detector.predict(image)</span><br><span class="line"></span><br><span class="line">print(objects)</span><br><span class="line"></span><br><span class="line">vis_objects(image, objects).save(<span class="string">'traffic-out.png'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="The-End"><a href="#The-End" class="headerlink" title="The End"></a>The End</h3><p>Hope you enjoyed the simple tutorial! :)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/02/14/object-detection-with-luminoth-step-by-step/" data-id="clpllv7wl001qt4xv19fs5nj9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer-Vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Object-Detection/" rel="tag">Object-Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Usage-of-PyTessBaseAPI-in-Tesserocr" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/Usage-of-PyTessBaseAPI-in-Tesserocr/" class="article-date">
  <time datetime="2020-01-18T20:16:21.000Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer-Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/Usage-of-PyTessBaseAPI-in-Tesserocr/">Usage of PyTessBaseAPI in Tesserocr</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202001/20200118/0.jpg" alt=""></p>
<p>Tesseroct is a simple, Pillow-friendly, wrapper around the tesseract-ocr API for Optical Character Recognition (OCR), it integrates directly with Tesseract’s C++ API using Cython which allows for a simple Pythonic and easy-to-read source code. It enables real concurrent execution when used with Python’s threading module by releasing the GIL while processing an image in tesseract.</p>
<h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><ul>
<li>Linux and BSD/MacOS</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install tesserocr</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Windows</li>
</ul>
<p>The proposed downloads consist of stand-alone packages containing all the Windows libraries needed for execution. The recommended method of installation is via Conda as described below.</p>
<p>1) Conda</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> conda install -c conda-forge tesserocr</span></span><br></pre></td></tr></table></figure>

<p>2) pip<br>Download the wheel file corresponding to your Windows platform and Python installation from <a href="https://github.com/simonflueckiger/tesserocr-windows_build/releases" target="_blank" rel="noopener">tesserocr-windows_build</a> and install them via:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> pip install &lt;package_name&gt;.whl</span></span><br></pre></td></tr></table></figure>

<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ul>
<li>Initialize and re-use the tesseract API instance to score multiple images:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI</span><br><span class="line"></span><br><span class="line">images = [<span class="string">'sample.jpg'</span>, <span class="string">'sample2.jpg'</span>, <span class="string">'sample3.jpg'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI() <span class="keyword">as</span> api:</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">        api.SetImageFile(img)</span><br><span class="line">        print(api.GetUTF8Text())</span><br><span class="line">        print(api.AllWordConfidences())</span><br><span class="line"><span class="comment"># api is automatically finalized when used in a with-statement (context manager).</span></span><br><span class="line"><span class="comment"># otherwise api.End() should be explicitly called when it's no longer needed.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Advanced API Examples</li>
</ul>
<p>1) GetComponentImages example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI, RIL</span><br><span class="line"></span><br><span class="line">image = Image.open(<span class="string">'/usr/src/tesseract/testing/phototest.tif'</span>)</span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI() <span class="keyword">as</span> api:</span><br><span class="line">    api.SetImage(image)</span><br><span class="line">    boxes = api.GetComponentImages(RIL.TEXTLINE, <span class="literal">True</span>)</span><br><span class="line">    print(<span class="string">'Found &#123;&#125; textline image components.'</span>.format(len(boxes)))</span><br><span class="line">    <span class="keyword">for</span> i, (im, box, _, _) <span class="keyword">in</span> enumerate(boxes):</span><br><span class="line">        <span class="comment"># im is a PIL image object</span></span><br><span class="line">        <span class="comment"># box is a dict with x, y, w and h keys</span></span><br><span class="line">        api.SetRectangle(box[<span class="string">'x'</span>], box[<span class="string">'y'</span>], box[<span class="string">'w'</span>], box[<span class="string">'h'</span>])</span><br><span class="line">        ocrResult = api.GetUTF8Text()</span><br><span class="line">        conf = api.MeanTextConf()</span><br><span class="line">        print(<span class="string">u"Box[&#123;0&#125;]: x=&#123;x&#125;, y=&#123;y&#125;, w=&#123;w&#125;, h=&#123;h&#125;, "</span></span><br><span class="line">              <span class="string">"confidence: &#123;1&#125;, text: &#123;2&#125;"</span>.format(i, conf, ocrResult, **box))</span><br></pre></td></tr></table></figure>

<p>2) Orientation and script detection (OSD):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI, PSM</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI(psm=PSM.AUTO_OSD) <span class="keyword">as</span> api:</span><br><span class="line">    image = Image.open(<span class="string">"/usr/src/tesseract/testing/eurotext.tif"</span>)</span><br><span class="line">    api.SetImage(image)</span><br><span class="line">    api.Recognize()</span><br><span class="line"></span><br><span class="line">    it = api.AnalyseLayout()</span><br><span class="line">    orientation, direction, order, deskew_angle = it.Orientation()</span><br><span class="line">    print(<span class="string">"Orientation: &#123;:d&#125;"</span>.format(orientation))</span><br><span class="line">    print(<span class="string">"WritingDirection: &#123;:d&#125;"</span>.format(direction))</span><br><span class="line">    print(<span class="string">"TextlineOrder: &#123;:d&#125;"</span>.format(order))</span><br><span class="line">    print(<span class="string">"Deskew angle: &#123;:.4f&#125;"</span>.format(deskew_angle))</span><br></pre></td></tr></table></figure>

<p><strong>or simply with OSD_ONLY page segmentation mode:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI, PSM</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI(psm=PSM.OSD_ONLY) <span class="keyword">as</span> api:</span><br><span class="line">    api.SetImageFile(<span class="string">"/usr/src/tesseract/testing/eurotext.tif"</span>)</span><br><span class="line"></span><br><span class="line">    os = api.DetectOS()</span><br><span class="line">    print(<span class="string">"Orientation: &#123;orientation&#125;\nOrientation confidence: &#123;oconfidence&#125;\n"</span></span><br><span class="line">          <span class="string">"Script: &#123;script&#125;\nScript confidence: &#123;sconfidence&#125;"</span>.format(**os))</span><br></pre></td></tr></table></figure>
<p><strong>more human-readable info with tesseract 4+ (with LSTM engine):</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI, PSM, OEM</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI(psm=PSM.OSD_ONLY, oem=OEM.LSTM_ONLY) <span class="keyword">as</span> api:</span><br><span class="line">    api.SetImageFile(<span class="string">"/usr/src/tesseract/testing/eurotext.tif"</span>)</span><br><span class="line"></span><br><span class="line">    os = api.DetectOrientationScript()</span><br><span class="line">    print(<span class="string">"Orientation: &#123;orient_deg&#125;\nOrientation confidence: &#123;orient_conf&#125;\n"</span></span><br><span class="line">          <span class="string">"Script: &#123;script_name&#125;\nScript confidence: &#123;script_conf&#125;"</span>.format(**os))</span><br></pre></td></tr></table></figure>

<p>3） Iterator over the classifier choices for a single symbol:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tesserocr <span class="keyword">import</span> PyTessBaseAPI, RIL, iterate_level</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> PyTessBaseAPI() <span class="keyword">as</span> api:</span><br><span class="line">    api.SetImageFile(<span class="string">'/usr/src/tesseract/testing/phototest.tif'</span>)</span><br><span class="line">    api.SetVariable(<span class="string">"save_blob_choices"</span>, <span class="string">"T"</span>)</span><br><span class="line">    api.SetRectangle(<span class="number">37</span>, <span class="number">228</span>, <span class="number">548</span>, <span class="number">31</span>)</span><br><span class="line">    api.Recognize()</span><br><span class="line"></span><br><span class="line">    ri = api.GetIterator()</span><br><span class="line">    level = RIL.SYMBOL</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> iterate_level(ri, level):</span><br><span class="line">        symbol = r.GetUTF8Text(level)  <span class="comment"># r == ri</span></span><br><span class="line">        conf = r.Confidence(level)</span><br><span class="line">        <span class="keyword">if</span> symbol:</span><br><span class="line">            print(<span class="string">u'symbol &#123;&#125;, conf: &#123;&#125;'</span>.format(symbol, conf), end=<span class="string">''</span>)</span><br><span class="line">        indent = <span class="literal">False</span></span><br><span class="line">        ci = r.GetChoiceIterator()</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> ci:</span><br><span class="line">            <span class="keyword">if</span> indent:</span><br><span class="line">                print(<span class="string">'\t\t '</span>, end=<span class="string">''</span>)</span><br><span class="line">            print(<span class="string">'\t- '</span>, end=<span class="string">''</span>)</span><br><span class="line">            choice = c.GetUTF8Text()  <span class="comment"># c == ci</span></span><br><span class="line">            print(<span class="string">u'&#123;&#125; conf: &#123;&#125;'</span>.format(choice, c.Confidence()))</span><br><span class="line">            indent = <span class="literal">True</span></span><br><span class="line">        print(<span class="string">'----------'</span>)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/01/18/Usage-of-PyTessBaseAPI-in-Tesserocr/" data-id="clpllv7vy000vt4xv9k8e2e20" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer-Vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OCR/" rel="tag">OCR</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer-Vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/System/">System</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azure/" rel="tag">Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bagging/" rel="tag">Bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bias/" rel="tag">Bias</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classification/" rel="tag">Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classifier/" rel="tag">Classifier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code/" rel="tag">Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer-Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/" rel="tag">Data-Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision-Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distance/" rel="tag">Distance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble/" rel="tag">Ensemble</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grammatical-Error-Correction/" rel="tag">Grammatical-Error-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hierarchical-Clustering/" rel="tag">Hierarchical-Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter/" rel="tag">Jupyter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/" rel="tag">Keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Levenshtein/" rel="tag">Levenshtein</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear/" rel="tag">Linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Merge/" rel="tag">Merge</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/" rel="tag">MongoDB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OCR/" rel="tag">OCR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Overfitting/" rel="tag">Overfitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pre-trained-Model/" rel="tag">Pre-trained-Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Programming/" rel="tag">Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyCharm/" rel="tag">PyCharm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regression/" rel="tag">Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scikit-Learn/" rel="tag">Scikit-Learn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shortcuts/" rel="tag">Shortcuts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Silhouette/" rel="tag">Silhouette</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sklearn/" rel="tag">Sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sort/" rel="tag">Sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Table-Detection/" rel="tag">Table-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TenforFlow/" rel="tag">TenforFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformers/" rel="tag">Transformers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tree/" rel="tag">Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VM/" rel="tag">VM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Variance/" rel="tag">Variance</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Stephen Cheng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/" class="mobile-nav-link">Home</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>