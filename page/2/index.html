<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Stephen Cheng</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="Personal sharings about Tech & Work.">



<meta name="keywords" content="AI, Tech, CS">



    <meta name="description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:type" content="website">
<meta property="og:title" content="Stephen Cheng">
<meta property="og:url" content="https://stephen-cheng.github.io/page/2/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Stephen Cheng">
<meta property="article:tag" content="AI">
<meta property="article:tag" content=" Tech">
<meta property="article:tag" content=" CS">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 4.2.1"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/12/19/PyCharm-keyboard-shortcuts/" itemprop="url">PyCharm Keyboard Shortcuts</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2019-12-20T03:17:38.000Z" itemprop="datePublished">Dec 19 2019</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Programming/">Programming</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            a few seconds read (About 78 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201912/20191219/0.png" alt=""></p>
<p>PyCharm is an integrated development environment for computer programming, specifically for the Python language. It is developed by the Czech company JetBrains on February 3, 2010.</p>
<h3 id="Part-one"><a href="#Part-one" class="headerlink" title="Part one"></a>Part one</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201912/20191219/1.png" alt=""></p>
<h3 id="Part-two"><a href="#Part-two" class="headerlink" title="Part two"></a>Part two</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201912/20191219/2.png" alt=""></p>
<h3 id="Part-three"><a href="#Part-three" class="headerlink" title="Part three"></a>Part three</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201912/20191219/3.png" alt=""></p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/09/21/Keras-for-Data-Science/" itemprop="url">Keras for Data Science</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2019-09-22T01:36:52.000Z" itemprop="datePublished">Sep 21 2019</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Deep-Learning/">Deep-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            5 minutes read (About 797 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201909/20190921/0.jpg" alt=""></p>
<p>Keras is a powerful and easy-to-use deep learning library for Theano and TensorFlow that provides a high-level neural networks API to develop and evaluate deep learning models.</p>
<h4 id="A-Basic-Example"><a href="#A-Basic-Example" class="headerlink" title="A Basic Example:"></a>A Basic Example:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = np.random.random((<span class="number">1000</span>,<span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>labels = np.random.randint(<span class="number">2</span>,size=(<span class="number">1000</span>,<span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = Sequential()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">32</span>,</span><br><span class="line"> activation=<span class="string">'relu'</span>,</span><br><span class="line"> input_dim=<span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line"> loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line"> metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.fit(data,labels,epochs=<span class="number">10</span>,batch_size=<span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>predictions = model.predict(data)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><p>Your data needs to be stored as NumPy arrays or as a list of NumPy arrays. Ideally, you split the data in training and test sets, for which you can also resort to the <em>train_test_split</em> module of <em>sklearn.cross_validation</em>.</p>
<h4 id="Keras-Data-Sets"><a href="#Keras-Data-Sets" class="headerlink" title="Keras Data Sets:"></a>Keras Data Sets:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> boston_housing,</span><br><span class="line"> mnist,</span><br><span class="line"> cifar10,</span><br><span class="line"> imdb</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x_train2,y_train2),(x_test2,y_test2) = boston_housing.load_data()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x_train3,y_train3),(x_test3,y_test3) = cifar10.load_data()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x_train4,y_train4),(x_test4,y_test4) = imdb.load_data(num_words=<span class="number">20000</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>num_classes = <span class="number">10</span></span><br></pre></td></tr></table></figure>

<h4 id="Other"><a href="#Other" class="headerlink" title="Other:"></a>Other:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = np.loadtxt(urlopen(<span class="string">"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"</span>),delimiter=<span class="string">","</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = data[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = data [:,<span class="number">8</span>]</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><h4 id="Sequence-Padding"><a href="#Sequence-Padding" class="headerlink" title="Sequence Padding:"></a>Sequence Padding:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x_train4 = sequence.pad_sequences(x_train4,maxlen=<span class="number">80</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x_test4 = sequence.pad_sequences(x_test4,maxlen=<span class="number">80</span>)</span><br></pre></td></tr></table></figure>

<h4 id="One-Hot-Encoding"><a href="#One-Hot-Encoding" class="headerlink" title="One-Hot Encoding:"></a>One-Hot Encoding:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Y_train = to_categorical(y_train, num_classes)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Y_test = to_categorical(y_test, num_classes)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Y_train3 = to_categorical(y_train3, num_classes)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Y_test3 = to_categorical(y_test3, num_classes)</span><br></pre></td></tr></table></figure>

<h4 id="Train-and-Test-Sets"><a href="#Train-and-Test-Sets" class="headerlink" title="Train and Test Sets:"></a>Train and Test Sets:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train5,X_test5,y_train5,y_test5 = train_test_split(X, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Standardization-Normalization"><a href="#Standardization-Normalization" class="headerlink" title="Standardization/Normalization:"></a>Standardization/Normalization:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler().fit(x_train2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>standardized_X = scaler.transform(x_train2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>standardized_X_test = scaler.transform(x_test2)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><h4 id="Sequential-Model"><a href="#Sequential-Model" class="headerlink" title="Sequential Model:"></a>Sequential Model:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = Sequential()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2 = Sequential()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3 = Sequential()</span><br></pre></td></tr></table></figure>

<h4 id="Multilayer-Perceptron-MLP"><a href="#Multilayer-Perceptron-MLP" class="headerlink" title="Multilayer Perceptron (MLP):"></a>Multilayer Perceptron (MLP):</h4><p><b>Binary Classification</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">12</span>,</span><br><span class="line"> input_dim=<span class="number">8</span>,</span><br><span class="line"> kernel_initializer=<span class="string">'uniform'</span>,</span><br><span class="line"> activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">8</span>,kernel_initializer=<span class="string">'uniform'</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">1</span>,kernel_initializer=<span class="string">'uniform'</span>,activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure>

<p><b>Multi-Class Classification</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">512</span>,activation=<span class="string">'relu'</span>,input_shape=(<span class="number">784</span>,)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">512</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>

<p><b>Regression</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>,input_dim=train_data.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add(Dense(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<h4 id="Convolutional-Neural-Network-CNN"><a href="#Convolutional-Neural-Network-CNN" class="headerlink" title="Convolutional Neural Network (CNN):"></a>Convolutional Neural Network (CNN):</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation,Conv2D,MaxPooling2D,Flatten</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>,input_shape=x_train.shape[<span class="number">1</span>:]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>), padding=<span class="string">'same'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Conv2D(<span class="number">64</span>,(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Flatten())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Dense(<span class="number">512</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Dense(num_classes))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.add(Activation(<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>

<h4 id="Recurrent-Neural-Network-RNN"><a href="#Recurrent-Neural-Network-RNN" class="headerlink" title="Recurrent Neural Network (RNN):"></a>Recurrent Neural Network (RNN):</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.klayers <span class="keyword">import</span> Embedding,LSTM</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.add(Embedding(<span class="number">20000</span>,<span class="number">128</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.add(LSTM(<span class="number">128</span>,dropout=<span class="number">0.2</span>,recurrent_dropout=<span class="number">0.2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.add(Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Inspect-Model"><a href="#Inspect-Model" class="headerlink" title="Inspect Model"></a>Inspect Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model output shape</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.output_shape</span><br><span class="line"><span class="comment"># Model summary representation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.summary()</span><br><span class="line"><span class="comment"># Model configuration</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.get_config()</span><br><span class="line"><span class="comment"># List all weight tensors in the model</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.get_weights()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Compile-Model"><a href="#Compile-Model" class="headerlink" title="Compile Model"></a>Compile Model</h3><p><b>MLP: Binary Classification</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line"> loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line"> metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<p><b>MLP: Multi-Class Classification</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line"> loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line"> metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<p><b>MLP: Regression</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>, metrics=[<span class="string">'mae'</span>])</span><br></pre></td></tr></table></figure>

<p><b>Recurrent Neural Network</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line"> optimizer=<span class="string">'adam'</span>,</span><br><span class="line"> metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.fit(x_train4,</span><br><span class="line"> y_train4,</span><br><span class="line"> batch_size=<span class="number">32</span>,</span><br><span class="line"> epochs=<span class="number">15</span>,</span><br><span class="line"> verbose=<span class="number">1</span>,</span><br><span class="line"> validation_data=(x_test4,y_test4))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Evaluate-Your-Model’s-Performance"><a href="#Evaluate-Your-Model’s-Performance" class="headerlink" title="Evaluate Your Model’s Performance"></a>Evaluate Your Model’s Performance</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>score = model3.evaluate(x_test,</span><br><span class="line"> y_test,</span><br><span class="line"> batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.predict(x_test4, batch_size=<span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.predict_classes(x_test4,batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Save-Reload-Models"><a href="#Save-Reload-Models" class="headerlink" title="Save/ Reload Models"></a>Save/ Reload Models</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.save(<span class="string">'model_file.h5'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_model = load_model(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h3><h4 id="Optimization-Parameters"><a href="#Optimization-Parameters" class="headerlink" title="Optimization Parameters:"></a>Optimization Parameters:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>opt = RMSprop(lr=<span class="number">0.0001</span>, decay=<span class="number">1e-6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model2.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=opt,</span><br><span class="line"> metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<h4 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping:"></a>Early Stopping:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>early_stopping_monitor = EarlyStopping(patience=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model3.fit(x_train4,</span><br><span class="line"> y_train4,</span><br><span class="line"> batch_size=<span class="number">32</span>,</span><br><span class="line"> epochs=<span class="number">15</span>,</span><br><span class="line"> validation_data=(x_test4,y_test4),</span><br><span class="line"> callbacks=[early_stopping_monitor])</span><br></pre></td></tr></table></figure>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/06/18/Python-for-Data-Science-Cheat-Sheet-with-Scikit-Learn/" itemprop="url">Python for Data Science Cheat Sheet with Scikit-Learn</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2019-06-18T20:33:19.000Z" itemprop="datePublished">Jun 18 2019</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            6 minutes read (About 860 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201906/20190618/0.png" alt=""></p>
<hr>
<h3 id="Intro-of-Scikit-Learn"><a href="#Intro-of-Scikit-Learn" class="headerlink" title="Intro of Scikit-Learn"></a>Intro of Scikit-Learn</h3><p>Scikit-learn is an open source Python library that implements a range of machine learning, data preprocessing, cross-validation and visualization algorithms using a unified interface.</p>
<p>The whole workflow of data science includes:</p>
<ul>
<li>Loading the data</li>
<li>Training and test data</li>
<li>Preprocessing ehe data</li>
<li>Create your model</li>
<li>Model fitting</li>
<li>Prediction</li>
<li>Evaluate your model’a performance</li>
<li>Tune your model</li>
</ul>
<p>Here I give you a basic example for reference.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors, datasets, preprocessing</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>iris = datasets.load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X, y = iris.data[:, :<span class="number">2</span>], iris.target</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">33</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = preprocessing.StandardScaler().fit(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train = scaler.transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_test = scaler.transform(X_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = knn.predict(X_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Loading-The-Data"><a href="#Loading-The-Data" class="headerlink" title="Loading The Data"></a>Loading The Data</h3><p>Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.random.random((<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.array([<span class="string">'M'</span>,<span class="string">'M'</span>,<span class="string">'F'</span>,<span class="string">'F'</span>,<span class="string">'M'</span>,<span class="string">'F'</span>,<span class="string">'M'</span>,<span class="string">'M'</span>,<span class="string">'F'</span>,<span class="string">'F'</span>,<span class="string">'F'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[X &lt; <span class="number">0.7</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Training-And-Test-Data"><a href="#Training-And-Test-Data" class="headerlink" title="Training And Test Data"></a>Training And Test Data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Preprocessing-The-Data"><a href="#Preprocessing-The-Data" class="headerlink" title="Preprocessing The Data"></a>Preprocessing The Data</h3><h4 id="Imputing-Missing-Values"><a href="#Imputing-Missing-Values" class="headerlink" title="Imputing Missing Values"></a>Imputing Missing Values</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp = Imputer(missing_values=<span class="number">0</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp.fit_transform(X_train)</span><br></pre></td></tr></table></figure>

<h4 id="Standardization"><a href="#Standardization" class="headerlink" title="Standardization"></a>Standardization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler().fit(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>standardized_X = scaler.transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>standardized_X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>

<h4 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Normalizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = Normalizer().fit(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalized_X = scaler.transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalized_X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>

<h4 id="Binarization"><a href="#Binarization" class="headerlink" title="Binarization"></a>Binarization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>binarizer = Binarizer(threshold=<span class="number">0.0</span>).fit(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>binary_X = binarizer.transform(X)</span><br></pre></td></tr></table></figure>

<h4 id="Encoding-Categorical-Features"><a href="#Encoding-Categorical-Features" class="headerlink" title="Encoding Categorical Features"></a>Encoding Categorical Features</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc = LabelEncoder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = enc.fit_transform(y)</span><br></pre></td></tr></table></figure>

<h4 id="Generating-Polynomial-Features"><a href="#Generating-Polynomial-Features" class="headerlink" title="Generating Polynomial Features"></a>Generating Polynomial Features</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly = PolynomialFeatures(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly.fit_transform(X)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Create-Your-Model"><a href="#Create-Your-Model" class="headerlink" title="Create Your Model"></a>Create Your Model</h3><h4 id="Supervised-Learning-Estimators"><a href="#Supervised-Learning-Estimators" class="headerlink" title="Supervised Learning Estimators"></a>Supervised Learning Estimators</h4><p><b>Linear Regression</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lr = LinearRegression(normalize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><b>Support Vector Machines (SVM)</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>svc = SVC(kernel=<span class="string">'linear'</span>)</span><br></pre></td></tr></table></figure>

<p><b>Naive Bayes</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gnb = GaussianNB()</span><br></pre></td></tr></table></figure>

<p><b>KNN</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Unsupervised-Learning-Estimators"><a href="#Unsupervised-Learning-Estimators" class="headerlink" title="Unsupervised Learning Estimators"></a>Unsupervised Learning Estimators</h4><p><b>Principal Component Analysis (PCA)</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pca = PCA(n_components=<span class="number">0.95</span>)</span><br></pre></td></tr></table></figure>

<p><b>K Means</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>k_means = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Model-Fitting"><a href="#Model-Fitting" class="headerlink" title="Model Fitting"></a>Model Fitting</h3><h4 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised learning"></a>Supervised learning</h4><p>Fit the model to the data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lr.fit(X, y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>svc.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>

<h4 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h4><p>Fit the model to the data.<br>Fit to data, then transform it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>k_means.fit(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pca_model = pca.fit_transform(X_train)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h3><h4 id="Supervised-Estimators"><a href="#Supervised-Estimators" class="headerlink" title="Supervised Estimators"></a>Supervised Estimators</h4><p>Predict labels. Predict labels. Estimate probability of a label.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = svc.predict(np.random.random((<span class="number">2</span>,<span class="number">5</span>)))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = lr.predict(X_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = knn.predict_proba(X_test)</span><br></pre></td></tr></table></figure>

<h4 id="Unsupervised-Estimators"><a href="#Unsupervised-Estimators" class="headerlink" title="Unsupervised Estimators"></a>Unsupervised Estimators</h4><p>Predict labels in clustering algos.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = k_means.predict(X_test)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Evaluate-Your-Model’s-Performance"><a href="#Evaluate-Your-Model’s-Performance" class="headerlink" title="Evaluate Your Model’s Performance"></a>Evaluate Your Model’s Performance</h3><h4 id="Classification-Metrics"><a href="#Classification-Metrics" class="headerlink" title="Classification Metrics"></a>Classification Metrics</h4><p><b>Accuracy Score</b></p>
<p>Estimator score method. Metric scoring functions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>knn.score(X_test, y_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure>

<p><b>Classification Report</b></p>
<p>Precision, recall, f1-score and support.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure>

<p><b>Confusion Matrix</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure>

<h4 id="Regression-Metrics"><a href="#Regression-Metrics" class="headerlink" title="Regression Metrics"></a>Regression Metrics</h4><p><b>Mean Absolute Error</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_true = [<span class="number">3</span>, <span class="number">-0.5</span>, <span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mean_absolute_error(y_true, y_pred)</span><br></pre></td></tr></table></figure>

<p><b>Mean Squared Error</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mean_squared_error(y_test, y_pred)</span><br></pre></td></tr></table></figure>

<p><b>R² Score</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r2_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>

<h4 id="Clustering-Metrics"><a href="#Clustering-Metrics" class="headerlink" title="Clustering Metrics"></a>Clustering Metrics</h4><p><b>Adjusted Rand Index</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> adjusted_rand_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>adjusted_rand_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>

<p><b>Homogeneity</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> homogeneity_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>homogeneity_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>

<p><b>V-measure</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> v_measure_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>metrics.v_measure_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>

<h4 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross-Validation"></a>Cross-Validation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(cross_val_score(knn, X_train, y_train, cv=<span class="number">4</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(cross_val_score(lr, X, y, cv=<span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<h3 id="Tune-Your-Model"><a href="#Tune-Your-Model" class="headerlink" title="Tune Your Model"></a>Tune Your Model</h3><h4 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>params = &#123;<span class="string">"n_neighbors"</span>: np.arange(<span class="number">1</span>,<span class="number">3</span>), <span class="string">"metric"</span>: [<span class="string">"euclidean"</span>, <span class="string">"cityblock"</span>]&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid = GridSearchCV(estimator=knn, param_grid=params)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(grid.best_score_)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(grid.best_estimator_.n_neighbors)</span><br></pre></td></tr></table></figure>

<h4 id="Randomized-Parameter-Optimization"><a href="#Randomized-Parameter-Optimization" class="headerlink" title="Randomized Parameter Optimization"></a>Randomized Parameter Optimization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>params = &#123;<span class="string">"n_neighbors"</span>: range(<span class="number">1</span>,<span class="number">5</span>), <span class="string">"weights"</span>: [<span class="string">"uniform"</span>, <span class="string">"distance"</span>]&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rsearch = RandomizedSearchCV(estimator=knn,</span><br><span class="line">                                param_distributions=params,</span><br><span class="line">                                cv=<span class="number">4</span>, n_iter=<span class="number">8</span>,random_state=<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rsearch.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(rsearch.best_score_)</span><br></pre></td></tr></table></figure>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/11/Install-MongoDB-on-Mac/" itemprop="url">How to Install and Run MongoDB on Mac OS</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2019-03-11T20:33:19.000Z" itemprop="datePublished">Mar 11 2019</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/System/">System</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            3 minutes read (About 407 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2019/201903/20190316/0.png" alt=""></p>
<p>MongoDB is a document database which belongs to a family of databases called NoSQL - not only SQL. In MongoDB, records are documents which behave a lot like JSON objects in JavaScript. Values in documents can be looked up by their field’s key. Documents can have some fields/keys and not others, which makes Mongo extremely flexible. This is much different than SQL databases like MySQL, where fields correspond to columns in a table and individual records correspond to rows.</p>
<h3 id="Install-and-Run-MongoDB-with-Homebrew"><a href="#Install-and-Run-MongoDB-with-Homebrew" class="headerlink" title="Install and Run MongoDB with Homebrew"></a>Install and Run MongoDB with Homebrew</h3><ul>
<li><p>Make sure Homebrew already installed on Mac (Homebrew is a package manager for the Mac – it makes installing most open source software).</p>
</li>
<li><p>Open the Mac terminal application and type <b>brew update</b>, then type <b>brew install mongodb</b></p>
</li>
<li><p>After MongoDB is downloaded, create a directory to store MongoDB data files, type <b>mkdir -p /data/db</b></p>
</li>
<li><p>Make sure the directory has the right permissions:</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> sudo chown -R `id -un` /data/db</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="comment"># Enter your psd</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>Run the Mongo daemon by typing <b>mongod</b> in your terminal window.</p>
</li>
<li><p>Run the Mongo shell by typing <b>mongo</b> in another terminal window.</p>
</li>
<li><p>To exit the Mongo shell run <b>quit()</b>, to stop the Mongo daemon hit <b>ctrl+c</b></p>
</li>
</ul>
<hr>
<h4 id="Install-and-Run-MongoDB-by-Downloading-it-Manually"><a href="#Install-and-Run-MongoDB-by-Downloading-it-Manually" class="headerlink" title="Install and Run MongoDB by Downloading it Manually"></a>Install and Run MongoDB by Downloading it Manually</h4><ul>
<li><p>1) Go to the MongoDB <a href="https://www.mongodb.com/" target="_blank" rel="noopener">website</a> and download the correct version of MongoDB.</p>
</li>
<li><p>2) After downloading MongoDB, move the gzipped tar file to the folder where you want MongoDB installed by typing commands like these in your terminal:</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="built_in">cd</span> Downloads</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> mv mongodb-macos-x86_64-4.2.2.tgz ~/</span></span><br></pre></td></tr></table></figure>

<ul>
<li>3) Extract MongoDB from the downloaded archive and change the name of the directory to something more concise by following commands:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="built_in">cd</span> ~/ &gt; tar -zxvf mongodb-macos-x86_64-4.2.2.tgz</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> mv mongodb-macos-x86_64-4.2.2 mongodb</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>4) Create a directory to store MongoDB data files, type <b>mkdir -p /data/db</b></p>
</li>
<li><p>5) Make sure the directory has the right permissions:</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> sudo chown -R `id -un` /data/db</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="comment"># Enter your psd</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>6) If you can’t create <b>/data/db</b> directory, you can also use other directory to replace it by running command like this:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/mongodb/bin/mongod --dbpath ~/mongodb/data</span><br></pre></td></tr></table></figure>

<p>then jump to step 8.</p>
<ul>
<li><p>7) Run the Mongo daemon by typing <b>~/mongodb/bin/mongod</b> in your terminal window.</p>
</li>
<li><p>8) Run the Mongo shell by typing <b>~/mongodb/bin/mongo</b> in another terminal window.</p>
</li>
<li><p>9) To exit the Mongo shell run <b>quit()</b>, to stop the Mongo daemon hit <b>ctrl+c</b></p>
</li>
</ul>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/01/28/HowtoTransferFiles/" itemprop="url">How to Transfer Files &amp; Connect to Jupyter Notebook Between Azure Virtual Machines and Local Systems</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2019-01-28T19:02:39.000Z" itemprop="datePublished">Jan 28 2019</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/System/">System</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 minutes read (About 334 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Recently, cloud platforms are popular among various companies and conferences. Virtual Machines are one of the main applications provided by cloud platforms. For instance, Microsoft Azure offers Data Science Virtual Machines. Even though we have cloud platforms do us a favour to process hundreds and thousands of data remotely, I do need to upload files or download results from remote server. So how to interact between remote cloud servers and local systems? We’ll take Azure Virtual Machines as a case study.</p>
<h3 id="Transfer-Files"><a href="#Transfer-Files" class="headerlink" title="Transfer Files"></a>Transfer Files</h3><ul>
<li>Copy a Local File to a Azure Virtual Machine with the scp Command:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp /local/path/file.txt azure_username@azure_host_ip:/remote/directory</span><br></pre></td></tr></table></figure>

<ul>
<li>If SSH on the remote host is listening on a port other than the default 22, then you can specify a port using the -P argument:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P 1234 /local/path/file.txt azure_username@azure_host_ip:/remote/directory</span><br></pre></td></tr></table></figure>

<ul>
<li>To copy a directory from a local to remote system, we can use the -r option:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /local/directory azure_username@azure_host_ip:/remote/directory</span><br></pre></td></tr></table></figure>

<ul>
<li>Copy a Remote File to a Local System using the scp command:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp azure_username@azure_host_ip:/remote/file.txt /local/directory</span><br></pre></td></tr></table></figure>

<ul>
<li>Copy a File Between Two Azure Virtual Machines using the scp Command:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp azure_username1@azure_host_ip1:/directory/file.txt azure_username2@azure_host_ip2:/directory</span><br></pre></td></tr></table></figure>

<h3 id="Connect-to-Azure-Virtual-Machine"><a href="#Connect-to-Azure-Virtual-Machine" class="headerlink" title="Connect to Azure Virtual Machine"></a>Connect to Azure Virtual Machine</h3><p>Here, we can use SSH command to connect to the Azure Virtual Machine from local path.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh azure_username@azure_host_ip</span><br></pre></td></tr></table></figure>

<h3 id="Connect-to-Jupyter-Notebook-application"><a href="#Connect-to-Jupyter-Notebook-application" class="headerlink" title="Connect to Jupyter Notebook application"></a>Connect to Jupyter Notebook application</h3><p>Here, we use SSH command to connect to the Jupyter Notebook Application.</p>
<ul>
<li>First, install and start the Jupyter Notebook Application in the Azure Virtual Machines, then open the local terminal and input the following command:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 8000:localhost:8888 azure_username@azure_host_ip</span><br></pre></td></tr></table></figure>

<ul>
<li>Next, entering to the Jupyter Notebook Application using local browser with the url ‘localhost:8000’, and input the Jupyter notebook token from Azure Virtual Machines.</li>
</ul>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2018/12/24/AwesomeProgramminSkillsforPythonUser/" itemprop="url">Awesome Programming Skills for Python User</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2018-12-24T23:22:38.000Z" itemprop="datePublished">Dec 24 2018</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Programming/">Programming</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 minutes read (About 305 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Here are some awesome programming skills shared for Python users. Hopefully it’s useful to you.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># most frequent element in  a list</span></span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">print(max(set(a), key = a.count))</span><br><span class="line"></span><br><span class="line"><span class="comment"># use Counter</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">cnt = Counter(a)</span><br><span class="line">print(cnt.most_common(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># check two strings have same characters</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">str1 = <span class="string">"I see him"</span></span><br><span class="line">str2 = <span class="string">"him I see"</span></span><br><span class="line"></span><br><span class="line">print(Counter(str1) == Counter(str2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># reverse string</span></span><br><span class="line"></span><br><span class="line">b = <span class="string">'abcdefghijklmnopqrstuvwxyz'</span></span><br><span class="line">print(b[::<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> char  <span class="keyword">in</span> reversed(b):</span><br><span class="line">	print(char)</span><br><span class="line"></span><br><span class="line">num = <span class="number">123456789</span></span><br><span class="line">print(int(str(num)[::<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># transpose 2d array</span></span><br><span class="line"></span><br><span class="line">original = [[<span class="string">'a'</span>,<span class="string">'b'</span>], [<span class="string">'1'</span>,<span class="string">'2'</span>],[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">transposed = zip(*original)</span><br><span class="line">print(list(transposed))</span><br><span class="line"></span><br><span class="line"><span class="comment"># call different functions with same arguments</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">product</span><span class="params">(a,b)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> a*b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a,b)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> a+b</span><br><span class="line"></span><br><span class="line">x = <span class="literal">True</span></span><br><span class="line">print((product <span class="keyword">if</span> x <span class="keyword">else</span> add)(<span class="number">5</span>,<span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># a shallow copy</span></span><br><span class="line">e = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">d = e</span><br><span class="line">d[<span class="number">0</span>] = <span class="number">10</span></span><br><span class="line">print(d,e)</span><br><span class="line"></span><br><span class="line">d2 = e[:]</span><br><span class="line">d2[<span class="number">0</span>] = <span class="number">11</span></span><br><span class="line">print(d2,e)</span><br><span class="line"></span><br><span class="line"><span class="comment"># deep copy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line">f = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">f2 = deepcopy(f)</span><br><span class="line">f[<span class="number">0</span>] = [<span class="string">'x'</span>,<span class="string">'y'</span>]</span><br><span class="line">print(f,f2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort a dict by its value with built-in sorted func</span></span><br><span class="line"></span><br><span class="line">g = &#123;<span class="string">'apple'</span>:<span class="number">50</span>, <span class="string">'banana'</span>:<span class="number">25</span>, <span class="string">'orange'</span>: <span class="number">20</span>, <span class="string">'watermelon'</span>:<span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line">print(sorted(g.items(), key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># use itemgetter instead of a lambda</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"></span><br><span class="line">print(sorted(g.items(), key=itemgetter(<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort dict by value</span></span><br><span class="line"></span><br><span class="line">print(sorted(g, key = g.get))</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge dict</span></span><br><span class="line"></span><br><span class="line">d1 = &#123;<span class="string">'x'</span>:<span class="number">1</span>&#125;</span><br><span class="line">d2 = &#123;<span class="string">'y'</span>:<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(&#123;**d1, **d2&#125;) <span class="comment">#python 3.5</span></span><br><span class="line"></span><br><span class="line">print(dict(d1.items() | d2.items())) <span class="comment">#python 3.5</span></span><br><span class="line"></span><br><span class="line">d1.update(d2) <span class="comment">#python 3.5    </span></span><br><span class="line">print(d1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert list to comma separated string</span></span><br><span class="line"></span><br><span class="line">data = [<span class="number">1</span>,<span class="string">'re'</span>, <span class="number">3</span>, <span class="string">'fa'</span>, <span class="number">5</span>]</span><br><span class="line">print(<span class="string">','</span>.join(map(str, data)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># find index of min/max element</span></span><br><span class="line"></span><br><span class="line">h = [<span class="number">40</span>, <span class="number">30</span>, <span class="number">20</span>, <span class="number">10</span>, <span class="number">50</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> min(range(len(lst)), key = lst.__getitem__)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> max(range(len(lst)), key = lst.__getitem__)</span><br><span class="line"></span><br><span class="line">print(minIndex(h))</span><br><span class="line">print(maxIndex(h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove duplicate items from list</span></span><br><span class="line"></span><br><span class="line">i = [<span class="number">6</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">print(list(set(i)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line">print(list(OrderedDict.fromkeys(i).keys()))</span><br></pre></td></tr></table></figure>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2018/11/21/WhatIsBaggingandHowDoesItWork/" itemprop="url">What Is Bagging and How Does It Work?</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2018-11-21T18:42:41.000Z" itemprop="datePublished">Nov 21 2018</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 minutes read (About 226 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Bagging is a technique used to reduce the variance of our predictions by combining the result of multiple classifiers modeled on different sub-samples of the same dataset. The following figure will make it clearer.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201811/20181121/0.png" alt=""></p>
<h3 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h3><p>The steps followed in bagging are:</p>
<p><b>1) Create Multiple DataSets</b></p>
<ul>
<li>Sampling is done with replacement on the original data and new datasets are formed.</li>
<li>The new data sets can have a fraction of the columns as well as rows, which are generally hyper-parameters in a bagging model.</li>
<li>Taking row and column fractions less than 1 helps in making robust models, less prone to overfitting.</li>
</ul>
<p><b>2) Build Multiple Classifiers</b></p>
<ul>
<li>Classifiers are built on each data set.</li>
<li>Generally the same classifier is modeled on each dataset and predictions are made.</li>
</ul>
<p><b>3) Combine Classifiers</b></p>
<ul>
<li>The predictions of all the classifiers are combined using a mean, median or mode value depending on the problem at hand.</li>
<li>The combined values are generally more robust than a single model.</li>
</ul>
<p>Note that, here the number of models built is not a hyper-parameters. Higher number of models are always better or may give similar performance than lower numbers. It can be theoretically shown that the variance of the combined predictions are reduced to 1/n (n: number of classifiers) of the original variance, under some assumptions.</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2018/10/10/WhatAreEnsembleMethodsinTreeBasedModelling/" itemprop="url">What Are Ensemble Methods in Tree Based Modelling?</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2018-10-10T19:33:00.000Z" itemprop="datePublished">Oct 10 2018</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 minutes read (About 242 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>The literary meaning of word ‘ensemble’ is group. Ensemble methods involve group of predictive models to achieve a better accuracy and model stability. Ensemble methods are known to impart supreme boost to tree based models.</p>
<h3 id="Bias-amp-Variance"><a href="#Bias-amp-Variance" class="headerlink" title="Bias &amp; Variance"></a>Bias &amp; Variance</h3><p>Like every other model, a tree based model also suffers from the plague of bias and variance. Bias means, ‘how much on an average are the predicted values different from the actual value.’ Variance means, ‘how different will the predictions of the model be at the same point if different samples are taken from the same population’.</p>
<p>You build a small tree and you will get a model with low variance and high bias. How do you manage to balance the trade off between bias and variance ?</p>
<p>Normally, as you increase the complexity of your model, you will see a reduction in prediction error due to lower bias in the model. As you continue to make your model more complex, you end up over-fitting your model and your model will start suffering from high variance.</p>
<p>A champion model should maintain a balance between these two types of errors. This is known as the trade-off management of bias-variance errors. Ensemble learning is one way to execute this trade off analysis.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201810/20181010/0.png" alt=""></p>
<p>Some of the commonly used ensemble methods include: Bagging, Boosting and Stacking.</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2018/08/07/DecisionTreesImplementationinRandPython/" itemprop="url">Decision Trees Implementation in R and Python</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2018-08-07T06:58:03.000Z" itemprop="datePublished">Aug 7 2018</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 minutes read (About 250 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>For R users and Python users, decision tree is quite easy to implement. Let’s quickly look at the set of codes which can get you started with this algorithm. For ease of use, I’ve shared standard codes where you’ll need to replace your dataset name and variables to get started.</p>
<h3 id="R"><a href="#R" class="headerlink" title="R"></a>R</h3><p>For R users, there are multiple packages available to implement decision tree such as ctree, rpart, tree etc.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">library</span>(rpart)</span><br><span class="line">&gt; x &lt;- cbind(x_train,y_train)</span><br><span class="line"><span class="comment"># grow tree</span></span><br><span class="line">&gt; fit &lt;- rpart(y_train ~ ., data = x,method=<span class="string">"class"</span>)</span><br><span class="line">&gt; summary(fit)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">&gt; predicted= predict(fit,x_test)</span><br><span class="line">&gt; <span class="keyword">library</span>(rpart)</span><br><span class="line">&gt; x &lt;- cbind(x_train,y_train)</span><br><span class="line"><span class="comment"># grow tree</span></span><br><span class="line">&gt; fit &lt;- rpart(y_train ~ ., data = x,method=<span class="string">"class"</span>)</span><br><span class="line">&gt; summary(fit)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">&gt; predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>

<p>In the code above:</p>
<ul>
<li>y_train – represents dependent variable.</li>
<li>x_train – represents independent variable</li>
<li>x – represents training data.</li>
</ul>
<h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>For Python users, below is the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import necessary libraries like pandas, numpy...</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create tree object</span></span><br><span class="line"><span class="comment"># for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  </span></span><br><span class="line">model = tree.DecisionTreeClassifier(criterion=<span class="string">'gini'</span>)</span><br><span class="line"><span class="comment"># model = tree.DecisionTreeRegressor() for regression</span></span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2018/07/27/AreTreeBasedModelsBetterThanLinearModels/" itemprop="url">Are Tree Based Models Better than Linear Models?</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2018-07-27T16:44:50.000Z" itemprop="datePublished">Jul 27 2018</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            a minute read (About 163 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>“If I can use logistic regression for classification problems and linear regression for regression problems, why is there a need to use trees”? Many of us have this question. And, this is a valid one too.</p>
<h3 id="How-to-choose-a-proper-algorithms"><a href="#How-to-choose-a-proper-algorithms" class="headerlink" title="How to choose a proper algorithms?"></a>How to choose a proper algorithms?</h3><p>Actually, you can use any algorithm. It is dependent on the type of problem you are solving. Let’s look at some key factors which will help you to decide which algorithm to use:</p>
<p>1) If the relationship between dependent &amp; independent variable is well approximated by a linear model, linear regression will outperform tree based model.</p>
<p>2) If there is a high non-linearity &amp; complex relationship between dependent &amp; independent variables, a tree model will outperform a classical regression method.</p>
<p>3) If you need to build a model which is easy to explain to people, a decision tree model will always do better than a linear model. Decision tree models are even simpler to interpret than linear regression!</p>

    
    </div>
    
    
</article>




    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous">
        <a href="/">Prev</a>
    </div>
    <div class="pagination-next">
        <a href="/page/3/">Next</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link" href="/">1</a></li>
        
        <li><a class="pagination-link is-current" href="/page/2/">2</a></li>
        
        <li><a class="pagination-link" href="/page/3/">3</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 Stephen Cheng&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery > p > .gallery-item').unwrap();
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>