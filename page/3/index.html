<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Stephen Cheng</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Stephen Cheng">
<meta property="og:url" content="https://stephen-cheng.github.io/page/3/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Stephen Cheng">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Stephen Cheng" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Stephen Cheng</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">AI | Tech</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/about">About</a>
        
          <a class="main-nav-link" href="/contact">Contact</a>
        
          <a class="main-nav-link" href="https://www.instagram.com" target="_blank" rel="noopener">Instagram</a>
        
          <a class="main-nav-link" href="https://www.linkedin.com" target="_blank" rel="noopener">LinkedIn</a>
        
          <a class="main-nav-link" href="https://www.facebook.com" target="_blank" rel="noopener">Facebook</a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://stephen-cheng.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/06/WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees/" class="article-date">
  <time datetime="2018-06-06T14:37:33.000Z" itemprop="datePublished">2018-06-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/06/WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees/">What Are The Key Parameters of Tree Modelling and How to Avoid Over-fitting in Decision Trees?</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Steven Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Overfitting is one of the key challenges faced while modeling decision trees. If there is no limit set of a decision tree, it will give you 100% accuracy on training set because in the worse case it will end up making 1 leaf for each observation. Thus, preventing overfitting is pivotal while modeling a decision tree and it can be done in 2 ways:</p>
<p>1) Setting constraints on tree size.<br>2) Tree pruning.</p>
<p>Let’s discuss both of these briefly.</p>
<h3 id="Setting-Constraints-on-Tree-Size"><a href="#Setting-Constraints-on-Tree-Size" class="headerlink" title="Setting Constraints on Tree Size"></a>Setting Constraints on Tree Size</h3><p>This can be done by using various parameters which are used to define a tree. First, let‘s look at the general structure of a decision tree.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201806/20180606/0.png" alt=""></p>
<p>The parameters used for defining a tree are further explained below. The parameters described below are irrespective of tool. It is important to understand the role of parameters used in tree modeling. These parameters are available in R &amp; Python.</p>
<h4><center>Minimum samples for a node split</center></h4>

<p>1) Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.<br>2) Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.<br>3) Too high values can lead to under-fitting hence, it should be tuned using CV.</p>
<h4><center>Minimum samples for a terminal node (leaf)</center></h4>

<p>1) Defines the minimum samples (or observations) required in a terminal node or leaf.<br>2) Used to control over-fitting similar to min_samples_split.<br>3) Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.</p>
<h4><center>Maximum depth of tree (vertical depth)</center></h4>

<p>1) The maximum depth of a tree.<br>2) Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.<br>3) Should be tuned using CV.</p>
<h4><center>Maximum number of terminal nodes</center></h4>

<p>1) The maximum number of terminal nodes or leaves in a tree.<br>2) Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.</p>
<h4><center>Maximum features to consider for split</center></h4>

<p>1) The number of features to consider while searching for a best split. These will be randomly selected.<br>2) As a thumb-rule, square root of the total number of features works great but we should check up to 30-40% of the total number of features.<br>3) Higher values can lead to over-fitting but depends on case to case.</p>
<h3 id="Tree-Pruning"><a href="#Tree-Pruning" class="headerlink" title="Tree Pruning"></a>Tree Pruning</h3><p>As discussed earlier, the technique of setting constraint is a greedy-approach. In other words, it will check for the best split instantaneously and move forward until one of the specified stopping condition is reached. Let’s consider the following case when you’re driving.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201806/20180606/1.png" alt=""></p>
<p>There are 2 lanes:</p>
<p>1) A lane with cars moving at 80km/h.<br>2) A lane with trucks moving at 30km/h.</p>
<p>At this instant, you are the yellow car and you have 2 choices:</p>
<p>1) Take a left and overtake the other 2 cars quickly.<br>2) Keep moving in the present lane.</p>
<p>Let’s analyze these choice. In the former choice, you’ll immediately overtake the car ahead and reach behind the truck and start moving at 30 km/h, looking for an opportunity to move back right. All cars originally behind you move ahead in the meanwhile. This would be the optimum choice if your objective is to maximize the distance covered in next say 10 seconds. In the later choice, you sale through at same speed, cross trucks and then overtake maybe depending on situation ahead. Greedy you!</p>
<p>This is exactly the difference between normal decision tree &amp; pruning. A decision tree with constraints won’t see the truck ahead and adopt a greedy approach by taking a left. On the other hand if we use pruning, we in effect look at a few steps ahead and make a choice.</p>
<h4><center>How to prune?</center></h4>

<p>So we know pruning is better. But how to implement it in decision tree? The idea is simple.</p>
<p>1) We first make the decision tree to a large depth.<br>2) Then we start at the bottom and start removing leaves which are giving us negative returns when compared from the top.<br>3) Suppose a split is giving us a gain of say -10 (loss of 10) and then the next split on that gives us a gain of 20. A simple decision tree will stop at step 1 but in pruning, we will see that the overall gain is +10 and keep both leaves.</p>
<h4><center>Note</center></h4>

<p>Note that sklearn’s decision tree classifier does not currently support pruning. Advanced packages like xgboost have adopted tree pruning in their implementation. But the library rpart in R, provides a function to prune. Good for R users!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2018/06/06/WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees/" data-id="clpllv7w60015t4xvb1wq05e8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Overfitting/" rel="tag">Overfitting</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tree/" rel="tag">Tree</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-MergeSort" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/19/MergeSort/" class="article-date">
  <time datetime="2018-05-19T04:23:47.000Z" itemprop="datePublished">2018-05-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/19/MergeSort/">Merge Sort</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Steven Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>In computer science, merge sort (also commonly spelled mergesort) is an efficient, general-purpose, comparison-based sorting algorithm. Most implementations produce a stable sort, which means that the implementation preserves the input order of equal elements in the sorted output. Mergesort is a divide and conquer algorithm that was invented by John von Neumann in 1945.</p>
<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Conceptually, a merge sort works as follows:</p>
<p>1) Divide the unsorted list into n sublists, each containing 1 element (a list of 1 element is considered sorted).</p>
<p>2) Repeatedly merge sublists to produce new sorted sublists until there is only 1 sublist remaining. This will be the sorted list.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201805/20180519/0.gif" alt=""></p>
<h3 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h3><p><b>Class:</b> Sorting algorithm<br><b>Data structure:</b> Array<br><b>Worst-case performance:</b> O(n log n)<br><b>Best-case performance:<b/> O(n log n) typical, O(n) natural variant<br><b>Average performance:</b> O(n log n)<br><b>Worst-case space complexity:&lt;/1b&gt; О(n) total, O(n) auxiliary</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201805/20180519/1.gif" alt=""></p>
<p>Figure above, first divide the list into the smallest unit (1 element), then compare each element with the adjacent list to sort and merge the two adjacent lists. Finally all the elements are sorted and merged.</p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>Python</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(lst) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> lst</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">        merged,left,right = deque(),deque(left),deque(right)</span><br><span class="line">        <span class="keyword">while</span> left <span class="keyword">and</span> right:</span><br><span class="line">            <span class="comment"># deque popleft is also O(1)</span></span><br><span class="line">            merged.append(left.popleft() <span class="keyword">if</span> left[<span class="number">0</span>] &lt;= right[<span class="number">0</span>] <span class="keyword">else</span> right.popleft())  </span><br><span class="line">        merged.extend(right <span class="keyword">if</span> right <span class="keyword">else</span> left)</span><br><span class="line">        <span class="keyword">return</span> list(merged)</span><br><span class="line">    middle = int(len(lst) // <span class="number">2</span>)</span><br><span class="line">    left = merge_sort(lst[:middle])</span><br><span class="line">    right = merge_sort(lst[middle:])</span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2018/05/19/MergeSort/" data-id="clpllv7vi000gt4xv5hqq3bkg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Merge/" rel="tag">Merge</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Sort/" rel="tag">Sort</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RegressionTreesvs-ClassificationTrees" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/06/RegressionTreesvs-ClassificationTrees/" class="article-date">
  <time datetime="2018-05-06T13:52:39.000Z" itemprop="datePublished">2018-05-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/06/RegressionTreesvs-ClassificationTrees/">Regression Trees vs. Classification Trees</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Steven Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>We all know that the terminal nodes (or leaves) lies at the bottom of the decision tree. This means that decision trees are typically drawn upside down such that leaves are the bottom &amp; roots are the tops (shown below).</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201805/20180506/0.png" alt=""></p>
<p>Both the trees work almost similar to each other, let’s look at the primary differences &amp; similarity between classification and regression trees:</p>
<p>1) Regression trees are used when dependent variable is continuous. Classification trees are used when dependent variable is categorical.</p>
<p>2) In case of regression tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.</p>
<p>3) In case of classification tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value.</p>
<p>4) Both the trees divide the predictor space (independent variables) into distinct and non-overlapping regions. For the sake of simplicity, you can think of these regions as high dimensional boxes or boxes.</p>
<p>5) Both the trees follow a top-down greedy approach known as recursive binary splitting. We call it as ‘top-down’ because it begins from the top of tree when all the observations are available in a single region and successively splits the predictor space into two new branches down the tree. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree.</p>
<p>6) This splitting process is continued until a user defined stopping criteria is reached. For example: we can tell the algorithm to stop once the number of observations per node becomes less than 50.</p>
<p>7) In both the cases, the splitting process results in fully grown trees until the stopping criteria is reached. But, the fully grown tree is likely to overfit data, leading to poor accuracy on unseen data. This bring ‘pruning’. Pruning is one of the technique used tackle overfitting.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2018/05/06/RegressionTreesvs-ClassificationTrees/" data-id="clpllv7vw000tt4xvf8d75fby" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Classification/" rel="tag">Classification</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Regression/" rel="tag">Regression</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-LevenshteinDistance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/18/LevenshteinDistance/" class="article-date">
  <time datetime="2018-04-18T22:09:03.000Z" itemprop="datePublished">2018-04-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/18/LevenshteinDistance/">Levenshtein Distance</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Steven Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is named after Vladimir Levenshtein, who considered this distance in 1965.</p>
<p>Levenshtein distance may also be referred to as edit distance, although that term may also denote a larger family of distance metrics.</p>
<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Mathematically, the Levenshtein distance between two strings a,b (of length |a| and |b| respectively) is given by lev_a,b(|a|,|b|)</p>
<p>where</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201804/20180418/0.png" alt=""></p>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>The Levenshtein distance between “kitten” and “sitting” is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits:</p>
<p>1) kitten → sitten (substitution of “s” for “k”)<br>2) sitten → sittin (substitution of “i” for “e”)<br>3) sittin → sitting (insertion of “g” at the end)</p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p><b>Python</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Levenshtein distance for measuring string difference</span></span><br><span class="line"><span class="string">Created on Apr. 6th, 2017</span></span><br><span class="line"><span class="string">@author: Stephen</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">levenshtein_distance</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">le_dis</span><span class="params">(self, input_x, input_y)</span>:</span></span><br><span class="line">        xlen = len(input_x) + <span class="number">1</span></span><br><span class="line">        ylen = len(input_y) + <span class="number">1</span></span><br><span class="line">        dp = np.zeros(shape=(xlen, ylen), dtype=int)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, xlen):</span><br><span class="line">            dp[i][<span class="number">0</span>] = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, ylen):</span><br><span class="line">            dp[<span class="number">0</span>][j] = j</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, xlen):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, ylen):</span><br><span class="line">                <span class="keyword">if</span> input_x[i - <span class="number">1</span>] == input_y[j - <span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="number">1</span> + min(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>], dp[i - <span class="number">1</span>][j - <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[xlen - <span class="number">1</span>][ylen - <span class="number">1</span>]</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    ld = levenshtein_distance()</span><br><span class="line">    print(ld.le_dis(<span class="string">'abcd'</span>, <span class="string">'abd'</span>)) <span class="comment"># print out 1</span></span><br><span class="line">    print(ld.le_dis(<span class="string">'ace'</span>, <span class="string">'abcd'</span>)) <span class="comment"># print out 2</span></span><br><span class="line">    print(ld.le_dis(<span class="string">'hello world'</span>, <span class="string">'hey word'</span>)) <span class="comment"># print out 4</span></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2018/04/18/LevenshteinDistance/" data-id="clpllv7vh000ft4xv9wyj7cwb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Distance/" rel="tag">Distance</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Levenshtein/" rel="tag">Levenshtein</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-WhatIsADecisionTreeHowDoesItWork" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/15/WhatIsADecisionTreeHowDoesItWork/" class="article-date">
  <time datetime="2018-04-15T22:09:03.000Z" itemprop="datePublished">2018-04-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/15/WhatIsADecisionTreeHowDoesItWork/">What Is A Decision Tree ? How Does It Work ?</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, the population or sample are split into two or more homogeneous sets (or sub-populations) based on most significant splitter differentiator in input variables.</p>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Say we have a sample of 30 students with three variables: Gender (Boy/Girl), Class(IX/X) and Height (5 to 6 ft). 15 out of these 30 play cricket in leisure time. Now, we want to create a model to predict who will play cricket during leisure period? In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three.</p>
<p>This is where decision tree helps, it will segregate the students based on all values of three variables and identify the variable, which creates the best homogeneous sets of students (which are heterogeneous to each other). In the snapshot below, you can see that variable Gender is able to identify best homogeneous sets compared to the other two variables.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201804/20180415/0.png" alt=""></p>
<p>As mentioned above, decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. Now the question which arises is, how does it identify the variable and the split? To do this, decision tree uses various algorithms, which we will shall discuss in the following section.</p>
<h3 id="Types-of-Decision-Trees"><a href="#Types-of-Decision-Trees" class="headerlink" title="Types of Decision Trees"></a>Types of Decision Trees</h3><p>Types of decision tree are based on the type of target variable we have. It can be of two types:</p>
<p><b>1) Categorical Variable Decision Tree</b></p>
<p>This type of Decision Tree which has categorical target variable then it called as categorical variable decision tree. E.g., in above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO.</p>
<p><b>2) Continuous Variable Decision Tree</b></p>
<p>This type of Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree.</p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p>Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/no). Here we know that income of a customer is a significant variable but insurance company does not have income details for all customers. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, age and various other variables. In this case, we are predicting values for continuous variable.</p>
<h3 id="Important-Terminology"><a href="#Important-Terminology" class="headerlink" title="Important Terminology"></a>Important Terminology</h3><p>Let’s look at the basic terminology used with Decision trees:</p>
<p><b>1) Root Node</b></p>
<p>It represents entire population or sample and this further gets divided into two or more homogeneous sets.</p>
<p><b>2) Splitting</b></p>
<p>It is a process of dividing a node into two or more sub-nodes.</p>
<p><b>3) Decision Node</b></p>
<p>When a sub-node splits into further sub-nodes, then it is called decision node.</p>
<p><b>4) Leaf/Terminal Node</b></p>
<p>Nodes do not split is called Leaf or Terminal node.</p>
<p><b>5) Pruning</b><br>When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting.</p>
<p><b>6) Branch/Sub-Tree</b></p>
<p>A sub section of entire tree is called branch or sub-tree.</p>
<p><b>7) Parent and Child Node</b></p>
<p>A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.</p>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2018/201804/20180415/1.png" alt=""></p>
<p>These above are the terms commonly used for decision trees. As we know that every algorithm has advantages and disadvantages, below are the important factors which one should know.</p>
<h3 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h3><p><b>1) Easy to Understand</b></p>
<p>Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Its graphical representation is very intuitive and users can easily relate their hypothesis.</p>
<p><b>2) Useful in Data Exploration</b></p>
<p>Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. With the help of decision trees, we can create new variables/features that has better power to predict target variable. For example, we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable.</p>
<p><b>3) Less Data Cleaning Required</b></p>
<p>It requires less data cleaning compared to some other modeling techniques. It is not influenced by outliers and missing values to a fair degree.</p>
<p><b>4) Data Type Is Not a Constraint</b></p>
<p>It can handle both numerical and categorical variables.</p>
<p><b>5) Non Parametric Method</b></p>
<p>Decision tree is considered to be a non-parametric method. This means that decision trees have no assumptions about the space distribution and the classifier structure.</p>
<h3 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages"></a>Disadvantages</h3><p><b>1) Over Fitting</b></p>
<p>Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning (discussed in detailed below).</p>
<p><b>2) Not Fit for Continuous Variables</b></p>
<p>While working with continuous numerical variables, decision tree looses information when it categorizes variables in different categories.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2018/04/15/WhatIsADecisionTreeHowDoesItWork/" data-id="clpllv7wb0018t4xv3vulghyz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision-Tree</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tree/" rel="tag">Tree</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer-Vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/System/">System</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azure/" rel="tag">Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bagging/" rel="tag">Bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bias/" rel="tag">Bias</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classification/" rel="tag">Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classifier/" rel="tag">Classifier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code/" rel="tag">Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer-Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/" rel="tag">Data-Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision-Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distance/" rel="tag">Distance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble/" rel="tag">Ensemble</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grammatical-Error-Correction/" rel="tag">Grammatical-Error-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hierarchical-Clustering/" rel="tag">Hierarchical-Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter/" rel="tag">Jupyter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/" rel="tag">Keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Levenshtein/" rel="tag">Levenshtein</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear/" rel="tag">Linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Merge/" rel="tag">Merge</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/" rel="tag">MongoDB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OCR/" rel="tag">OCR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Overfitting/" rel="tag">Overfitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pre-trained-Model/" rel="tag">Pre-trained-Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Programming/" rel="tag">Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyCharm/" rel="tag">PyCharm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regression/" rel="tag">Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scikit-Learn/" rel="tag">Scikit-Learn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shortcuts/" rel="tag">Shortcuts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Silhouette/" rel="tag">Silhouette</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sklearn/" rel="tag">Sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sort/" rel="tag">Sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Table-Detection/" rel="tag">Table-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TenforFlow/" rel="tag">TenforFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformers/" rel="tag">Transformers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tree/" rel="tag">Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VM/" rel="tag">VM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Variance/" rel="tag">Variance</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/Azure/" style="font-size: 10px;">Azure</a> <a href="/tags/BERT/" style="font-size: 16.67px;">BERT</a> <a href="/tags/Bagging/" style="font-size: 10px;">Bagging</a> <a href="/tags/Bias/" style="font-size: 10px;">Bias</a> <a href="/tags/Classification/" style="font-size: 10px;">Classification</a> <a href="/tags/Classifier/" style="font-size: 10px;">Classifier</a> <a href="/tags/Code/" style="font-size: 10px;">Code</a> <a href="/tags/Computer-Vision/" style="font-size: 13.33px;">Computer-Vision</a> <a href="/tags/Data-Science/" style="font-size: 13.33px;">Data-Science</a> <a href="/tags/Decision-Tree/" style="font-size: 10px;">Decision-Tree</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep-Learning</a> <a href="/tags/Distance/" style="font-size: 10px;">Distance</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Grammatical-Error-Correction/" style="font-size: 10px;">Grammatical-Error-Correction</a> <a href="/tags/Hierarchical-Clustering/" style="font-size: 10px;">Hierarchical-Clustering</a> <a href="/tags/Jupyter/" style="font-size: 10px;">Jupyter</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Levenshtein/" style="font-size: 10px;">Levenshtein</a> <a href="/tags/Linear/" style="font-size: 10px;">Linear</a> <a href="/tags/Machine-Learning/" style="font-size: 16.67px;">Machine-Learning</a> <a href="/tags/Merge/" style="font-size: 10px;">Merge</a> <a href="/tags/MongoDB/" style="font-size: 10px;">MongoDB</a> <a href="/tags/Natural-Language-Processing/" style="font-size: 13.33px;">Natural-Language-Processing</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/Object-Detection/" style="font-size: 13.33px;">Object-Detection</a> <a href="/tags/Overfitting/" style="font-size: 10px;">Overfitting</a> <a href="/tags/Pre-trained-Model/" style="font-size: 10px;">Pre-trained-Model</a> <a href="/tags/Programming/" style="font-size: 10px;">Programming</a> <a href="/tags/PyCharm/" style="font-size: 10px;">PyCharm</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/R/" style="font-size: 10px;">R</a> <a href="/tags/Regression/" style="font-size: 10px;">Regression</a> <a href="/tags/Scikit-Learn/" style="font-size: 10px;">Scikit-Learn</a> <a href="/tags/Shortcuts/" style="font-size: 10px;">Shortcuts</a> <a href="/tags/Silhouette/" style="font-size: 10px;">Silhouette</a> <a href="/tags/Sklearn/" style="font-size: 10px;">Sklearn</a> <a href="/tags/Sort/" style="font-size: 10px;">Sort</a> <a href="/tags/Spelling-Correction/" style="font-size: 20px;">Spelling-Correction</a> <a href="/tags/Table-Detection/" style="font-size: 10px;">Table-Detection</a> <a href="/tags/TenforFlow/" style="font-size: 10px;">TenforFlow</a> <a href="/tags/Transformers/" style="font-size: 10px;">Transformers</a> <a href="/tags/Tree/" style="font-size: 20px;">Tree</a> <a href="/tags/VM/" style="font-size: 10px;">VM</a> <a href="/tags/Variance/" style="font-size: 10px;">Variance</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/22/table-detection-with-detectron2-n-maskrcnn/">Table Detection with Detectron2 &amp; Mask R-CNN</a>
          </li>
        
          <li>
            <a href="/2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/">Grammatical-Error-Correction Sequence Tagging System with an Pretrained BERT-like Transformer Encoder</a>
          </li>
        
          <li>
            <a href="/2020/09/06/spelling-correction-with-soft-masked-bert/">Spelling Correction with Soft-Masked BERT</a>
          </li>
        
          <li>
            <a href="/2020/08/16/spelling-correction-with-python-spellchecker/">Spelling Correction with Python Spellchecker</a>
          </li>
        
          <li>
            <a href="/2020/07/18/spelling-correction-with-pretrained-bert/">Spelling Correction with The Pretrained BERT Model</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Stephen Cheng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/contact" class="mobile-nav-link">Contact</a>
  
    <a href="https://www.instagram.com" target="_blank" rel="noopener" class="mobile-nav-link">Instagram</a>
  
    <a href="https://www.linkedin.com" target="_blank" rel="noopener" class="mobile-nav-link">LinkedIn</a>
  
    <a href="https://www.facebook.com" target="_blank" rel="noopener" class="mobile-nav-link">Facebook</a>
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>