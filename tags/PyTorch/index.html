<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Tag: PyTorch - Stephen Cheng</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="Personal sharings about Tech & Work.">



<meta name="keywords" content="AI, Tech, CS">



    <meta name="description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:type" content="website">
<meta property="og:title" content="Stephen Cheng">
<meta property="og:url" content="https://stephen-cheng.github.io/tags/PyTorch/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:description" content="Personal sharings about Tech &amp; Work.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Stephen Cheng">
<meta property="article:tag" content="AI">
<meta property="article:tag" content=" Tech">
<meta property="article:tag" content=" CS">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 4.2.1"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#PyTorch</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/" itemprop="url">Convert Pre-trained Model from MXNet to PyTorch or TensorFlow</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-04-20T17:20:22.000Z" itemprop="datePublished">Apr 20 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Deep-Learning/">Deep-Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            8 minutes read (About 1266 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/0.png" alt=""></p>
<p>Currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models. Sometimes, when you find a fantastic GitHub repository which share a pre-trained model on a framework which you are not familiar with. For example, you are an expert PyTorch deep learning code developer, meanwhile you find a great code with its pre-trained model on MXNet; and you want to modify this model according to your needs. Thus, deep learning model conversion tools are extremely needed. As each framework has its own structure, converting a model between two different frameworks requires a great knowledge of both of them. However, There are many fantastic model conversion tools such as <a href="https://onnx.ai/" target="_blank" rel="noopener">ONNX</a>, <a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a>, and etc. for converting and visualizing deep models between a wide collection of frameworks.  </p>
<h3 id="Model-Convertors"><a href="#Model-Convertors" class="headerlink" title="Model Convertors"></a>Model Convertors</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/1.jpg" alt=""></p>
<ul>
<li>ONNX</li>
</ul>
<p><a href="http://onnx.ai/" target="_blank" rel="noopener">ONNX</a> is an effort to unify converters for neural networks in order to bring some sanity to the NN world. Released by Facebook and Microsoft.</p>
<ul>
<li>MMdnn</li>
</ul>
<p><a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a> (Model Management Deep Neural Network) is supported by Microsoft, By using MMdnn, one can convert each model from the origin framework to a standard Intermediate Representation (IR), and then convert the IR format to the target framework structure. It can convert models between CaffeEmit, CNTK, CoreML, Keras, MXNet, ONNX, PyTorch and TensorFlow.</p>
<ul>
<li>PyTorch convertor  </li>
</ul>
<p><a href="https://github.com/ruotianluo/pytorch-resnet" target="_blank" rel="noopener">PyTorch convertor</a> can convert models to PyTorch model.</p>
<ul>
<li>TensorFlow convertor  </li>
</ul>
<p><a href="https://github.com/goranrauker/convert-to-tensorflow" target="_blank" rel="noopener">TensorFlow convertor</a> can convert models to TensorFlow model.</p>
<ul>
<li>Keras convertor  </li>
</ul>
<p><a href="https://github.com/qxcv/caffe2keras" target="_blank" rel="noopener">Keras convertor</a> can convert models to Keras model.</p>
<ul>
<li>MXNet convertor</li>
</ul>
<p><a href="https://github.com/nicklhy/ResNet_caffe2mxnet" target="_blank" rel="noopener">MXNet convertor</a> can convert models to MXNet model.</p>
<ul>
<li>Caffe convertor</li>
</ul>
<p><a href="https://github.com/longcw/pytorch2caffe" target="_blank" rel="noopener">Caffe convertor</a> can convert models to Caffe model.</p>
<ul>
<li>Caffe2 convertor</li>
</ul>
<p><a href="https://caffe2.ai/docs/caffe-migration.html#caffe-to-caffe2" target="_blank" rel="noopener">Caffe2 convertor</a> can convert models to Caffe2 model.</p>
<ul>
<li>CNTK convertor</li>
</ul>
<p><a href="https://github.com/Microsoft/CNTK/tree/master/bindings/python/cntk/contrib/crosstalkcaffe" target="_blank" rel="noopener">CNTK convertor</a> can convert models to CNTK model.</p>
<ul>
<li>Theano/Lasagne convertor</li>
</ul>
<p><a href="https://github.com/an-kumar/caffe-theano-conversion" target="_blank" rel="noopener">Theano/Lasagne convertor</a> can convert models to Theano/Lasagne model.</p>
<ul>
<li>Darknet convertor  </li>
</ul>
<p><a href="https://github.com/marvis/pytorch-caffe-darknet-convert" target="_blank" rel="noopener">Darknet convertor</a> can convert models to Darknet model.</p>
<ul>
<li>Torch convertor  </li>
</ul>
<p><a href="https://github.com/kmatzen/googlenet-caffe2torch" target="_blank" rel="noopener">Torch convertor</a> can convert models to Torch model.</p>
<ul>
<li>Neon convertor  </li>
</ul>
<p><a href="https://github.com/NervanaSystems/caffe2neon" target="_blank" rel="noopener">Neon convertor</a> can convert models to Neon model.</p>
<ul>
<li>CoreML convertor</li>
</ul>
<p><a href="https://developer.apple.com/documentation/coreml" target="_blank" rel="noopener">CoreML convertor</a> can convert models to coreML model.</p>
<ul>
<li>Paddle convertor  </li>
</ul>
<p><a href="https://github.com/PaddlePaddle/X2Paddle" target="_blank" rel="noopener">Paddle convertor</a> can convert models to Paddle model.</p>
<ul>
<li>Chainer convertor  </li>
</ul>
<p>Chainer convertor can convert models to Chainer model.</p>
<h3 id="A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch"><a href="#A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch" class="headerlink" title="A Demo of Model Convertion from MXNet to PyTorch"></a>A Demo of Model Convertion from MXNet to PyTorch</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/2.png" alt=""></p>
<p>Here is an appropriate example to convert the Full ImageNet pre-trained model from MXNet to PyTorch via MMdnn convertor. ImageNet is an image database organized according to the WordNet hierarchy, in which each node of the hierarchy is depicted by hundreds and thousands of images. Since 2010, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a competition where research teams evaluate their algorithms on the given data set, and compete to achieve higher accuracy on several visual recognition tasks. A common reason to train a network on ImageNet data is to use it for transfer learning (including feature extraction or fine-tuning other models). Having a pre-trained model which is trained on such a huge training data set (i.e., full ImageNet), would be a really valuable network. It can speed up the convergence early in the training phase, and also improves the target task accuracy in some scenarios.</p>
<ul>
<li>Prerequisites:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade mmdnn</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade torch torchvision</span><br></pre></td></tr></table></figure>

<ul>
<li>Download pre-trained models:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_base_model_url = <span class="string">'http://data.mxnet.io/models/'</span></span><br><span class="line">_default_model_info = &#123;</span><br><span class="line">    <span class="string">'imagenet11k-resnet-152'</span>: &#123;<span class="string">'symbol'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-symbol.json'</span>,</span><br><span class="line">                             <span class="string">'params'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-0000.params'</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_file</span><span class="params">(url, local_fname=None, force_write=False)</span>:</span></span><br><span class="line">    <span class="comment"># requests is not default installed</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="keyword">if</span> local_fname <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        local_fname = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> force_write <span class="keyword">and</span> os.path.exists(local_fname):</span><br><span class="line">        <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line">    dir_name = os.path.dirname(local_fname)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dir_name != <span class="string">""</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_name):</span><br><span class="line">            <span class="keyword">try</span>:  <span class="comment"># try to create the directory if it doesn't exists</span></span><br><span class="line">                os.makedirs(dir_name)</span><br><span class="line">            <span class="keyword">except</span> OSError <span class="keyword">as</span> exc:</span><br><span class="line">                <span class="keyword">if</span> exc.errno != errno.EEXIST:</span><br><span class="line">                    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    r = requests.get(url, stream=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">assert</span> r.status_code == <span class="number">200</span>, <span class="string">"failed to open %s"</span> % url</span><br><span class="line">    <span class="keyword">with</span> open(local_fname, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size=<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">if</span> chunk:  <span class="comment"># filter out keep-alive new chunks</span></span><br><span class="line">                f.write(chunk)</span><br><span class="line">    <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_model</span><span class="params">(model_name, dst_dir=<span class="string">'./'</span>, meta_info=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> meta_info <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        meta_info = _default_model_info</span><br><span class="line">    meta_info = dict(meta_info)</span><br><span class="line">    <span class="keyword">if</span> model_name <span class="keyword">not</span> <span class="keyword">in</span> meta_info:</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">None</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_dir):</span><br><span class="line">        os.mkdir(dst_dir)</span><br><span class="line">    meta = dict(meta_info[model_name])</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'symbol'</span> <span class="keyword">in</span> meta, <span class="string">"missing symbol url"</span></span><br><span class="line">    model_name = os.path.join(dst_dir, model_name)</span><br><span class="line">    download_file(meta[<span class="string">'symbol'</span>], model_name+<span class="string">'-symbol.json'</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'params'</span> <span class="keyword">in</span> meta, <span class="string">"mssing parameter file url"</span></span><br><span class="line">    download_file(meta[<span class="string">'params'</span>], model_name+<span class="string">'-0000.params'</span>)</span><br><span class="line">    <span class="keyword">return</span> (model_name, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># ***** Download synset (i.e., Synonym Set):</span></span><br><span class="line">    synset_url = <span class="string">'http://data.mxnet.io.s3-website-us-west-1.amazonaws.com/models/imagenet-11k/synset.txt'</span></span><br><span class="line">    download_file(synset_url, <span class="string">'synset.txt'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ***** Download Model:</span></span><br><span class="line">    download_model(<span class="string">'imagenet11k-resnet-152'</span>, dst_dir=<span class="string">'./'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>Converting Full ImageNet Pre-trained Model from MXNet to PyTorch:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.convertToIR -f mxnet -n imagenet11k-resnet-152-symbol.json -w imagenet11k-resnet-152-0000.params -d resnet152 --inputShape 3,224,224</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.IRToCode -f pytorch --IRModelPath resnet152.pb --dstModelPath kit_imagenet.py --IRWeightPath resnet152.npy -dw kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion.examples.pytorch.imagenet_test --dump resnet152Full.pth -n kit_imagenet.py -w kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<ul>
<li>Testing the Converted Model:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.keras.api.keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ************** Parameters:</span></span><br><span class="line">num_predictions = <span class="number">5</span>  <span class="comment"># Top-k Results</span></span><br><span class="line">model_address = <span class="string">'resnet152Full.pth'</span>  <span class="comment"># for loading models</span></span><br><span class="line">lexicon_address = <span class="string">'synset.txt'</span></span><br><span class="line">test_image_address = <span class="string">'seagull.jpg'</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Converted Model:</span></span><br><span class="line">model = torch.load(model_address).to(device)</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read Input Image and Apply Pre-process:</span></span><br><span class="line">img = image.load_img(test_image_address, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x[..., ::<span class="number">-1</span>]  <span class="comment"># transform image from RGB to BGR</span></span><br><span class="line">x = np.transpose(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">x = np.expand_dims(x, <span class="number">0</span>).copy()</span><br><span class="line">x = torch.from_numpy(x)</span><br><span class="line">x = x.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Full-ImageNet Dictionary (i.e., lexicon):</span></span><br><span class="line"><span class="keyword">with</span> open(lexicon_address, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    labels = [l.rstrip() <span class="keyword">for</span> l <span class="keyword">in</span> f]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make prediction (forward pass):</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(x)</span><br><span class="line">max, argmax = output.data.squeeze().max(<span class="number">0</span>)</span><br><span class="line">class_id = argmax.item()</span><br><span class="line">class_name = labels[class_id]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the top-5 Results:</span></span><br><span class="line">h_x = output.data.squeeze()</span><br><span class="line">probs, idx = h_x.sort(<span class="number">0</span>, <span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'Top-5 Results: '</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_predictions):</span><br><span class="line">    print(<span class="string">'&#123;:.2f&#125;% -&gt; &#123;&#125;'</span>.format(probs[i] * <span class="number">100.0</span>, labels[idx[i]]))</span><br><span class="line">str_final_label = <span class="string">'The Image is a '</span> + class_name[<span class="number">10</span>:] + <span class="string">'.'</span></span><br><span class="line">print(str_final_label)</span><br></pre></td></tr></table></figure>

    
    </div>
    
    
</article>




    
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 Stephen Cheng&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery > p > .gallery-item').unwrap();
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>