{"meta":{"title":"Stephen's Blog","subtitle":"AI | Tech","description":"","author":"Stephen","url":"https://stephen-cheng.github.io","root":"/"},"pages":[{"title":"About","date":"2019-03-07T03:08:40.000Z","updated":"2024-11-15T17:22:14.110Z","comments":true,"path":"about/index.html","permalink":"https://stephen-cheng.github.io/about/index.html","excerpt":"","text":"My name is Stephen Cheng. This is my personal blog where I share ideas about Artificial Intelligence, Tech and Education. Hobbies Education Travelling Technology Business Reading Cooking Swimming Jogging Hiking Tennis Basketball Football Music Film Art"}],"posts":[{"title":"Top 40 SQL Interview Questions for Intermediate Practitioners","slug":"Top-40-SQL-Interview-Questions-for-Intermediate-Practitioners","date":"2024-11-15T22:41:55.000Z","updated":"2024-11-22T02:24:18.657Z","comments":true,"path":"2024/11/15/Top-40-SQL-Interview-Questions-for-Intermediate-Practitioners/","link":"","permalink":"https://stephen-cheng.github.io/2024/11/15/Top-40-SQL-Interview-Questions-for-Intermediate-Practitioners/","excerpt":"","text":"Stephen Cheng &nbsp; IntroIn this article, we’ll examine 40 essential SQL questions and answers for intermediate practitioners. These will cover useful functions in SQL (e.g., aggregate and scalar functions, built-in and user-defined functions), advanced commands (e.g., joins, primary and foreign keys, indexes, and SQL relationships), database design (e.g., normalization, denormalization, and the differences between various SQL statements like DELETE, TRUNCATE, and DROP), and advanced queries (e.g., subqueries, both nested and correlated, specific tasks like finding the nth highest value in a column). These questions and answers will help you better prepare for the interview and know what to expect from your interviewer/interviewee. 40 Intermediate SQL Interview QuestionsIn this section, we take a look at the 40 most popular intermediate SQL questions and answers, so that we’ll know what to expect from our interviewer. These questions are more suited to SQL practitioners with a few years of experience. 1. What is a function in SQL, and why use functions?A database object representing a set of SQL statements frequently used for a certain task. A function takes in some input parameters, performs calculations or other manipulations on them, and returns the result. Functions help improve code readability and avoid repetition of the same code snippets. 2. What types of SQL functions do you know? Aggregate functions: Work on multiple, usually grouped records for the provided columns of a table, and return a single value (usually by group). Scalar functions: Work on each individual value and return a single value. SQL functions: Built-in (defined by the system) or user-defined (created by the user for specific needs). 3. What aggregate functions do you know? AVG(): Returns the average value. SUM(): Returns the sum of values MIN(): Returns the minimum value. MAX(): Returns the maximum value. COUNT(): Returns the number of rows, including those with null values. FIRST(): Returns the first value from a column. LAST(): Returns the last value from a column. 4. What scalar functions do you know? LEN() (in other SQL flavors – LENGTH()): Returns the length of a string, including the blank spaces. UCASE() (in other SQL flavors – UPPER()): Returns a string converted to the upper case. LCASE() (in other SQL flavors – LOWER()): Returns a string converted to the lower case. INITCAP(): Returns a string converted to the title case (i.e., each word of the string starts from a capital letter). MID() (in other SQL flavors – SUBSTR()): Extracts a substring from a string. ROUND(): Returns the numerical value rounded to a specified number of decimals. NOW(): Returns the current date and time. 5. What are case manipulation functions?Case manipulation functions represent a subset of character functions, and they’re used to change the case of the text data. With these functions, we can convert the data into the upper, lower, or title case. UCASE() (in other SQL flavors – UPPER()): Returns a string converted to the upper case. LCASE() (in other SQL flavors – LOWER()): Returns a string converted to the lower case. INITCAP(): Returns a string converted to the title case (i.e., each word of the string starts from a capital letter). 6. What are character manipulation functions?Character manipulation functions represent a subset of character functions, and they’re used to modify the text data. CONCAT(): Joins two or more string values appending the second string to the end of the first one. SUBSTR(): Returns a part of a string satisfying the provided start and end points. LENGTH() (in other SQL flavors – LEN()): Returns the length of a string, including the blank spaces. REPLACE(): Replaces all occurrences of a defined substring in a provided string with another substring. INSTR(): Returns the numeric position of a defined substring in a provided string. LPAD() and RPAD(): Return the padding of the left-side/right-side character for right-justified/left-justified value. TRIM(): Removes all the defined characters, as well as white spaces, from the left, right, or both ends of a provided string. 7. What is the difference between local and global variables?Local variables can be accessed only inside the function in which they were declared. Instead, global variables, being declared outside any function, are stored in fixed memory structures and can be used throughout the entire program. 8. What is the default data ordering with the ORDER BY statement, and how do you change it?By default, the order is ascending. To change it to descending, we need to add the DESC keyword as follows: 12SELECT * FROM table_nameORDER BY col_1 DESC; 9. What set operators do you know? UNION: Returns the records obtained by at least one of two queries (excluding duplicates). UNION ALL: Returns the records obtained by at least one of two queries (including duplicates). INTERSECT: Returns the records obtained by both queries. EXCEPT (called MINUS in MySQL and Oracle): Returns only the records obtained by the first query but not the second one. 10. What operator is used in the query for pattern matching?The LIKE operator in combination with the % and _ wildcards. The % wildcard represents any number of characters including zero, while _ represents strictly one character. 11. What is the difference between a primary key and a unique key?While both types of keys ensure unique values in a column of a table, the first one uniquely identifies each record of the table, and the second one prevents duplicates in that column. 12. What is a composite primary key?The primary key of a table, based on multiple columns. 13. What is the order of appearance of the common statements in the SELECT query?SELECT – FROM – JOIN – ON – WHERE – GROUP BY – HAVING – ORDER BY – LIMIT 14. In which order the interpreter executes the common statements in the SELECT query?FROM – JOIN – ON – WHERE – GROUP BY – HAVING – SELECT – ORDER BY – LIMIT 15. What is a view, and why use it?A virtual table containing a subset of data retrieved from one or more database tables (or other views). Views take very little space, simplify complex queries, limit access to the data for security reasons, enable data independence, and summarize data from multiple tables. 16. Can we create a view based on another view?Yes. This is also known as nested views. However, we should avoid nesting multiple views since the code becomes difficult to read and debug. 17. Can we still use a view if the original table is deleted?No. Any views based on that table will become invalid after deleting the base table. If we try to use such a view anyway, we’ll receive an error message. 18. What types of SQL relationships do you know? One-to-one: Each record in one table corresponds to only one record in another table. One-to-many: Each record in one table corresponds to several records in another table. Many-to-many: Each record in both tables corresponds to several records in another table. 19. What are the possible values of a BOOLEAN data field?In some SQL flavors, such as PostgreSQL, the BOOLEAN data type exists explicitly and takes values TRUE, FALSE, or NULL. In other flavors, such as Microsoft SQL Server, the BIT datatype is used to store Boolean values as integers 1 (true) or 0 (false). 20. What is normalization in SQL, and why use it?Normalization is a process of database design that includes organizing and restructuring data in a way to reduce data redundancy, dependency, duplication, and inconsistency. This leads to enhanced data integrity, more tables within the database, more efficient data access and security control, and greater query flexibility. 21. What is denormalization in SQL, and why use it?Denormalization is the process opposite of normalization. It introduces data redundancy and combines data from multiple tables. Denormalization optimizes the performance of the database infrastructure in situations when read operations are more important than write operations since it helps avoid complex joins and reduces the time of query running. 22. What is the difference between renaming a column and giving an alias to it?Renaming a column means permanently changing its actual name in the original table. Giving an alias to a column means giving it a temporary name while executing an SQL query, with the purpose to make the code more readable and compact. 23. What is the difference between nested and correlated subqueries?A correlated subquery is an inner query nested in a bigger (outer) query that refers to the values from the outer query for its execution, meaning that a correlated subquery depends on its outer query. Instead, a non-correlated subquery doesn’t rely on the data from the outer query and can be run independently of it. 24. What is the difference between clustered and non-clustered indexes?While a clustered index defines the physical order of records of a table and performs data searching based on the key values, a non-clustered index keeps the order of records that do not match the physical order of the actual data on the disk. A table can have only one clustered index but many non-clustered ones. 25. What is the CASE() function?The way to implement the if-then-else logic in SQL. This function sequentially checks the provided conditions in the WHEN clauses and returns the value from the corresponding THEN clause when the first condition is satisfied. If none of the conditions is satisfied, the function returns the value from the ELSE clause in case it’s provided, otherwise, it returns NULL. The syntax is: 1234567CASE WHEN condition_1 THEN value_1 WHEN condition_2 THEN value_2 WHEN condition_3 THEN value_3 ... ELSE valueEND; 26. What is the difference between the DELETE and TRUNCATE statements?DELETE is a reversible DML (Data Manipulation Language) command used to delete one or more rows from a table based on the conditions specified in the WHERE clause. Instead, TRUNCATE is an irreversible DDL (Data Definition Language) command used to delete all rows from a table. DELETE works slower than TRUNCATE. Also, we can’t use the TRUNCATE statement for a table containing a foreign key. 27. What is the difference between the DROP and TRUNCATE statements?DROP deletes a table from the database completely, including the table structure and all the associated constraints, relationships with other tables, and access privileges. TRUNCATE deletes all rows from a table without affecting the table structure and constraints. DROP works slower than TRUNCATE. Both are irreversible DDL (Data Definition Language) commands. 28. What is the difference between the HAVING and WHERE statements?The first one works on aggregated data after they are grouped, while the second one checks each row individually. If both statements are present in a query, they appear in the following order: WHERE – GROUP BY – HAVING. The SQL engine interprets them also in the same order. 29. How do you add a record to a table?Using the INSERT INTO statement in combination with VALUES. The syntax is: 12INSERT INTO table_nameVALUES (value_1, value_2, ...); 30. How to delete a record from a table?We can also delete multiple records if they satisfy the provided condition. Using the DELETE statement. The syntax is: 12DELETE FROM table_nameWHERE condition; 31. How to add a column to a table?Using the ALTER TABLE statement in combination with ADD. The syntax is: 12ALTER TABLE table_nameADD column_name datatype; 32. How to rename a column of a table?Using the ALTER TABLE statement in combination with RENAME COLUMN … TO … The syntax is: 12ALTER TABLE table_nameRENAME COLUMN old_column_name TO new_column_name; 33. How to delete a column from a table?Using the ALTER TABLE statement in combination with DROP COLUMN. The syntax is: 12ALTER TABLE table_nameDROP COLUMN column_name; 34. How to select all even or all odd records in a table?By checking the remainder of the division by 2. In some SQL versions (e.g., PostgreSQL and My SQL), we use the MOD function, in the others (Microsoft SQL Server and SQLite) – the modulo operator (%). To select all even records using MOD: 12SELECT * FROM table_nameWHERE MOD(ID_column, 2) = 0; To select all even records using %: 12SELECT * FROM table_name WHERE ID_column % 2 = 0; To select all odd records, the syntax is identical in both cases, only that we would use the inequality operator &lt;&gt; instead of =. 35. How to prevent duplicate records when making a query?Using the DISTINCT statement in combination with SELECT or creating a unique key for that table. 36. How to insert many rows in a table?Using the INSERT INTO statement in combination with VALUES. The syntax is: 12345INSERT INTO table_nameVALUES (value_1, value_2, ...), (value_3, value_4, ...), (value_5, value_6, ...), ...; 37. How to find the nth highest value in a column of a table?Using the OFFSET clause. For example, to find the 6th highest value from a column, we would use the following syntax: 1234SELECT * FROM table_nameORDER BY column_name DESCLIMIT 1OFFSET 5; 38. How to find the values in a text column of a table that start with a certain letter?Using the LIKE operator in combination with the % and _ wildcards. For example, we need to find all surnames in a table that start with “A”. The query is: 12SELECT * FROM table_nameWHERE surname LIKE 'A_'; Here, we assume that a surname must contain at least two letters. Without this assumption (meaning that a surname can be just A), the query is as follows: 12SELECT * FROM table_nameWHERE surname LIKE 'A%'; 39. How to find the last id in a table?Using the MAX() function. Otherwise, in many SQL versions, we can use the following syntax: 1234SELECT idFROM table_nameORDER BY id DESCLIMIT 1; or in Microsoft SQL Server: 123SELECT TOP 1 idFROM table_nameORDER BY id DESC 40. How to select random rows from a table?Using the RAND() function in combination with ORDER BY and LIMIT. In some SQL flavors, such as PostgreSQL, it’s called RANDOM(). For example, the following code will return five random rows from a table in MySQL: 123SELECT * FROM table_nameORDER BY RAND()LIMIT 5; ConclusionTo sum up, we discussed 40 essential intermediate SQL interview questions and answers. Hopefully, this information will help you to get ready for the interview and feel more confident, whether you’re looking for a job in SQL or hiring candidates for an intermediate SQL position.","categories":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/categories/SQL/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/tags/SQL/"},{"name":"Interview","slug":"Interview","permalink":"https://stephen-cheng.github.io/tags/Interview/"},{"name":"Database","slug":"Database","permalink":"https://stephen-cheng.github.io/tags/Database/"}],"author":"Stephen Cheng"},{"title":"Top 40 SQL Interview Questions for Beginners","slug":"Top-40-SQL-Interview-Questions-for-Beginners","date":"2024-11-08T17:10:23.000Z","updated":"2024-11-21T22:44:43.380Z","comments":true,"path":"2024/11/08/Top-40-SQL-Interview-Questions-for-Beginners/","link":"","permalink":"https://stephen-cheng.github.io/2024/11/08/Top-40-SQL-Interview-Questions-for-Beginners/","excerpt":"","text":"Stephen Cheng &nbsp; IntroWhether you’re a job hunter looking for a new opportunity to apply your SQL skills or a hiring manager who is going to interrogate a candidate for a job opening in your company, knowing common SQL interview questions and answers is a must. Next, we’ll examine 40 essential SQL interview questions and answers for beginners. These will cover the basics of SQL, such as what it is, its applications, SQL statements, SQL commands, and types of SQL queries, among others. 40 Technical SQL Interview QuestionsNow, let’s move on to the technical SQL interview questions and some potential answers to them. When answering technical questions, the best strategy is to give as precise answers as possible. It may look like an attempt to deviate from the main topic. In addition, it may provoke additional questions about which you can feel less confident. 1. What is SQL?SQL stands for Structured Query Language, and it’s a programming language used for interaction with relational database management systems (RDBMS). This includes fetching, updating, inserting, and removing data from tables. 2. What are SQL dialects?The various versions of SQL, both free and paid, are also called SQL dialects. All the flavors of SQL have a very similar syntax and vary insignificantly only in additional functionality. Some examples are Microsoft SQL Server, PostgreSQL, MySQL, SQLite, T-SQL, Oracle, and MongoDB. 3. What are the main applications of SQL?Using SQL, we can: (1) create, delete, and update tables in a database; (2) access, manipulate, and modify data in a table; (3) retrieve and summarize the necessary information from a table or several tables; (4) add or remove certain rows or columns from a table. Overall, SQL allows querying a database in multiple ways. In addition, it easily integrates with other programming languages, such as Python or R, so we can use their combined power. 4. What is an SQL statement?An SQL statement is also known as an SQL command. It’s a string of characters interpreted by the SQL engine as a legal command and executed accordingly. Some examples of SQL statements are SELECT, CREATE, DELETE, DROP, REVOKE, and so on. 5. What types of SQL commands do you know? Data Definition Language (DDL): Define and modify the structure of a database. Data Manipulation Language (DML): Access, manipulate, and modify data in a database. Data Query Language (DQL): Perform queries on the data in a database to retrieve the necessary information from it. Data Control Language (DCL): Control user access to the data in the database and give or revoke privileges to a specific user or a group of users. Transaction Control Language (TCL): Control transactions in a database. 6. Give some examples of common SQL commands of each type. Data Definition Language (DDL): CREATE, ALTER TABLE, DROP, TRUNCATE, and ADD COLUMN. Data Manipulation Language (DML): UPDATE, DELETE, and INSERT. Data Query Language (DQL): SELECT. Data Control Language (DCL): GRANT and REVOKE. Transaction Control Language (TCL): COMMIT, SET TRANSACTION, ROLLBACK, and SAVEPOINT. 7. What is a database?A database is a structured storage space, where the data is kept in many tables and organized so that the necessary information can be easily fetched, manipulated, and summarized. 8. What is DBMS, and what types of DBMS do you know?DBMS stands for Database Management System, a software package used to perform various operations on the data stored in a database, such as accessing, updating, wrangling, inserting, and removing data. There are various types of DBMS, such as relational, hierarchical, network, graph, or object-oriented. These types are based on the way the data is organized, structured, and stored in the system. 9. What is RDBMS? Give some examples of RDBMS.RDBMS stands for Relational Database Management System. It’s the most common type of DBMS used for working with data stored in multiple tables related to each other by means of shared keys. The SQL programming language is designed to interact with RDBMS. Some examples of RDBMS are MySQL, PostgreSQL, Oracle, MariaDB, etc. 10. What are tables and fields in SQL?A table is an organized set of related data stored in a tabular form, i.e., in rows and columns. A field is another term for a column of a table. 11. What is an SQL query, and what types of queries do you know?A query is a piece of code written in SQL to access or modify data from a database. There are two types of SQL queries: Select queries: Retrieve the necessary data (including limiting, grouping, ordering, and extracting the data from multiple tables, etc.). Action queries: Create, add, delete, update, rename the data, etc. 12. What is a subquery?A subquery is also called an inner query, a query placed inside another query, or an outer query. A subquery may occur in the clauses such as SELECT, FROM, WHERE, UPDATE, etc. It’s also possible to have a subquery inside another subquery. The innermost subquery is run first, and its result is passed to the containing query (or subquery). 13. What types of SQL subqueries do you know? Single-row: Returns at most one row. Multi-row: Returns at least two rows. Multi-column: Returns at least two columns. Correlated: A subquery related to the information from the outer query. Nested: A subquery inside another subquery. 14. What is a constraint, and why use constraints?A set of conditions defining the type of data that can be input into each column of a table. Constraints ensure data integrity in a table and block undesired actions. 15. What SQL constraints do you know? DEFAULT: Provides a default value for a column. UNIQUE: Allows only unique values. NOT NULL: Allows only non-null values. PRIMARY KEY: Allows only unique and strictly non-null values (NOT NULL and UNIQUE). FOREIGN KEY: Provides shared keys between two or more tables. 16. What is a join?A clause used to combine and retrieve records from two or multiple tables. SQL tables can be joined based on the relationship between the columns of those tables. 17. What types of joins do you know? (INNER) JOIN: Returns only those records that satisfy a defined join condition in both (or all) tables. It’s a default SQL join. LEFT (OUTER) JOIN: Returns all records from the left table and those records from the right table that satisfy a defined join condition. RIGHT (OUTER) JOIN: Returns all records from the right table and those records from the left table that satisfy a defined join condition. FULL (OUTER) JOIN: Returns all records from both (or all) tables. It can be considered as a combination of left and right joins. 18. What is a primary key?A column (or multiple columns) of a table to which the PRIMARY KEY constraint was imposed to ensure unique and non-null values in that column. In other words, a primary key is a combination of the NOT NULL and UNIQUE constraints. The primary key uniquely identifies each record of the table. Each table should contain a primary key and can’t contain more than one primary key. 19. What is a unique key?A column (or multiple columns) of a table to which the UNIQUE constraint was imposed to ensure unique values in that column, including a possible NULL value (the only one). 20. What is a foreign key?A column (or multiple columns) of a table to which the FOREIGN KEY constraint was imposed to link this column to the primary key in another table (or several tables). The purpose of foreign keys is to keep connected various tables of a database. 21. What is an index?A special data structure related to a database table and used for storing its important parts and enabling faster data search and retrieval. Indexes are especially efficient for large databases, where they significantly enhance query performance. 22. What types of indexes do you know? Unique index: Doesn’t allow duplicates in a table column and hence helps maintain data integrity. Clustered index: Defines the physical order of records of a database table and performs data searching based on the key values. A table can have only one clustered index. Non-clustered index: Keeps the order of the table records that don’t match the physical order of the actual data on the disk. It means that the data is stored in one place and a non-clustered index – in another one. A table can have multiple non-clustered indexes. 23. What is a schema?A collection of database structural elements such as tables, stored procedures, indexes, functions, and triggers. It shows the overall database architecture, specifies the relationships between various objects of a database, and defines different access permissions for them. 24. What is a SQL comment?A human-readable clarification of what a particular piece of code does. SQL code comments can be single-line (preceded by a double dash –) or span over multiple lines (as follows: /comment_text/). When the SQL engine runs, it ignores code comments. The purpose of adding SQL code comments is to make the code more comprehensive for those people who will read it in the future. 25. What is a SQL operator?A reserved character, a combination of characters, or a keyword used in SQL queries to perform a specific operation. SQL operators are commonly used with the WHERE clause to set a condition (or conditions) for filtering the data. 26. What types of SQL operators do you know? Arithmetic (+, -, *, /, etc.) Comparison (&gt;, &lt;, =, &gt;=, etc.) Compound (+=, -=, *=, /=, etc.) Logical (AND, OR, NOT, BETWEEN, etc.) String (%, _, +, ^, etc.) Set (UNION, UNION ALL, INTERSECT, and MINUS (or EXCEPT)) 27. What is an alias?A temporary name given to a table (or a column in a table) while executing a certain SQL query. Aliases are used to improve the code readability and make the code more compact. An alias is introduced with the AS keyword: 12SELECT col_1 AS columnFROM table_name; 28. What is a clause?A condition imposed on a SQL query to filter the data to obtain the desired result. Some examples are WHERE, LIMIT, HAVING, LIKE, AND, OR, ORDER BY, etc. 29. What are some common statements used with the SELECT query?The most common ones are FROM, GROUP BY, JOIN, WHERE, ORDER BY, LIMIT, and HAVING. 30. How to create a table?Using the CREATE TABLE statement. For example, to create a table with three columns of predefined datatypes, we apply the following syntax: 1234CREATE TABLE table_name (col_1 datatype,col_2 datatype,col_3 datatype); 31. How to update a table?Using the UPDATE statement. The syntax is: 123UPDATE table_nameSET col_1 = value_1, col_2 = value_2WHERE condition; 32. How to delete a table from a database?Using the DROP TABLE statement. The syntax is: 1DROP TABLE table_name; 33. How to get the count of records in a table?Using the COUNT() aggregate function with the asterisk passed as its argument: 1SELECT COUNT(*) FROM table_name; 34. How to sort records in a table?Using the ORDER BY statement: 12SELECT * FROM table_nameORDER BY col_1; We can specify that we need a descending order using the DESC keyword. Otherwise, the order will be ascending by default. Also, we can sort by more than one column and specify for each one, ascending or descending order separately. For example: 12SELECT * FROM table_nameORDER BY col_1 DESC, col_3, col_6 DESC; 35. How to select all columns from a table?Using the asterisk * with the SELECT statement. The syntax is: 1SELECT * FROM table_name; 36. How to select common records from two tables?Using the INTERSECT statement: 123SELECT * FROM table_1INTERSECTSELECT * FROM table_1; 37. What is the DISTINCT statement and how do you use it?This statement is used with the SELECT statement to filter out duplicates and return only unique values from a column of a table. The syntax is: 12SELECT DISTINCT col_1FROM table_name; 38. What are entities?An entity is a real-world object, creature, place, or phenomenon for which the data can be gathered and stored in a database table. Each entity corresponds to a row in a table, while the table’s columns describe its properties. Some examples of entities are bank transactions, students in a school, cars sold, etc. 39. What are relationships?Relationships are the connections and correlations between entities, basically meaning how two or more tables of a database are related to one another. For example, we can find an ID of the same client in a table on sales data and in a customer table. 40. What is NULL value? How is it different from zero or a blank space?A NULL value indicates the absence of data for a certain cell of a table. Instead, zero is a valid numeric value, and an empty string is a legal string of zero length.","categories":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/categories/SQL/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/tags/SQL/"},{"name":"Interview","slug":"Interview","permalink":"https://stephen-cheng.github.io/tags/Interview/"},{"name":"Database","slug":"Database","permalink":"https://stephen-cheng.github.io/tags/Database/"}],"author":"Stephen Cheng"},{"title":"Python 3 Cheat Sheet","slug":"Python-3-Cheat-Sheet","date":"2024-11-01T16:01:31.000Z","updated":"2024-11-21T17:03:41.522Z","comments":true,"path":"2024/11/01/Python-3-Cheat-Sheet/","link":"","permalink":"https://stephen-cheng.github.io/2024/11/01/Python-3-Cheat-Sheet/","excerpt":"","text":"Stephen Cheng &nbsp; IntroPython is one of the most widely-used and popular programming languages, was developed by Guido van Rossum and released first in 1991. It is a free and open-source language with a very simple and clean syntax which makes it easy for developers to learn Python. It supports object-oriented programming and is most commonly used to perform general-purpose programming. Python is used in several domains like Data Science, Machine Learning, Deep Learning, Artificial Intelligence, Scientific Computing Scripting, Networking, Game Development Web Development, Web Scraping, and various other domains. Python Cheat sheetIn this Cheat Sheet of Python, you’ll learn all the basic to advanced topics and concepts of Python, like Python data types, Python for loop, Python slice, python map function, python dictionary, Python File Handling, etc.","categories":[{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/categories/Programming/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/tags/Programming/"},{"name":"Computer Science","slug":"Computer-Science","permalink":"https://stephen-cheng.github.io/tags/Computer-Science/"}],"author":"Stephen Cheng"},{"title":"A Complete Guide to Regularization in Deep Learning","slug":"A-Complete-Guide-to-Regularization-in-Deep-Learning","date":"2024-10-30T14:34:43.000Z","updated":"2024-11-16T20:44:26.385Z","comments":true,"path":"2024/10/30/A-Complete-Guide-to-Regularization-in-Deep-Learning/","link":"","permalink":"https://stephen-cheng.github.io/2024/10/30/A-Complete-Guide-to-Regularization-in-Deep-Learning/","excerpt":"","text":"Stephen Cheng &nbsp; IntroA universal problem in machine learning has been making an algorithm that performs equally well on training data and any new samples or test dataset. Techniques used in machine learning that have specifically been designed to cater to reducing test error, mostly at the expense of increased training error, are globally known as regularization. Regularization techniques are crucial in minimizing overfitting and ensuring the model performs optimally. In this article, you will understand regularization comprehensively, equipping you with the knowledge to implement these techniques effectively and achieve the best possible outcomes with your models. What is Regularization?Regularization in machine learning and deep learning serves as a method to forestall a model from overfitting. Overfitting transpires when a model not only discerns the inherent pattern within the training data but also incorporates the noise, potentially leading to subpar performance on fresh, unobserved data. The employment of regularization aids in mitigating this issue by augmenting a penalty to the loss function employed for model training. This method strikes a balance between underfitting and overfitting, where underfitting occurs when the model is too simple to capture the underlying trends in the data, leading to both training and validation accuracy being low. The primary goal of regularization is to reduce the model’s complexity to make it more generalizable to new data, thus improving its performance on unseen datasets. How Does Regularization Work?Regularization adds a penalty term to the standard loss function that a machine learning model minimizes during training. This penalty encourages the model to keep its parameters (like weights in neural networks or coefficients in regression models) small, which can help prevent overfitting. Here’s a step-by-step breakdown of how regularization functions. 1.Modifying the Loss FunctionThe regularization process starts by modifying the loss function. The updated loss function encompasses the initial loss, assessing the model’s alignment with the training data, and a regularization term that discourages excessive parameter magnitudes. The general form of the regularized loss function is: Regularized Loss = Original Loss + λ * Penalty Here, λ (lambda) is the regularization strength, which controls the trade-off between fitting the data well and keeping the model parameters small. 2.Types of Regularization (Penalties) L1 Regularization (Lasso Regularization): A regression model which uses the L1 Regularization technique is called LASSO (Least Absolute Shrinkage and Selection Operator) regression. Lasso Regression adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function (L). Lasso regression also helps us achieve feature selection by penalizing the weights to approximately equal to zero if that feature does not serve any purpose in the model. This penalty is the sum of the absolute values of the parameters. It can lead to a sparse model where some parameter values are exactly zero, effectively removing those features from the model. L2 Regularization (Ridge Regularization): A regression model that uses the L2 regularization technique is called Ridge regression. Ridge regression adds the “squared magnitude” of the coefficient as a penalty term to the loss function (L). This penalty is the sum of the squares of the parameters. It evenly distributes the penalty among all parameters, shrinking them towards zero but not exactly zeroing any. Elastic Net Regularization (L1 and L2 Regularization): This model is a combination of L1 as well as L2 regularization. That implies that we add the absolute norm of the weights as well as the squared measure of the weights. With the help of an extra hyperparameter (e.g., learning rate, epochs, layers, etc.) that controls the ratio of the L1 and L2 regularization. It is useful when there are correlations among features or when you want to combine the feature selection properties of L1 with the shrinkage properties of L2. 3.Effect on TrainingDuring training, the regularization term influences the updates made to the model parameters: Minimizing a larger penalty term (due to larger values of λ) emphasizes smaller model parameters, leading to simpler models that might generalize better but could underfit the training data. Minimizing a smaller penalty term (lower values of λ) allows the model to fit the training data more closely, possibly at the expense of increased complexity and overfitting. 4.Balancing Overfitting and UnderfittingChoosing the right value of λ is crucial: Too high a value can make the model too simple and fail to capture important patterns in the data (underfitting). Too low a value might not sufficiently penalize large coefficients, leading to a model that captures too much noise from the training data (overfitting). 5.ImplementationIn practice, the optimal value of λ and the type of regularization (L1, L2, or Elastic Net) are often selected through cross-validation, where multiple models are trained with different values of λ and possibly different types of regularization. The model that performs best on a validation set or through a cross-validation process is then chosen. Roles of RegularizationRegularization plays several crucial roles in developing and performing machine learning models. Its main purposes revolve around managing model complexity, improving generalization to new data, and addressing specific issues like multicollinearity and feature selection. Here are the primary roles of regularization in machine learning. Preventing OverfittingRegularization’s most significant role is to prevent overfitting, a common issue in which a model learns the underlying pattern and noise in the training data. This usually results in high performance on the training set but poor performance on unseen data. Regularization reduces overfitting by penalizing larger weights, encouraging the model to prioritize simpler hypotheses. Balancing Bias for VarianceRegularization introduces bias into the model (assuming that smaller weights are preferable). However, it reduces variance by preventing the model from fitting too closely to the training data. This trade-off is beneficial when the unconstrained model is highly complex and prone to overfitting. Feature SelectionL1 regularization (Lasso) encourages sparsity in the model coefficients. By penalizing the absolute value of the coefficients, Lasso can shrink some of them to exactly zero, effectively selecting a smaller subset of the available features. This can be extremely useful in scenarios with high-dimensional data where feature selection is necessary to improve model interpretability and efficiency. Handling MulticollinearityRegularization is particularly useful in scenarios where features are highly correlated (multicollinearity). L2 regularization (Ridge) can reduce the variance of the coefficient estimates, which are otherwise inflated due to multicollinearity. This stabilization makes the model’s predictions more reliable. Improving Model GeneralizationRegularization helps ensure the model performs well on the training and new, unseen data by constraining its complexity. A well-regularized model will likely capture the data’s underlying trends rather than the training set’s specific details and noise. Complexity ControlRegularization sometimes allows practitioners to use more complex models than they otherwise could. For example, regularization techniques like dropout can be used in neural networks to train deep networks without overfitting, as they help prevent neuron co-adaptation. Improving Robustness to NoiseRegularization makes the model less sensitive to the idiosyncrasies of the training data. This includes noise and outliers, as the penalty discourages fitting them too closely. Consequently, the model focuses more on the robust features that are more generally applicable, enhancing its robustness. Aiding in ConvergenceFor models trained using iterative optimization techniques (like gradient descent), regularization can help ensure smoother and more reliable convergence. This is especially true for problems that are ill-posed or poorly conditioned without regularization. What are Overfitting and Underfitting?OverfittingOverfitting happens when a model gets too caught up in the nuances and random fluctuations of the training data to the point where its ability to perform well on new, unseen data suffers. Essentially, the model becomes overly intricate, grasping at patterns that don’t hold up when applied to different datasets. Characteristics: High accuracy on training data but poor accuracy on validation or test data. The model has learned the training data’s underlying structure and random fluctuations. Often occurs when the model is too complex relative to the amount and noisiness of the input data. Common Causes: Too many parameters in the model (high complexity). Too little training data. Insufficient use of regularization. Training for too many epochs or without early stopping. Mitigation Strategies: Simplify the model by reducing the number of parameters or using a less complex model. Increase training data. Use regularization techniques like L1, L2, and dropout. Implement early stopping during training. Employ techniques like cross-validation to ensure the model performs well on unseen data. UnderfittingUnderfitting arises when a model lacks the complexity to capture the underlying patterns within the data. Consequently, it inadequately fits the training data, leading to subpar performance when applied to new data. Characteristics: Poor performance on both the training and testing datasets. The model is too simple and does not capture the basic trends in the data. Common Causes: The model is too simple and has very few parameters. Features used in the model do not adequately capture the complexities of the data. Excessive use of regularization (too strong a penalty for model complexity). Mitigation Strategies: Increase the complexity of the model by using more parameters or choosing a more sophisticated model. Create more features or use different techniques to extract and select relevant features. Reduce the regularization force if the model is overly penalized. Ensure the model is properly trained and tweak training parameters like the number of epochs or learning rate. Balancing ActFinding the balance between overfitting and underfitting is key to developing effective machine learning models. It involves choosing the right model complexity, adequately preparing the data, selecting suitable features, and tuning the training process (including regularization and other parameters). The aim is to build a model that generalizes well to new, unseen datasets while maintaining good performance on the training data. What are Bias and Variance?Bias and variance are two fundamental concepts that describe different types of errors in predictive models in machine learning and statistics. Understanding bias and variance is crucial for diagnosing model performance issues and navigating the trade-offs between underfitting and overfitting. BiasBias in machine learning arises when a simplified model fails to capture the complexities of a real-world problem. This oversight can lead to underfitting, where the algorithm overlooks important relationships between input features and target outputs. Characteristics: Bias is the difference between our model’s expected (or average) prediction and the correct value we try to predict. Models with high bias pay little attention to the training data and oversimplify the model, often leading to underfitting. High bias can lead to a model that is too simple and does not capture the complexity of the data. VarianceVariance refers to the amount by which the model’s predictions would change if we estimated it using a different training data set Essentially, variance indicates how much the model’s predictions are spread out from the average prediction. Excessive variability can lead an algorithm to mimic the random fluctuations in the training data instead of focusing on the desired outcomes, resulting in overfitting. Characteristics: Variance quantifies the extent to which predictions for a specific point fluctuate across various model instances. Elevated variance may cause the model to capture the noise within the training data instead of the desired outcomes, thereby causing subpar performance when applied to unseen data. Different Combinations of Bias and VarianceThere can be four combinations between bias and variance: High Bias, Low Variance: A model that has high bias and low variance is considered to be underfitting. High Variance, Low Bias: A model that has high variance and low bias is considered to be overfitting. High-Bias, High-Variance: A model with high bias and high variance cannot capture underlying patterns and is too sensitive to training data changes. On average, the model will generate unreliable and inconsistent predictions. Low Bias, Low Variance: A model with low bias and low variance can capture data patterns and handle variations in training data. This is the perfect scenario for a machine learning model where it can generalize well to unseen data and make consistent, accurate predictions. However, in reality, this is not feasible. Bias Variance tradeoffThe bias-variance tradeoff is a fundamental concept in machine learning. It refers to the balance between bias and variance, which affect predictive model performance. When one decreases, the other tends to increase, and vice versa. Finding the right tradeoff is crucial for creating models that generalize well to new data. Underfitting: Occurs when the model is too simple, characterized by low variance and high bias. Overfitting: Occurs when the model is too complex, characterized by high variance and low bias. Effective Regularization TechniquesRegularization is a critical technique in machine learning to reduce overfitting, enhance model generalization, and manage model complexity. Several regularization techniques are used across different types of models. Here are some of the most common and effective regularization techniques: L1 Regularization (Lasso Regularization)Lasso regularization encourages sparsity in the model parameters. Some coefficients can shrink to zero, effectively performing feature selection. L2 Regularization (Ridge Regularization)Ridge regularization shrinks the coefficients evenly but does not necessarily bring them to zero. It helps with multicollinearity and model stability. Elastic NetElastic net is useful when there are correlations among features or to balance feature selection with coefficient shrinkage. DropoutDropout results in a network that is robust and less likely to overfit, as it has to learn more robust features from the data that aren’t reliant on any small set of neurons. Early StoppingEarly stopping prevents overfitting by not allowing the training to continue too long. It is a straightforward and often very effective form of regularization. Batch NormalizationBatch normalization reduces the need for other forms of regularization and can sometimes eliminate the need for dropout. Weight ConstraintWeight constraint ensures that the weights do not grow too large, which can help prevent overfitting and improve the model’s generalization. Data AugmentationAlthough not a direct form of regularization in a mathematical sense, data augmentation acts like one by artificially increasing the size of the training set, which helps the model generalize better. Benefits of Regularization Reduces Overfitting: Regularization helps prevent models from learning noise and irrelevant details in the training data. Enables Feature Selection: L1 regularization can zero out some coefficients, effectively selecting more relevant features. Improves Generalization: By discouraging complex models, regularization ensures better performance on unseen data. Enhances Stability: Regularization stabilizes model training by penalizing large weights. Manages Multicollinearity: Reduces the problem of high correlations among features, particularly useful in linear models. Encourages Simplicity: Promotes simpler models that are easier to interpret and less likely to overfit. Controls Model Complexity: Provides a mechanism to balance the complexity of the model with its performance on the training and test data. Facilitates Robustness: Makes models less sensitive to individual peculiarities in the training set. Improves Convergence: Helps optimization algorithms converge more quickly and reliably by smoothing the error landscape. ConclusionMastering regularization techniques is essential for any aspiring AI engineer looking to build robust, efficient, and generalizable machine learning models. Understanding and implementing various regularization methods such as L1, L2, Elastic Net, Dropout, and others enhances our models’ performance and deepens your understanding of machine learning fundamentals. Whether we’re dealing with overfitting, underfitting, or needing to improve model stability, regularization offers the tools necessary to address these challenges effectively.","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"},{"name":"Regularization","slug":"Regularization","permalink":"https://stephen-cheng.github.io/tags/Regularization/"}],"author":"Stephen Cheng"},{"title":"Gradient Descent based Optimization Algorithms for Deep Learning Models Training","slug":"Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training","date":"2024-10-18T23:37:03.000Z","updated":"2024-11-16T03:08:48.210Z","comments":true,"path":"2024/10/18/Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training/","link":"","permalink":"https://stephen-cheng.github.io/2024/10/18/Gradient-Descent-based-Optimization-Algorithms-for-Deep-Learning-Models-Training/","excerpt":"","text":"Stephen Cheng &nbsp; IntroGradient descent is an optimisation method for finding the minimum of a function. It is commonly used in deep learning models to update the weights of the neural network through backpropagation. Understanding different optimization algorithms and their strengths and weaknesses is crucial for any data scientist training deep learning models. Selecting the right optimizer for the task at hand is paramount to achieving the best possible training results in the shortest amount of time. Next, we’ll explore the most commonly used deep learning optimization algorithms, including Gradient Descent, Stochastic Gradient Descent, and the Adam optimizer. By the end of this article, you’ll have a clear idea of how to choose the best algorithm for training your models. Gradient DescentGradient Descent is an algorithm designed to minimize a function by iteratively moving towards the minimum value of the function. It’s akin to a hiker trying to find the lowest point in a valley shrouded in fog. The hiker starts at a random location and can only feel the slope of the ground beneath their feet. To reach the valley’s lowest point, the hiker takes steps in the direction of the steepest descent. All deep learning model optimization algorithms widely used today are based on Gradient Descent. How it Works Initialization: Start with random values for the model’s weights. Gradient computation: Calculate the gradient of the cost function with respect to each parameter. The gradient is a vector that points in the direction of the steepest increase of the function. In the context of optimization, we’re interested in the negative gradient, which points towards the direction of the steepest decrease. Update parameters: Adjust the model’s parameters in the direction opposite to the gradient. This step is done by subtracting a fraction of the gradient from the current values of the parameters. The size of this step is determined by the learning rate, a hyperparameter that controls how fast or slow we move toward the optimal weights. Mathematical RepresentationThe update rule for each parameter 𝒘 can be mathematically represented as: where w represents the model’s parameters (weights) and 𝛼 is the learning rate. Δ𝑤𝐽(w) is the gradient of the cost function 𝐽(w) with respect to w. The learning rate is a crucial hyperparameter that needs to be chosen carefully. If it’s too small, the algorithm will converge very slowly. If it’s too large, the algorithm might overshoot the minimum and fail to converge. Stochastic Gradient Descent (SGD)Stochastic Gradient Descent (SGD) is a variant of the traditional Gradient Descent optimization algorithm that introduces randomness into the optimization process to improve convergence speed and potentially escape local minima. To understand the intuition behind SGD, we can again invoke the analogy of a hiker descending a foggy valley. If Gradient Descent represents a cautious hiker who carefully evaluates the slope around them before taking a step, Stochastic Gradient Descent is akin to a more impulsive hiker who decides their next step based only on the slope of the ground immediately beneath their feet. This approach can lead to a quicker descent but might involve more meandering. How it Works Initialization: Start with a random set of parameters for the model. Gradient computation: Instead of calculating the gradient of the cost function over the entire training data, SGD computes the gradient based on a single randomly selected training example. Update parameters: Update the model’s parameters using this computed gradient. The parameters are adjusted in the direction opposite to the gradient, similar to basic Gradient Descent. Mathematical RepresentationThe parameter update rule in SGD is similar to that of Gradient Descent but applies to a single example i: Here, w represents the model’s parameters (weights), 𝛼 is the learning rate, and ∆𝘸𝘑𝘪(𝘸) is the gradient of the cost function 𝐽i(w) for the ith training example with respect to w. Mini-batch Gradient DescentMini-batch Gradient Descent strikes a balance between the thorough, calculated approach of Gradient Descent and the unpredictable, swift nature of Stochastic Gradient Descent (SGD). Imagine a group of hikers navigating through a foggy valley. Each hiker independently assesses a small, distinct section of the surrounding area before the group decides on the best direction to take. Based on a broader but still limited view of the terrain, this collective decision-making process allows for a more informed and steady progression toward the valley’s lowest point compared to an individual hiker’s erratic journey. How it Works Initialization: Start with initial random values for the model’s parameters. Gradient computation: Instead of calculating the gradient using the entire dataset (as in Gradient Descent) or a single example (as in SGD), Mini-batch Gradient Descent computes the gradient using a small subset of the training data, known as a mini-batch. Update parameters: Adjust the parameters in the direction opposite to the computed gradient. This adjustment is made based on the gradient derived from the mini-batch, aiming to reduce the cost function. Mathematical RepresentationThe parameter update rule for Mini-batch Gradient Descent can be represented as: where 𝑤 represents the model’s parameters (weights), 𝛼 is the learning rate, and ∆𝘸𝘑𝘪(𝘸) is the gradient of the cost function 𝘑𝘮𝘪𝘯𝘪-𝘣𝘢𝘵𝘤𝘩(𝘸) for the current mini-batch of training samples with respect to w. AdaGrad (Adaptive Gradient Algorithm)AdaGrad (Adaptive Gradient Algorithm) introduces an innovative twist to the conventional Gradient Descent optimization technique by dynamically adapting the learning rate, allowing for a more nuanced and effective optimization process. Imagine a scenario where our group of hikers, navigating the foggy valley, now has access to a map highlighting areas of varying difficulty. With this map, they can adjust their pace — taking smaller steps in steep, difficult terrain and larger strides in flatter regions — to optimize their path toward the valley’s bottom. How it Works Initialization: Begin with random values for the model’s parameters and initialize a gradient accumulation variable, typically a vector of zeros, of the same size as the parameters. Gradient computation: Square and accumulate the gradients in the gradient accumulation variable, which consequently tracks the sum of squares of the gradients for each parameter. Adjust learning rate: Modify the learning rate for each parameter inversely proportional to the square root of its accumulated gradient, ensuring parameters with smaller gradients to have larger updates. Update parameters: Update each parameter using its adjusted learning rate and the computed gradient. Mathematical RepresentationThe parameter update rule for AdaGrad can be represented as: Where w represents the model’s parameters (weights), 𝛼 is the initial learning rate, 𝘎 is the accumulation of the squared gradients, ∈ is a small smoothing term to prevent division by zero, and ∆𝘸𝘑(𝘸) is the gradient of the cost function 𝐽(w) for the training samples with respect to w. RMSprop (Root Mean Square Propagation)RMSprop (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm designed to address AdaGrad’s diminishing learning rates issue. Continuing with the analogy of hikers navigating a foggy valley, RMSprop equips our hikers with an adaptive tool that allows them to maintain a consistent pace despite the terrain’s complexity. This tool evaluates the recent terrain and adjusts their steps accordingly, ensuring they neither get stuck in difficult areas due to excessively small steps nor overshoot their target with overly large steps. RMSprop achieves this by modulating the learning rate based on a moving average of the squared gradients. How it Works Initialization: Start with random initial values for the model’s parameters and initialize a running average of squared gradients, typically as a vector of zeros of the same size as the parameters. Compute gradient: Calculate the gradient of the cost function with respect to each parameter using a selected subset of the training data (mini-batch). Update squared gradient average: Update the running average of squared gradients using a decay factor, γ, often set to 0.9. This moving average emphasizes more recent gradients, preventing the learning rate from diminishing too rapidly. Adjust learning rate: Scale down the gradient by the square root of the updated running average, normalizing the updates and allowing for a consistent pace of learning across parameters. Update parameters: Apply the adjusted gradients to update the model’s parameters. Mathematical RepresentationThe parameter update rule for RMSprop can be represented as follows: Here, 𝘸 represents the parameters, α is the initial learning rate, 𝘌[𝘨²]ₜ is the running average of squared gradients at a certain time, ∈ is a small smoothing term to prevent division by zero, and ∆𝘸𝘑(𝘸) is the gradient of the cost function 𝘑(𝘸) with respect to 𝘸. AdaDeltaAdaDelta is an extension of AdaGrad that seeks to reduce its aggressively decreasing learning rate. Imagine our group of hikers now has an advanced tool that not only adapts to recent terrain changes but also ensures their gear weight doesn’t hinder their progress. This tool dynamically adjusts their stride length, ensuring they can maintain a steady pace without the burden of past terrain slowing them down. Similarly, AdaDelta modifies the learning rate based on a window of recent gradients rather than accumulating all past squared gradients. This approach allows for a more robust and adaptive learning rate adjustment over time. How it Works Initialization: Start with random initial parameters and two state variables, one for accumulating gradients and another for accumulating parameter updates, both initially set to zero. Compute gradient: Determine the gradient of the cost function with respect to each parameter using a subset of the training data (mini-batch). Accumulate gradients: Update the first state variable with the squared gradients, applying a decay factor to maintain a focus on recent gradients. Compute update: Determine the parameter updates based on the square root of the accumulated updates state variable divided by the square root of the accumulated gradients state variable, adding a small constant to avoid division by zero. Accumulate updates: Update the second state variable with the squared parameter updates. Update parameters: Modify the model’s parameters using the computed updates. Mathematical RepresentationThe parameter update rule for AdaDelta is more complex due to its iterative nature but can be generalized as: Where 𝘸 represents the parameters, 𝘙𝘔𝘚[𝘶]ₜ₋₁ is the root mean square of parameter updates up to the previous time step, 𝘙𝘔𝘚[𝘨]ₜ is the root mean square of gradients at the current time step, and ∆𝘸𝘑(𝘸) is the gradient of the cost function 𝘑(𝘸) with respect to 𝘸. Adam (Adaptive Moment Estimation)Adam (Adaptive Moment Estimation) combines the best properties of AdaGrad and RMSprop to provide an optimization algorithm that can handle sparse gradients on noisy problems. Using our hiking analogy, imagine that the hikers now have access to a state-of-the-art navigation tool that not only adapts to the terrain’s difficulty but also keeps track of their direction to ensure smooth progress. This tool adjusts their pace based on both the recent and accumulated gradients, ensuring they efficiently navigate towards the valley’s bottom without veering off course. Adam achieves this by maintaining estimates of the first and second moments of the gradients, thus providing an adaptive learning rate mechanism. How it Works Initialization: Start with random initial parameter values and initialize a first moment vector (m) and a second moment vector (v). Each “moment vector” stores aggregated information about the gradients of the cost function with respect to the model’s parameters. The first moment vector accumulates the means (or the first moments) of the gradients, acting like a momentum by averaging past gradients to determine the direction to update the parameters. The second moment vector accumulates the variances (or second moments) of the gradients, helping adjust the size of the updates by considering the variability of past gradients. Compute gradient: For each mini-batch, compute the gradients of the cost function with respect to the parameters. Update moments: Update the first moment vector (m) with the bias-corrected moving average of the gradients. Similarly, update the second moment vector (v) with the bias-corrected moving average of the squared gradients. Adjust learning rate: Calculate the adaptive learning rate for each parameter using the updated first and second moment vectors, ensuring effective parameter updates. Update parameters: Use the adaptive learning rates to update the model’s parameters. Mathematical RepresentationThe parameter update rule for Adam can be expressed as: Where 𝘸 represents the parameters, α is the learning rate, and 𝘮ₜ and 𝘷ₜ are bias-corrected estimates of first and second moments of the gradients, respectively. Cheat Sheet of Mathematical Representation of Optimizers Comparisons between Different Optimization Algorithms Algorithm Pros Cons When to use Gradient Descent Simple and easy to implement Computationally expensive on large datasets; May get stuck in local minima Small datasets; When simplicity and clarity are preferred SGD Fast; Handles large datasets well High variance in updates can lead to instability Large datasets; Online or incremental learning scenarios Mini-batch Gradient Descent Balances between efficiency and stability; More generalizable updates Requires tuning of batch size Most deep learning tasks, especially when working with moderate to large datasets AdaGrad Adapts learning rate for each parameter; Good for sparse data Learning rate can diminish to zero, stopping learning Sparse datasets like text and images where learning rate needs to adapt to feature frequency RMSprop Addresses diminishing learning rate of AdaGrad; Adapts learning rate based on recent gradients Can still get stuck in local minima on non-convex problems Non-convex optimization problems; Situations where AdaGrad’s learning rate diminishes too fast AdaDelta Eliminates the need to set a default learning rate; Addresses diminishing learning rate issue More complex than RMSprop and AdaGrad Similar to RMSprop, but when you want to avoid manual learning rate setting Adam Combines advantages of AdaGrad and RMSprop; Adaptive learning rates; Includes bias correction Requires tuning of hyperparameters (though it often works well with defaults) Most deep learning applications, due to its efficiency and effectiveness","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"},{"name":"Gradient Descent","slug":"Gradient-Descent","permalink":"https://stephen-cheng.github.io/tags/Gradient-Descent/"},{"name":"Optimization Algorithms","slug":"Optimization-Algorithms","permalink":"https://stephen-cheng.github.io/tags/Optimization-Algorithms/"}],"author":"Stephen Cheng"},{"title":"Backpropagation in Neural Networks - The Engine Behind Deep Learning","slug":"Backpropagation-in-Neural-Networks-The-Engine-Behind-Deep-Learning","date":"2024-10-02T16:28:14.000Z","updated":"2024-11-15T23:21:11.133Z","comments":true,"path":"2024/10/02/Backpropagation-in-Neural-Networks-The-Engine-Behind-Deep-Learning/","link":"","permalink":"https://stephen-cheng.github.io/2024/10/02/Backpropagation-in-Neural-Networks-The-Engine-Behind-Deep-Learning/","excerpt":"","text":"Stephen Cheng &nbsp; IntroBackpropagation (short for “Backward Propagation of Errors”) is a method used to train artificial neural networks. Its goal is to reduce the difference between the model’s predicted output and the actual output by adjusting the weights and biases in the network. In this article, we will explore what backpropagation is, why it is crucial in machine learning, and how it works. What is Backpropagation?Introduced in the 1970s, the backpropagation algorithm is the method for fine-tuning the weights of a neural network with respect to the error rate obtained in the previous iteration or epoch, and this is a standard method of training artificial neural networks, particularly feed-forward networks. You can think of it as a feedback system where, after each round of training or ‘epoch,’ the network reviews its performance on tasks. It calculates the difference between its output and the correct answer, known as the error. Backpropagation works iteratively, minimizing the cost function by adjusting weights and biases. In each epoch, the model adapts these parameters, reducing loss by following the error gradient. Backpropagation often utilizes optimization algorithms like gradient descent or stochastic gradient descent. The algorithm computes the gradient using the chain rule from calculus, allowing it to effectively navigate complex layers in the neural network to minimize the cost function. Why is Backpropagation Important?Backpropagation plays a critical role in how neural networks improve over time. Here’s why: Efficient Weight Update: It computes the gradient of the loss function with respect to each weight using the chain rule, making it possible to update weights efficiently. Scalability: The backpropagation algorithm scales well to networks with multiple layers and complex architectures, making deep learning feasible. Automated Learning: With backpropagation, the learning process becomes automated, and the model can adjust itself to optimize its performance. How Does Backpropagation Work?There are overall four main steps in the backpropagation algorithm: The Forward Pass Errors Calculation (The Loss Function) The Backward Pass Weights Update (Optimizer/Optimization Algorithm) Next, let’s understand each of these steps from the above animation. The Forward PassIn the forward pass, the input data is fed into the input layer. These inputs, combined with their respective weights, are passed to hidden layers. For example, in a network with two hidden layers (h1 and h2 as shown in Fig.), the output from h1 serves as the input to h2. Before applying an activation function, a bias is added to the weighted inputs. Each hidden layer applies an activation function like ReLU (Rectified Linear Unit), which returns the input if it’s positive and zero otherwise. This adds non-linearity, allowing the model to learn complex relationships in the data. Finally, the outputs from the last hidden layer are passed to the output layer, where an activation function, such as softmax, converts the weighted outputs into probabilities for classification. The forward pass is the first step of the backpropagation process, and it’s illustrated below: The data (inputs X1 and X2) is fed to the input layer. Then, each input is multiplied by its corresponding weight, and the results are passed to the neurons N1X and N2X of the hidden layers, where X takes the values of 1, 2 and 3. Those neurons apply an activation function to the weighted inputs they receive, and the result passes to the output layer. Errors Calculation (The Loss Function)The process continues until the output layer generates the final output (o/p). The output of the network is then compared to the ground truth (desired output), and the difference is calculated, resulting in an error value. The Backward PassThis is an actual backpropagation step, and can not be performed without the above forward and the loss function steps. Here is how it works: The error value obtained previously is used to calculate the gradient of the loss function. The gradient of the error is propagated back through the network, starting from the output layer to the hidden layers. As the error gradient propagates back, the weights (represented by the lines connecting the nodes) are updated according to their contribution to the error. This involves taking the derivative of the error with respect to each weight, which indicates how much a change in the weight would change the error. The learning rate determines the size of the weight updates. A smaller learning rate means than the weights are updated by a smaller amount, and vice-versa. One common method for error calculation is the Mean Squared Error (MSE), given by: MSE = (Predicted Output − Actual Output)^2 Weights Update (Optimizer/Optimization Algorithm)The weights are updated in the opposite direction of the gradient, leading to the name gradient descent. It aims to reduce the error in the next forward pass. This process of forward pass, error calculation, backward pass, and weights update continues for multiple epochs until the network performance reaches a satisfactory level or stops improving significantly. The activation function, through its derivative, plays a crucial role in computing these gradients during backpropagation. Optimizers are algorithms or methods used to minimize an error function(loss function)or to maximize the efficiency of production. Optimizers help to know how to change weights and learning rate of neural network to reduce the losses. There are different types of optimizers, such as Gradient Descent algorithm, Stochastic Gradient Descent (SGD), Mini-Batch Gradient Descent, SGD with Momentum, Adaptive Gradient Descent (AdaGrad), Root Mean Square Propagation (RMS-Prop), AdaDelta, Adaptive Moment Estimation (Adam). Advantages of BackpropagationThe key benefits of using the backpropagation algorithm are: Ease of Implementation: Backpropagation is beginner-friendly, requiring no prior neural network knowledge, and simplifies programming by adjusting weights via error derivatives. Simplicity and Flexibility: Its straightforward design suits a range of tasks, from basic feedforward to complex convolutional or recurrent networks. Efficiency: Backpropagation accelerates learning by directly updating weights based on error, especially in deep networks. Generalization: It helps models generalize well to new data, improving prediction accuracy on unseen examples. Scalability: The algorithm scales efficiently with larger datasets and more complex networks, making it ideal for large-scale tasks. Limitations and ChallengesWhile backpropagation is powerful, it does face some challenges: Vanishing Gradient Problem: In deep networks, the gradients can become very small during backpropagation, making it difficult for the network to learn. This is common when using activation functions like sigmoid or tanh. Exploding Gradients: The gradients can also become excessively large, causing the network to diverge during training. Overfitting: If the network is too complex, it might memorize the training data instead of learning general patterns. An Example of BackpropagationLet’s walk through an example of backpropagation in machine learning. Assume the neurons use the sigmoid activation function for the forward and backward pass. The target output is 0.5, and the learning rate is 1. Here’s how backpropagation is implemented: The Forward Pass Initial Calculation The weighted sum at each node is calculated using: Sigmoid Function The sigmoid function returns a value between 0 and 1, introducing non-linearity into the model. Computing Outputs At h1 node, Once, we calculated the a1 value, we can now proceed to find the y3 value: Similarly find the values of y4 at h2 and y5 at O3, Errors Calculation (The Loss Function) Note that, our actual output is 0.5 but we obtained 0.67. To calculate the error, we can use the below formula: Using this error value, we will be backpropagating. The Backward Pass Calculating Gradients The change in each weight is calculated as: Output Unit Error For O3: Hidden Unit Error For h1: For h2: Weight Updates The updated weights are illustrated below. Final Forward Pass: After updating the weights, the forward pass is repeated. y3 = 0.57 y4 = 0.56 y5 = 0.61 Since y5 = 0.61 is still not the target output, the process of calculating the error and backpropagating continues until the desired output is reached. This process demonstrates how backpropagation iteratively updates weights by minimizing errors until the network accurately predicts the output. This process is said to be continued until the actual output is gained by the neural network. Implementation in PythonThis code demonstrates how backpropagation is used in a neural network to solve the XOR problem. The neural network consists of: Input layer with 2 inputs, Hidden layer with 4 neurons, Output layer with 1 output neuron. Key steps: The Forward Pass: The inputs are passed through the network, activating the hidden and output layers using the sigmoid function. The Backward Pass (Backpropagation): The errors between the predicted and actual outputs are computed. The gradients are calculated using the derivative of the sigmoid function, and weights and biases are updated accordingly. Training: The network is trained over 10,000 epochs using the backpropagation algorithm with a learning rate of 0.1, progressively reducing the error. This implementation highlights how backpropagation adjusts weights and biases to minimize the loss and improve predictions over time. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import numpy as npclass NeuralNetwork: def __init__(self, input_size, hidden_size, output_size): self.input_size = input_size self.hidden_size = hidden_size self.output_size = output_size # Initialize weights self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) # Initialize the biases self.bias_hidden = np.zeros((1, self.hidden_size)) self.bias_output = np.zeros((1, self.output_size)) def sigmoid(self, x): return 1 / (1 + np.exp(-x)) def sigmoid_derivative(self, x): return x * (1 - x) def feedforward(self, X): # Input to hidden self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden self.hidden_output = self.sigmoid(self.hidden_activation) # Hidden to output self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output self.predicted_output = self.sigmoid(self.output_activation) return self.predicted_output def backward(self, X, y, learning_rate): # Compute the output layer error output_error = y - self.predicted_output output_delta = output_error * self.sigmoid_derivative(self.predicted_output) # Compute the hidden layer error hidden_error = np.dot(output_delta, self.weights_hidden_output.T) hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output) # Update weights and biases self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate def train(self, X, y, epochs, learning_rate): for epoch in range(epochs): output = self.feedforward(X) self.backward(X, y, learning_rate) if epoch % 4000 == 0: loss = np.mean(np.square(y - output)) print(f\"Epoch &#123;epoch&#125;, Loss:&#123;loss&#125;\")X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])y = np.array([[0], [1], [1], [0]])nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)nn.train(X, y, epochs=10000, learning_rate=0.1)# Test the trained modeloutput = nn.feedforward(X)print(\"Predictions after training:\")print(output) Output: 123456789Epoch 0, Loss:0.26804276270586413Epoch 4000, Loss:0.012477301332301533Epoch 8000, Loss:0.0029801470220045504Predictions after training:[[0.02330965] [0.95658721] [0.95049451] [0.05896647]] ConclusionBackpropagation is the engine that drives neural network learning. By propagating errors backward and adjusting the weights and biases, neural networks can gradually improve their predictions. Though it has some limitations like vanishing gradients, many techniques, such as using ReLU activation or optimizing learning rates, have been developed to address these issues.","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Neural Networks","slug":"Neural-Networks","permalink":"https://stephen-cheng.github.io/tags/Neural-Networks/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"},{"name":"Backpropagation","slug":"Backpropagation","permalink":"https://stephen-cheng.github.io/tags/Backpropagation/"}],"author":"Stephen Cheng"},{"title":"A Complete Guide to Neural Networks","slug":"A-Complete-Guide-to-Neural-Networks","date":"2024-09-17T18:19:25.000Z","updated":"2024-11-16T02:48:29.602Z","comments":true,"path":"2024/09/17/A-Complete-Guide-to-Neural-Networks/","link":"","permalink":"https://stephen-cheng.github.io/2024/09/17/A-Complete-Guide-to-Neural-Networks/","excerpt":"","text":"Stephen Cheng &nbsp; IntroArtificial Intelligence is a term used for machines that can interpret the data, learn from it, and use it to do such tasks that would otherwise be performed by humans. Deep Learning is a branch of Artificial Intelligence that focuses more on training the machines to learn on their own without much supervision. Deep Learning has witnessed tremendous growth in the last decade. With applications in image classification, speech recognition, text to speech conversion, self driving cars etc., the list of problems that Deep Learning has addressed is very significant. It is therefore necessary to understand the basic structure and working of Neural Networks to appreciate these advancements. What is a Neural Network?A neural network is a system or hardware that is designed to operate like a human brain. It can perform the following tasks: Translate text Identify faces Recognize speech Read handwritten text Control robots And a lot more A neural network is usually described as having different layers. The first layer is the input layer, it picks up the input signals and passes them to the next layer. The next layer does all kinds of calculations and feature extractions—it’s called the hidden layer. Often, there will be more than one hidden layer. And finally, there’s an output layer, which delivers the final result. How Does a Neural Network Work?Let’s take the real-life example of how traffic cameras identify license plates and speeding vehicles on the road. The image is 28 by 28 pixels, and the image is fed as an input to identify the license plate. Each neuron has a number, called activation, which represents the grayscale value of the corresponding pixel, ranging from 0 to 1 (It’s 1 for a white pixel and 0 for a black pixel). Each neuron is lit up when its activation is close to 1. Pixels in the form of arrays are fed into the input layer (If your image is bigger than 28 by 28 pixels, you must shrink it down, because you can’t change the size of the input layer). In our example, we’ll name the inputs as X1, X2, and X3. Each of those represents one of the pixels coming in. The input layer then passes the input to the hidden layer. The interconnections are assigned weights at random. The weights are multiplied with the input signal, and a bias is added to all of them. The weighted sum of the inputs is fed as input to the activation function, to decide which nodes to fire for feature extraction. As the signal flows within the hidden layers, the weighted sum of inputs is calculated and is fed to the activation function in each layer to decide which nodes to fire. Finally, the model will predict the outcome, applying a suitable application function to the output layer. In our example with the car image, optical character recognition (OCR) is used to convert it into text to identify what’s written on the license plate. In the neural network example, we show only three dots coming in, eight hidden layer nodes, and one output, but there’s really a huge amount of input and output. Error in the output is back-propagated through the network and weights are adjusted to minimize the error rate. This is calculated by a cost function. We keep adjusting the weights until they fit all the different training models we put in. The output is then compared with the original result, and multiple iterations are done for maximum accuracy. With every iteration, the weight at every interconnection is adjusted based on the error. Essential Components of Neural NetworksA neural network is a computational learning system that maps input variables to the output variable using an underlying mapping function that is non linear in nature. The architecture of a neural network comprises five essential components: Layers Nodes Activation Function Loss Function Optimizer We will learn about each of these components in detail. 1.LayersSimply put, a Neural Network is a stack of layers, interconnected to each other. There are three types of layers in a Neural Network: Input Layer takes the input data, Hidden Layer transforms the input data, Output Layer generates prediction for the given inputs after applying transformations. The layers close to the Input Layer are called the Lower layers, the layers close to the Output Layer are called the Upper Layers. 2. NodesEach layer consists of multiple neurons, also called Nodes. Each node in a given layer is connected to each node in the next layer. The nodes take the weighted sum of the inputs from the previous layer, applies a non linear activation function to it and generates an output which then becomes an input to the nodes in the next layer. The number of nodes in the input layer correspond to the number of independent variables in the data . The number of hidden layers and the nodes in these layers is a hyperparameter and usually is a function of the complexity of the problem and the data available. For a regression problem, the number of nodes in the output layer is one; for a multiclassification problem, the number of nodes in the output layer is equal to the number of labels / categories, for a binary classification problem, the number of nodes in the output layer is equal to 1. Each connection between neurons carries a weight that determines the strength of their influence on the data’s transformation. For any arbitrary function f there exist a neuronal network. The goal is to find the best parameters 𝜃 (weights) which result in the best decision boundary. Thus, a neuron can be defined as an operation that has two parts — linear component and an activation component i.e. Neuron = Linear + Activation. How Nodes Work in LayersLet’s consider the illustration below. There is a dataset on the left. Typically, the dataset consists of some features denoted as X. In this case, we have two features, X1 and X2, for each sample. Additionally, there is a label Y, also referred to as the target or class, associated with each sample. To learn the relationship between features X1 and X2 and their corresponding label, we utilize a neural network consisting of 2 input nodes (owing to the two features), one hidden layer with 3 neurons (the number of hidden layers and neurons can be adjusted as hyperparameters), and one output neuron. A weight matrix is associated with each layer. In this instance, there exists a hidden layer and an output layer, resulting in two weight matrices. These weights are initialized randomly, and throughout the training process, they are iteratively updated until the loss converges. A weight matrix always has the dimension n x m: n neurons in the previous layer (input layer or a previous hidden layer). m neurons in the current hidden layer. The illustration below shows how a neural network results in a specific function. Each node in a hidden layer has the following function: a = ReLU(weights * input + bias), where a refers to an activation function, such as ReLu. The last node a7 is a combination of all previous functions, resulting in one single non-linear function. To understand the combination of functions, we can take node a4 as an example. We can see that node a4 depends on the functions of nodes a1 to a3, which in turn depend on the input x. In particular, the value of node a4 is calculated by ReLU(weights * input + bias). In this case the bias is -1, the weights are 0.3, 0.2 and 0.1. And the input is the output of the previous three nodes a1, a2 and a3. In this illustration we use ReLU as activation function, which simply is max(0, z). 3.Activation FunctionAn activation function is used to transform the input from a node to an output value that is fed to the node in the next hidden layer. In technical terms, an activation function, also known as a transfer function, defines how the weighted sum of the inputs and the bias is transformed into an output from the node in a given layer. It maps the output value in a given range i.e. 0 to 1 or -1 to +1 depending on the type of function used. Generally one activation function is used across all layers, exception being the output layer. There are different types of activation functions used in Neural Networks, and they have two types — linear and non-linear. Linear Activation Function: The range of this function is: —infinity to +infinity. A linear activation function is used in outer layer of the neural network when solving regression problems. It is not a good idea to use it in the input or hidden layers cause the network will not be able to capture the complex relationships in the underlying data. Non-Linear Activation Function: Non-Linear activation functions are by default, the most used activation function in Deep Learning. These include Sigmoid or Logistic function, Rectified Linear Activation (ReLU), and Hyperbolic Tangent (Tanh). Next, let’s understand each of them in more detail. Sigmoid Function: The Sigmoid activation function, also called the Logistic function, compresses values between 0 and 1, which can be interpreted as a probability that the input belongs to a specific class. It takes in any real value as input and gives an output in the range of 0 and 1. Given as y = 1/(1+ e^-z), it has a S shaped curve. Here z = b + sigma(xi * wi), indexed over i input variables. For a very large positive number z, e^-z will be 0 and the output of the function will be 1. For a very large negative number z, e^-z will be a large number and thus the output of the function will be 0. Sigmoid function is frequently employed as an activation function for the output in binary classification problems. However, it yields very small gradients that can lead to neural network stagnation. Additionally, it causes gradients to vanish beyond 1 and 0, respectively. Implementation in Python: 123456# sigmoid functiondef sigmoid(z): return 1.0 / (1 + np.exp(-z))# Derivative of sigmoid functiondef sigmoid_prime(z): return sigmoid(z) * (1-sigmoid(z)) Hyperbolic Tangent Function: The hyperbolic tangent function is similar to the sigmoid function but has a range of -1 to 1. It is given as : f(x) = (e^z — e^-z) / (e^z+e^-z). Here z = b + sigma(xi * wi), indexed over i input variables. The shape of Tanh function is also S shaped but the range is different. Derivative function give us almost same as sigmoid’s derivative function. Implementation in Python: 123456# tanh activation functiondef tanh(z): return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))# Derivative of Tanh Activation Functiondef tanh_prime(z): return 1 - np.power(tanh(z), 2) ReLU (Rectified Linear Unit) Function: ReLu is today, the most used activation function. ReLU has a property of being linear for all input values greater than 0 and non-linear otherwise. It is computationally efficient, because it uses only a simple thresholding operation. It is given as f(x) = max(0, x) It is less susceptible to vanishing gradient problem because the gradients are 1 if x &gt; 0. However, every negative value results in a gradient of zero, which means the weights will never be updated, resulting in a dead neuron. Implementation in Python: 123456# ReLU activation functiondef relu(z): return max(0, z)# Derivative of ReLU Activation Functiondef relu_prime(z): return 1 if z &gt; 0 else 0 Leaky ReLU: Leaky ReLU prevents dying ReLU problem. This variation of ReLU has a small positive slope in the negative area, so it does enable back-propagation, even for negative input values. Leaky ReLU does not provide consistent predictions for negative input values. During the front propagation if the learning rate is set very high it will overshoot killing the neuron. The idea of leaky ReLU can be extended even further. Instead of multiplying x with a constant term we can multiply it with a hyper-parameter which seems to work better the leaky ReLU. This extension to leaky ReLU is known as Parametric ReLU. While we compare Leaky-ReLU with ReLU, then it shows clear concept of difference between them. Implementation in Python: 123456# Leaky_ReLU activation functiondef leakyrelu(z, alpha): return max(alpha * z, z)# Derivative of leaky_ReLU Activation Functiondef leakyrelu_prime(z, alpha): return 1 if z &gt; 0 else alpha Softmax: Softmax is genereally used at last layer of neural network which calculates the probabilities distribution of the event over n different events. The main advantage of the function is able to handle multiple classes. when we compare the sigmoid and softmax activation functions , they produce different results: Input values: -0.5, 1.2, -0.1, 2.4 Sigmoid output values: 0.37, 0.77, 0.48, 0.91 SoftMax output values: 0.04, 0.21, 0.05, 0.70 Sigmoid’s probabilities produced by a Sigmoid are independent. Furthermore, they are not constrained to sum to one: 0.37 + 0.77 + 0.48 + 0.91 = 2.53. The reason for this is because the Sigmoid looks at each raw output value separately. Whereas Softmax’s the outputs are interrelated. The Softmax probabilities will always sum to one by design: 0.04 + 0.21 + 0.05 + 0.70 = 1.00. In this case, if we want to increase the likelihood of one class, the other has to decrease by an equal amount. Threshold Function: The threshold function is used when you don’t want to worry about the uncertainty in the middle. 4.Loss FunctionThe predicted value is compared with actual value and the error is computed. The magnitude of the error is given by the loss function. The loss function will estimate how close the distribution of the predicted value is to distribution of the actual target variable in the training data. The Maximum Likelihood Estimation (MLE) framework is used to compute the error over the entire training data. It does this by estimating how closely the distribution of the predictions matches with the distribution of the target variable in the training data. The loss function under the MLE framework for classification problem is Cross Entropy, and for regression problem is Mean Squared Error. Cross Entropy Loss: Cross Entropy gives the measure of the difference between two probability distributions of a random variable. In the context of the Neural Networks, it gives the difference between the predicted probability distribution and the distribution of the target variable in the training data set for a given set of weights or parameters. For a binary classification problem, the loss function used is binary cross entropy and for a multiclass classification problem, the loss function used is categorical cross entropy. Binary Cross Entropy Loss: In case of a binary classification problem, where the target variable only has two options, class 1 or class 0, we use binary cross entropy loss to understand how bad the prediction was by measuring the dissimilarity between predicted probabilities and the actual target values. It is important to note that we only have one output node in binary classification tasks. This output node uses the sigmoid activation function, which squeezes values between 0 and 1. We use sigmoid, because the output value close to 1 can be interpreted as a high probability of the input belonging to one class, while an output value close to 0 indicates a high probability of belonging to the other class. Binary Cross-Entropy Loss: L = - (y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred)). The prediction for the first sample was 0.7 and the target was 1. If we pass this into the binary cross-entropy loss function we get a loss of 0.15: L = - (1 * log(0.7) + (1 - 1) * log(1 - 0.7)) = - log(0.7) = 0.15. Similarly, the second sample yields the prediction 0.4 and the target was 0, thus the loss is 0.2: L = - (0 * log(0.4) + (1 - 0) * log(1 - 0.4)) = - log(1-0.4) = 0.2. Categorical Cross Entropy Loss: In case of a multiclass classification problem, where the target variable is encoded as 1 to n-1 categories, the categorical cross entropy will calculate the score that summarizes the average difference between the actual and predicted probability distributions for all the classes. The loss is averaged over all samples. If we want to classify an input that has more than two target classes, we use an architecture that has one output neuron for each class. First of all, we have to encode all labels as one-hot-encode, thus, if we have three classes we have an array of size three, as label for each class. The last layer uses softmax instead of sigmoid. Softmax function is typically used in multi class classification problems. It is applied to the outputs of all nodes in the output layer of a neural network. The output of the function is a vector of values between 0 and 1 that sum to 1. Mean Squared Error: In regression, we have only one output node and no activation function. As Loss function we use Mean Squared Error (MSE). MSE is the most commonly used loss function for a regression problem. MSE is calculated as the average of the squared difference between the predicted and actual values of the target variable. The output is always positive as it is a square of the error. MSE penalizes larger prediction errors more significantly due to the squaring operation. This means that outliers or instances with larger errors contribute more to the overall loss. Minimizing MSE during training encourages the model to adjust its parameters to make predictions that closely match the actual target values, resulting in a regression model that provides accurate estimations. There are variants to the MSE like the Mean Squared Logarithmic Error Loss (MSLE) and Mean Absolute Error (MAE). The choice depends on number of factors like presence of outliers , distribution of the target variable and others. Mean-squared error: L = (y_true - y_pred)² 5. OptimizerThe output generated by the network in the first forward pass is a result of the weights that were initialized to some random values. The loss function compares the actual and predicted values and computes the error. The next step is to minimize the error by changing the weights. How does the network achieve this? This is achieved by using an optimizer together with backpropagation (The Backpropagation algorithm involves two main steps: the Forward Pass and the Backward Pass). Optimizers are algorithms or methods used to minimize an error function(loss function)or to maximize the efficiency of production. Optimizers are mathematical functions which are dependent on model’s learnable parameters i.e Weights &amp; Biases. Optimizers help to know how to change weights and learning rate of neural network to reduce the losses. There are different types of optimizers, such as Gradient Descent algorithm, Stochastic Gradient Descent (SGD), Mini-Batch Gradient Descent, SGD with Momentum, Adaptive Gradient Descent (AdaGrad), Root Mean Square Propagation (RMS-Prop), AdaDelta, Adaptive Moment Estimation (Adam), etc. Types of Neural NetworksThere are different types of neural networks. Feed-forward Neural NetworkThis is the simplest form of ANN (artificial neural network); data travels only in one direction (input to output). This is the example we just looked at. When you actually use it, it’s fast. When you’re training it, it takes a while. Almost all vision and speech recognition applications use some form of this type of neural network. Recurrent Neural NetworkIn this type, the hidden layer saves its output to be used for future prediction. The output becomes part of its new input. Applications include text-to-speech conversion. Convolution Neural NetworkIn Convolution Neural Network, the input features are taken in batches, as if they pass through a filter. This allows the network to remember an image in parts. Applications include signal and image processing, such as facial recognition. Radial Basis Functions Neural NetworkThis model classifies the data point based on its distance from a center point. If you don’t have training data, for example, you’ll want to group things and create a center point. The network looks for data points that are similar to each other and groups them. One of the applications for this is power restoration systems. Kohonen Self-organizing Neural NetworkVectors of random input are input to a discrete map comprised of neurons. Vectors are also called dimensions or planes. Applications include using it to recognize patterns in data like a medical analysis. Modular Neural NetworkThis is composed of a collection of different neural networks working together to get the output. This is cutting-edge and is still in the research phase.","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Neural Networks","slug":"Neural-Networks","permalink":"https://stephen-cheng.github.io/tags/Neural-Networks/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"}],"author":"Stephen Cheng"},{"title":"K-Means vs DBSCAN - Clustering Algorithms for Grouping Data","slug":"K-Means-vs-DBSCAN-Clustering-Algorithms-for-Grouping-Data","date":"2024-09-03T19:51:16.000Z","updated":"2024-11-16T02:48:44.951Z","comments":true,"path":"2024/09/03/K-Means-vs-DBSCAN-Clustering-Algorithms-for-Grouping-Data/","link":"","permalink":"https://stephen-cheng.github.io/2024/09/03/K-Means-vs-DBSCAN-Clustering-Algorithms-for-Grouping-Data/","excerpt":"","text":"Stephen Cheng &nbsp; IntroClustering is a popular unsupervised machine learning technique used to identify groups of similar objects in a dataset. It has numerous applications in various fields, such as image recognition, customer segmentation, and anomaly detection. Two popular clustering algorithms are DBSCAN and K-Means. Each of these algorithms excels in different scenarios and has distinct advantages and limitations. In this guide, we will explore the key differences between DBSCAN and K-Means and how to implement them in Python using scikit-learn, a popular machine learning library. We will also discuss when to use each algorithm based on the characteristics of the dataset and the problem at hand. So let’s dive in! K-Means Clustering AlgorithmK-Means is a centroid-based algorithm that partitions data into k clusters based on the mean distance between points and their assigned centroid. The algorithm aims to minimize the sum of squared distances between each point and its assigned centroid. K-Means is widely used due to its simplicity and efficiency. How K-Means Works Choose K: Start by selecting the number of clusters K. Initialize Centroids: Randomly place K centroids (one for each cluster) in the data space. Assign Points to Clusters: Assign each data point to the nearest centroid based on Euclidean distance. Update Centroids: Recalculate the centroids by taking the mean of all data points assigned to each cluster. Repeat: Repeat the assignment and update steps until the centroids no longer change significantly (convergence). Mathematical Representation Given a set of data points X={x1,x2,…,xn}, K-Means aims to minimize the following objective function: Where: K is the number of clusters, Ci is the set of points in cluster i, μi*​ is the centroid of cluster *i, |x−μi|² is the squared distance between point x and the centroid μi. Advantages of K-Means Simplicity: Easy to implement and computationally efficient, making it suitable for large datasets. Scalability: K-Means performs well with a large number of data points and clusters. Interpretability: The algorithm is intuitive, and the results are easy to interpret visually, especially in 2D space. Limitations of K-Means Predefined Number of Clusters: The number of clusters K must be defined beforehand, which can be difficult to determine. Sensitivity to Outliers: K-Means is highly sensitive to outliers, as they can disproportionately affect the position of centroids. Non-Spherical Clusters: K-Means assumes clusters are spherical and evenly sized, making it ineffective for complex, irregularly shaped clusters. Implementation in Python To implement K-Means in Python, we can use the scikit-learn library. Here’s an example. We initialize a KMeans object with n_clusters (the number of clusters to form) set to 3 and fit the model on our dataset X. 1234567from sklearn.cluster import KMeans# Create a KMeans instance with 3 clusterskmeans = KMeans(n_clusters=3)# Fit the model to datakmeans.fit(X)# Predict cluster labels for new data pointslabels = kmeans.predict(new_data) DBSCAN Clustering AlgorithmDBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. It is a density-based algorithm that groups together points that are close to each other based on a density criterion. Points that are not part of any cluster are considered noise. DBSCAN is particularly useful when dealing with datasets that have irregular shapes and different densities. How DBSCAN Works Choose Parameters: Set the distance threshold ε and the minimum number of points MinPts required to form a dense region (core point). Core Points and Neighborhoods: Identify core points that have at least MinPts points within the ε-radius neighborhood. Cluster Formation: Form clusters by connecting core points and their neighbors. Handle Noise: Any point that is not part of a core point’s neighborhood and cannot be assigned to any cluster is classified as noise. Mathematical Representation A point p is core point if there are at least MinPts points within ε-radius neighborhood of p. Formally, the neighborhood N(p) of point p is defined as: where: D is the dataset, dist(p,q) is the distance between points p and q, ε is the maximum distance threshold. Advantages of DBSCAN No Need for Predefined Clusters: DBSCAN can automatically determine the number of clusters based on the density of data points. Handles Noise and Outliers: DBSCAN can identify outliers as noise, making it robust to noisy data. Clusters of Arbitrary Shapes: DBSCAN can identify clusters of various shapes, not just spherical ones, making it versatile for complex datasets. Limitations of DBSCAN Sensitive to Parameter Choice: The performance of DBSCAN heavily depends on the correct choice of ε and MinPts. Inappropriate parameter selection can lead to poor results. Not Ideal for Varying Densities: DBSCAN struggles when clusters have varying densities, as it may merge dense and sparse regions into the same cluster. High-Dimensional Data: DBSCAN’s performance degrades in high-dimensional data because the concept of distance becomes less meaningful in higher dimensions (the curse of dimensionality). Implementation in Python Let’s take a look at some Python code examples for implementing these algorithms. We first initialize a DBSCAN object with eps (the radius of neighborhood) set to 0.5 and min_samples (the minimum number of points required to form a dense region) set to 5. We then fit the model on our dataset X. 1234# Example of using DBSCANfrom sklearn.cluster import DBSCANdbscan = DBSCAN(eps=0.5, min_samples=5)dbscan.fit(X) Differences Between K-Means and DBSCAN Use K-Means if: You Know the Number of Clusters: K-Means is a good choice when you already have an idea of how many clusters K exist in the data. The Data is Well-Separated: If the clusters are compact and well-separated in Euclidean space, K-Means can efficiently identify them. You Have a Large Dataset: K-Means is computationally efficient and can handle large datasets quickly. Example: A customer segmentation task where the dataset is large and consists of distinct, evenly distributed clusters would be ideal for K-Means clustering. Use DBSCAN if: You Don’t Know the Number of Clusters: DBSCAN automatically identifies the number of clusters based on the density of the data, making it useful when you don’t have prior knowledge of K. You Have Irregularly Shaped Clusters: DBSCAN excels at finding clusters that are non-spherical or complex in shape, such as clusters in spatial data. You Want to Handle Outliers: If your dataset contains noise or outliers, DBSCAN can effectively separate noise from the dense regions of the data. Example: In a geographical mapping application, where data points (e.g., earthquake epicenters) are scattered irregularly and outliers need to be identified, DBSCAN is an ideal choice. ConclusionK-Means is a simple and fast algorithm that works well when the data is well-separated into clusters. However, it requires the number of clusters to be specified beforehand, which can be a challenge in real-world applications where the number of clusters is not known. On the other hand, DBSCAN is a more flexible algorithm that does not require the number of clusters to be specified beforehand. It can also handle noise and outliers well. However, it may not work well when the density of the data points varies greatly across different parts of the dataset. Both algorithms have their strengths and weaknesses, so it’s important to experiment with both and compare their results before making a final decision. By leveraging existing libraries such as scikit-learn in Python, you can easily apply these algorithms to your own datasets and gain valuable insights into your data.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"DBSCAN","slug":"DBSCAN","permalink":"https://stephen-cheng.github.io/tags/DBSCAN/"},{"name":"Clustering","slug":"Clustering","permalink":"https://stephen-cheng.github.io/tags/Clustering/"},{"name":"Kmeans","slug":"Kmeans","permalink":"https://stephen-cheng.github.io/tags/Kmeans/"}],"author":"Stephen Cheng"},{"title":"Evaluation Metrics for Classification Models","slug":"Evaluation-Metrics-for-Classification-Models","date":"2024-06-24T15:48:16.000Z","updated":"2024-11-16T02:48:59.194Z","comments":true,"path":"2024/06/24/Evaluation-Metrics-for-Classification-Models/","link":"","permalink":"https://stephen-cheng.github.io/2024/06/24/Evaluation-Metrics-for-Classification-Models/","excerpt":"","text":"Stephen Cheng &nbsp; IntroFor supervised learning models, evaluation typically involves comparing the predictions made by the model with the ground truth labels that are provided in the dataset. Here are some common evaluation metrics used for assessing the performance of classification models. Confusion MatrixA confusion matrix (or, error matrix) is a visualization method for classifier algorithm results. More specifically, it is a table that breaks down the number of ground truth instances of a specific class against the number of predicted class instances. Accuracy: [(TP + TN) / (TP + TN + FP + FN)] Measures the proportion of correctly classified instances out of the total instances. It’s suitable for balanced datasets but can be misleading for imbalanced datasets. Higher accuracy values indicate a higher proportion of correct predictions. Precision: TP / (TP + FP) or predicted positives Measures the proportion of true positive predictions out of all positive predictions. Higher precision values indicate fewer false positive predictions. Precision is useful when the cost of false positives is high. Recall (Sensitivity)/TPR: TP / (TP + FN) or actual positives Measures the proportion of true positive predictions out of all actual positives. It focuses on the ability of the model to capture positive instances. Higher recall values indicate fewer false negative predictions. Specificity/TNR : TN / (TN + FP) or actual negatives Specificity, also known as the true negative rate, is a metric used in binary classification tasks to evaluate the performance of a model in correctly identifying negative instances (actual negatives). Higher specificity values indicate fewer false positive predictions. False Positive Rate (FPR): FP / (FP + TN) or actual negatives Also known as the false alarm rate, it is a metric used in binary classification tasks to evaluate the performance of a model in correctly identifying negative instances. It is the complement of specificity. Lower FPR values indicate fewer false positive predictions. F1-score: 2 * (Precision * Recall) / (Precision + Recall) The harmonic mean of precision and recall provides a balance between the two metrics. It’s useful when there’s an uneven class distribution. Implementation with Python123456789101112131415161718192021222324252627282930313233from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix# Example ground truth and predicted labelsy_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]y_pred = [1, 1, 1, 0, 1, 1, 0, 0, 0, 1]# Calculate accuracyaccuracy = accuracy_score(y_true, y_pred)print(\"Accuracy:\", accuracy)# Calculate precisionprecision = precision_score(y_true, y_pred)print(\"Precision:\", precision)# Calculate recallrecall = recall_score(y_true, y_pred)print(\"Recall:\", recall)# Calculate F1-scoref1 = f1_score(y_true, y_pred)print(\"F1-score:\", f1)# Calculate confusion matrixconf_matrix = confusion_matrix(y_true, y_pred)print(\"Confusion Matrix:\")print(conf_matrix)# Calculate False Positive Rate (FPR)TN = conf_matrix[0, 0]FP = conf_matrix[0, 1]FPR = FP / (FP + TN)print(\"False Positive Rate (FPR):\", FPR)","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Classification","slug":"Classification","permalink":"https://stephen-cheng.github.io/tags/Classification/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Evaluation Metrics","slug":"Evaluation-Metrics","permalink":"https://stephen-cheng.github.io/tags/Evaluation-Metrics/"}],"author":"Stephen Cheng"},{"title":"The Guide to K-Fold Cross Validation in Machine Learning","slug":"The-Guide-to-K-Fold-Cross-Validation-in-Machine-Learning","date":"2024-04-15T13:16:30.000Z","updated":"2024-11-16T02:49:10.268Z","comments":true,"path":"2024/04/15/The-Guide-to-K-Fold-Cross-Validation-in-Machine-Learning/","link":"","permalink":"https://stephen-cheng.github.io/2024/04/15/The-Guide-to-K-Fold-Cross-Validation-in-Machine-Learning/","excerpt":"","text":"Stephen Cheng &nbsp; IntroIn machine learning, if a model simply memorizes the labels of the training samples, it may achieve a perfect score on the training data but fail to make meaningful predictions on new-unseen data. This problem is known as overfitting. To avoid it, it is standard practice in supervised learning to set aside a portion of the data, called the test set (X_test, y_test), for evaluating the model’s performance. That is where K-Fold Cross-Validation comes in. It offers a sneak peek at how your model might fare in the real world. In this guide, we will unpack the basics of K-Fold Cross-Validation and compare it to simpler methods like the Train-Test Split. Cross Validation WorkflowK-Fold Cross-Validation is a robust technique used to evaluate the performance of machine learning models. It helps ensure that the model generalizes well to unseen data by using different portions of the dataset for training and testing in multiple iterations. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by grid search techniques. K-Fold Cross-Validation vs Train-Test SplitWhile K-Fold Cross-Validation partitions the dataset into multiple subsets to iteratively train and test the model, the Train-Test Split method divides the dataset into just two parts: one for training and the other for testing. The Train-Test Split method is simple and quick to implement, but the performance estimate can be highly dependent on the specific split, leading to high variance in the results. The images below illustrate the structural differences between these two methods. The first image shows the Train-Test Split method, where the dataset is divided into 80% training and 20% testing segments. The second image depicts a 5-Fold Cross-Validation, where the dataset is split into five parts, with each part serving as a test set in one of the five iterations, ensuring each segment is used for both training and testing. We can see that K-Fold Cross-Validation provides a more robust and reliable performance estimate because it reduces the impact of data variability. By using multiple training and testing cycles, it minimizes the risk of overfitting to a particular data split. This method also ensures that every data point is used for both training and validation, which results in a more comprehensive evaluation of the model’s performance. What Does ‘K’ Represent in K-Fold Cross-Validation?In K-Fold Cross-Validation, K represents the number of groups into which the dataset is divided. This number determines how many rounds of testing the model undergoes, ensuring each segment is used as a testing set once. Here is a heuristic: K = 2 or 3: These choices can be beneficial when computational resources are limited or when a quicker evaluation is needed. They reduce the number of training cycles, thus saving time and computational power while still providing a reasonable estimate of model performance. K = 5 or 10: Choosing K = 5 or K = 10 are popular choices because they provide a good balance between computational efficiency and model performance estimation. K = 20: Using a larger value of K can provide a more detailed performance evaluation. However, it increases the computational burden and might result in higher variance if the subsets are too small. Implementing K-Fold Cross-Validation in PythonThe following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time). 1234from sklearn.model_selection import cross_val_scoreclf = svm.SVC(kernel='linear', C=1, random_state=42)scores = cross_val_score(clf, X, y, cv=5)scores array([0.96…, 1. , 0.96…, 0.96…, 1. ]) The mean score and the standard deviation are hence given by: 1print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std())) 0.98 accuracy with a standard deviation of 0.02 By default, the score computed at each CV (Cross Validation) iteration is the score method of the estimator. It is possible to change this by using the scoring parameter: 1234from sklearn import metricsscores = cross_val_score( clf, X, y, cv=5, scoring='f1_macro')scores array([0.96…, 1. …, 0.96…, 0.96…, 1. ]) When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin. It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance: 1234from sklearn.model_selection import ShuffleSplitn_samples = X.shape[0]cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)cross_val_score(clf, X, y, cv=cv) array([0.977…, 0.977…, 1. …, 0.955…, 1. ]) ConclusionThis guide has shown you how K-Fold Cross-Validation is a powerful tool for evaluating machine learning models. It’s better than the simple Train-Test Split because it tests the model on various parts of your data, helping you trust that it will work well on unseen data too.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Cross Validation","slug":"Cross-Validation","permalink":"https://stephen-cheng.github.io/tags/Cross-Validation/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"}],"author":"Stephen Cheng"},{"title":"The Stages of a Machine Learning Pipeline\n","slug":"The-stages-of-a-machine-learning-pipeline","date":"2024-02-06T14:00:31.000Z","updated":"2024-11-16T02:49:18.711Z","comments":true,"path":"2024/02/06/The-stages-of-a-machine-learning-pipeline/","link":"","permalink":"https://stephen-cheng.github.io/2024/02/06/The-stages-of-a-machine-learning-pipeline/","excerpt":"","text":"Stephen Cheng &nbsp; IntroMachine learning technology is advancing at a rapid pace, but we can identify some broad steps involved in the process of building and deploying machine learning and deep learning models. A machine learning pipeline is a series of interconnected data processing and modeling steps designed to automate, standardize and streamline the process of building, training, evaluating and deploying machine learning models. Data CollectionIn this initial stage, new data is collected from various data sources, such as databases, APIs or files. This data ingestion often involves raw data which may require preprocessing to be useful. Data PreprocessingThis stage involves cleaning, transforming and preparing input data for modeling. Common preprocessing steps include handling missing values, encoding categorical variables, scaling numerical features and splitting the data into training and testing sets. Feature EngineeringFeature engineering is the process of creating new features or selecting relevant features from the data that can improve the model’s predictive power. This step often requires domain knowledge and creativity. Model SelectionIn this stage, you choose the appropriate machine learning algorithm(s) based on the problem type (e.g., classification, regression, clustering), data characteristics, and performance requirements. You may also consider hyperparameter tuning. Model TrainingThe selected model(s) are trained on the training dataset using the chosen algorithm(s). This involves learning the underlying patterns and relationships within the training data. Pre-trained models can also be used, rather than training a new model. Model EvaluationAfter training, the model’s performance is assessed using a separate testing dataset or through cross-validation. Common evaluation metrics depend on the specific problem but may include accuracy, precision, recall, F1-score, mean squared error or others. Model DeploymentOnce a satisfactory model is developed and evaluated, it can be deployed to a production environment where it can make predictions on new, unseen data. Deployment may involve creating APIs and integrating with other systems. Monitoring and MaintenanceAfter deployment, it’s important to continuously monitor the model’s performance and retrain it as needed to adapt to changing data patterns. This step ensures that the model remains accurate and reliable in a real-world setting. ConclusionMachine learning lifecycles can vary in complexity and may involve additional steps depending on the use case, such as hyperparameter optimization, cross-validation, and feature selection. The goal of a machine learning pipeline is to automate and standardize these processes, making it easier to develop and maintain ML models for various applications.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Pipeline","slug":"Pipeline","permalink":"https://stephen-cheng.github.io/tags/Pipeline/"}],"author":"Stephen Cheng"},{"title":"Data Collection and File Handling in Python","slug":"Data-Collection-and-File-Handling-in-Python","date":"2023-12-21T17:19:38.000Z","updated":"2024-11-12T03:54:12.958Z","comments":true,"path":"2023/12/21/Data-Collection-and-File-Handling-in-Python/","link":"","permalink":"https://stephen-cheng.github.io/2023/12/21/Data-Collection-and-File-Handling-in-Python/","excerpt":"","text":"&nbsp; Stephen Cheng IntroGathering data is a critical first step in any data science project. Python provides versatile tools for collecting, importing, and saving data from various sources, such as CSV, Excel, JSON, and databases. This guide highlights key techniques and libraries to help you manage, process, and store data efficiently for analysis and modeling. How to Gather DataHere’s an improved and detailed breakdown of the different methods to gather data. Through Surveys and Forms: Online surveys, interviews, focus groups. Internal Data Sources: Company databases, CRM systems. Data from Sensors and IoT Devices: Smart devices, IoT platforms. Public Datasets: Government websites, research institutions, open data portals. Web Scraping: Automated tools, APIs, ethical considerations. Collaborations and Partnerships: Academic and industry partnerships. Purchase Data: Data vendors, market research firms. Crowdsourcing: Crowdsourcing platforms, open innovation challenges. Simulated Data: Synthetic data generation, simulation models. Importing Data from Different Types of FilesIn data science projects, data often comes from various sources and formats. Python provides several libraries to efficiently handle different types of files. In this guide, we’ll explore how to import data from CSV, Excel, JSON, and SQLite databases. Importing Data from CSV Files CSV (Comma-Separated Values) files are simple text files used to store tabular data. Python’s pandas library is highly efficient for handling CSV files. 12345import pandas as pd# Load data from a CSV filecsv_data = pd.read_csv('books.csv')# Display the first few rows of the DataFrameprint(csv_data.head()) Importing Data from Excel Files Excel files are common for data storage and analysis. The pandas library, can be used to read Excel files. 12345import pandas as pd# Load data from an Excel fileexcel_data = pd.read_excel('weather.xlsx')# Display the first few rows of the DataFrameprint(excel_data.head()) Importing Data from JSON Files JSON (JavaScript Object Notation) is a widely-used format for data interchange, especially with APIs. Python’s json library and pandas can handle JSON files efficiently. 123456789import pandas as pdimport json# Load data from a JSON filewith open('latest_launch.json', 'r') as file: json_data = json.load(file)# Convert JSON data to a DataFramejson_df = pd.json_normalize(json_data)# Display the DataFrameprint(json_df.head()) Importing Data from SQLite Databases SQLite is a lightweight, disk-based database. The sqlite3 module in Python, along with pandas, can be used to query and import data from SQLite databases. 1234567891011import sqlite3import pandas as pd# Connect to the SQLite databaseconn = sqlite3.connect('users.db')# Query the data and load it into a DataFramesql_query = \"SELECT * FROM users\"db_data = pd.read_sql_query(sql_query, conn)# Close the database connectionconn.close()# Display the DataFrameprint(db_data.head()) Gathering Data by Web scraping 123456789101112131415161718192021import requestsfrom bs4 import BeautifulSoupimport csvurl = 'http://books.toscrape.com/'response = requests.get(url)soup = BeautifulSoup(response.content, 'html.parser')# Find all book itemsbooks = soup.find_all('article', class_='product_pod')# Open a CSV file to write the datawith open('books.csv', 'w', newline='') as file: writer = csv.writer(file) writer.writerow(['Title', 'Price']) # Write data to CSV for book in books: title = book.h3.a['title'] price = book.find('p', class_='price_color').text writer.writerow([title, price])print(\"Data has been written to books.csv\") Saving Data to Different Types of Files in Python Saving Data to CSV Files CSV (Comma-Separated Values) files are simple text files used to store tabular data. Python’s pandas library is highly efficient for handling CSV files. 1234567891011import pandas as pd# Create a sample DataFramedata = &#123; 'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [30, 25, 35], 'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com']&#125;df = pd.DataFrame(data)# Save the DataFrame to a CSV filedf.to_csv('users.csv', index=False)print(\"Data has been written to users.csv\") Saving Data to Excel Files Excel files are common for data storage and analysis. The pandas library can be used to write Excel files. 1234567891011import pandas as pd# Create a sample DataFramedata = &#123; 'City': ['New York', 'Los Angeles', 'Chicago'], 'Temperature': [25, 30, 20], 'Description': ['Sunny', 'Cloudy', 'Rainy']&#125;df = pd.DataFrame(data)# Save the DataFrame to an Excel filedf.to_excel('weather.xlsx', index=False)print(\"Data has been written to weather.xlsx\") Saving Data to JSON Files JSON (JavaScript Object Notation) is a widely-used format for data interchange, especially with APIs. Python’s json library and pandas can handle JSON files efficiently. 1234567891011import pandas as pd# Create a sample DataFramedata = &#123; 'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [30, 25, 35], 'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com']&#125;df = pd.DataFrame(data)# Save the DataFrame to a JSON filedf.to_json('users.json', orient='records', indent=4)print(\"Data has been written to users.json\") Saving Data to SQLite Databases SQLite is a lightweight, disk-based database. The sqlite3 module in Python, along with pandas, can be used to store data in SQLite databases. 12345678910111213141516import sqlite3import pandas as pd# Create a sample DataFramedata = &#123; 'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [30, 25, 35], 'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com']&#125;df = pd.DataFrame(data)# Connect to the SQLite database (or create it)conn = sqlite3.connect('users.db')# Save the DataFrame to the SQLite databasedf.to_sql('users', conn, if_exists='replace', index=False)# Close the database connectionconn.close()print(\"Data has been written to users.db\")","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/categories/Data-Science/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Data Collection","slug":"Data-Collection","permalink":"https://stephen-cheng.github.io/tags/Data-Collection/"}],"author":"Stephen Cheng"},{"title":"Working with Text in R","slug":"Working-with-Text-in-R","date":"2023-10-20T01:32:33.000Z","updated":"2024-11-12T03:04:42.025Z","comments":true,"path":"2023/10/19/Working-with-Text-in-R/","link":"","permalink":"https://stephen-cheng.github.io/2023/10/19/Working-with-Text-in-R/","excerpt":"","text":"&nbsp; Stephen Cheng IntroWorking with text data is a critical skill in data analysis, enabling you to process, clean, and extract valuable insights from unstructured information. In R, powerful tools like regular expressions, string manipulation functions, and specialized packages such as stringr and tidytext make text handling efficient and intuitive. This guide introduces essential techniques and functions for working with text in R, helping you tackle tasks ranging from basic string operations to advanced text mining and natural language processing. PackagesWe will use the following packages. stringr: for basic text manipulation (part of the tidyverse) readtext: for reading diﬀerent text files (incl. websites) tesseract: for converting PDF files into text Formatting Text 1text [1] “CDSI - Computing &amp; Data Systems Initiative at McGill”[2] “ Phew! It’s getting cold! “[3] “The phone number at the CDSI is not 555-111-2222!” Length of text 1nchar(text) [1] 52 27 49 Deleting whitespace 12library(stringr)str_trim(text) [1] “CDSI - Computing &amp; Data Systems Initiative at McGill”[2] “Phew! It’s getting cold!”[3] “The phone number at the CDSI is not 555-111-2222!” Adding whitespace 1str_pad(text, 52, \"right\") [1] “CDSI - Computing &amp; Data Systems Initiative at McGill”[2] “ Phew! It’s getting cold! “[3] “The phone number at the CDSI is not 555-111-2222! “ Gets the position of Sorting 1str_order(text) [1] 2 1 3 Actually sorts the data 1str_sort(text) [1] “ Phew! It’s getting cold! “[2] “CDSI - Computing &amp; Data Systems Initiative at McGill”[3] “The phone number at the CDSI is not 555-111-2222!” Capping 1str_trunc(text, 40) [1] “CDSI - Computing &amp; Data Systems Initi…”[2] “ Phew! It’s getting cold! “[3] “The phone number at the CDSI is not 5…” Adding line breaks 1str_wrap(text, 40) [1] “CDSI - Computing &amp; Data Systems\\nInitiative at McGill”[2] “Phew! It’s getting cold!”[3] “The phone number at the CDSI is not\\n555-111-2222!” Executes escaped characters 1cat(str_wrap(text, 40)) CDSI - Computing &amp; Data SystemsInitiative at McGill Phew! It’s getting cold! The phone number at the CDSI isnot555-111-2222! Convert to string lower 1str_to_lower(text) [1] “cdsi - computing &amp; data systems initiative at mcgill”[2] “ phew! it’s getting cold! “[3] “the phone number at the cdsi is not 555-111-2222!” Convert to string title 1str_to_title(text) [1] “Cdsi - Computing &amp; Data Systems Initiative At Mcgill”[2] “ Phew! It’s Getting Cold! “[3] “The Phone Number At The Cdsi Is Not 555-111-2222!” Text Manipulation Combining text 123text1 &lt;- \"A\"text2 &lt;- \"number\"paste(text1, text2) [1] “A number” Defines the separator 1paste(text1, text2, sep = \"\") [1] “Anumber” 1paste0(text1, text2) [1] “Anumber” Extracting text 1str_sub(text, 1, 9) [1] “CDSI - Co” “ Phew! I” “The phone” To get text from the right hand side 1str_sub(text, -4, -1) [1] “Gill” “ld! “ “222!” Splitting text 1str_split(text, boundary(\"word\")) [[1]][1] “CDSI” “Computing” “Data” “Systems” “Initiative”[6] “at” “McGill”[[2]][1] “Phew” “It’s” “getting” “cold”[[3]][1] “The” “phone” “number” “at” “the” “CDSI” “is” “not”[9] “555” “111” “2222” Spliting text by ‘at’ 1str_split(text[1], \"at\") [[1]][1] “CDSI - Computing &amp; D” “a Systems Initi” “ive “[4] “ McGill” 1str_split_1(text[1], \"at\") [1] “CDSI - Computing &amp; D” “a Systems Initi” “ive “[4] “ McGill” Importing Text Importing text from a pdf/image 12library(tesseract)text3 &lt;- ocr(\"data/Canadian_Geographer.pdf\") Importing with readtext 12345library(readtext)text4 &lt;- readtext(\"data/CAG_Newsletter.pdf\")text5 &lt;- readtext(\"https://laws-lois.justice.gc.ca/eng/acts/o-3.01/fulltext.htmtext6 &lt;- readtext(\"data/PhD_Guide.doc\")text7 &lt;- readtext(\"data/New_Students_Guide.docx\") Read a full directories of text files 1text &lt;- readtext(\"data/\")","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/categories/Data-Science/"}],"tags":[{"name":"R","slug":"R","permalink":"https://stephen-cheng.github.io/tags/R/"},{"name":"Text","slug":"Text","permalink":"https://stephen-cheng.github.io/tags/Text/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"}],"author":"Stephen Cheng"},{"title":"Data Visualization with ggplot2 in R","slug":"Data-Visualization-with-ggplot2-in-R","date":"2023-08-27T20:21:16.000Z","updated":"2024-11-11T22:12:40.012Z","comments":true,"path":"2023/08/27/Data-Visualization-with-ggplot2-in-R/","link":"","permalink":"https://stephen-cheng.github.io/2023/08/27/Data-Visualization-with-ggplot2-in-R/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Data visualization is a powerful tool for uncovering insights and communicating findings effectively. In R, ggplot2, part of the tidyverse, is one of the most popular and versatile packages for creating elegant and customizable visualizations. Built on the Grammar of Graphics, ggplot2 enables users to build complex plots layer by layer, providing flexibility to create everything from simple charts to intricate, publication-quality graphics. This introduction will guide you through the basics of ggplot2, helping you transform raw data into meaningful visual representations. Basics AesCommon aesthetic values. GeomsUse a geom function to represent data points, use the geom’s aesthetic properties to represent variables. Each function returns a layer. StatsAn alternative way to build a layer. ScalesOverride defaults with scales package. Coordinate Systems Position AdjustmentsPosition adjustments determine how to arrange geoms that would otherwise occupy the same space. Themes FacetingFacets divide a plot into subplots based on the values of one or more discrete variables. Labels and Legends Zooming","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/categories/Data-Science/"}],"tags":[{"name":"R","slug":"R","permalink":"https://stephen-cheng.github.io/tags/R/"},{"name":"Data Visualization","slug":"Data-Visualization","permalink":"https://stephen-cheng.github.io/tags/Data-Visualization/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://stephen-cheng.github.io/tags/ggplot2/"}],"author":"Stephen Cheng"},{"title":"Linux Commands and Paths in Linux","slug":"Linux-Commands-and-Paths-in-Linux","date":"2023-06-05T16:18:07.000Z","updated":"2024-11-11T20:40:34.506Z","comments":true,"path":"2023/06/05/Linux-Commands-and-Paths-in-Linux/","link":"","permalink":"https://stephen-cheng.github.io/2023/06/05/Linux-Commands-and-Paths-in-Linux/","excerpt":"","text":"&nbsp; Stephen Cheng IntroLinux is a family of open-source Unix-like operating systems based on the Linux kernel, an operating system kernel first released on September 17, 1991, by Linus Torvalds. System commands are a computer user’s instruction (not part of a program) that calls for action by the computer’s executive program. Most of the “commands” that we use on the Linux command line are in fact programs (which are stored as files) located typically in the /bin or /usr/bin directories. Take the cp command for instance. You can use the “which” command to determine where the cp program is located. Basic commands and Paths What is the date?1$ date Let’s print something1$ echo \"Hello World\" Paths: what are they1$ echo $PATH Files and Paths1$ which python Get Help1$ man echo Get short help1$ whatis echo Navigating Paths Where am I in the structure?1$ pwd What’s in here?1$ ls OR prettier, what’s in here?1$ tree How to change to another directory?1$ cd directory_name How do I move up the directory structure?1$ cd .. How do I move to my home directory?1$ cd ~ Files Creaing and Moving Create a file1$ touch file_name Is the file there?1$ ls -l file_name What’s in the file1$ cat file_name What type of file is this1$ file file_name Rename, Move this file to another directory1$ mv original_file final_file Find the file1$ ls -l final_file Copy the file (make a second copy)1$ cp file_name new_file_name Cobble files (DO NOT Try this)1$ cp file_name existing_file_name Combine multiple files into another1$ cat file1 file2 See the beginning of a file1$ head file See the end of a file1$ tail file Pause between each pageful of file1$ less file Same thing (older)1$ more file Directories Create a directory1$ mkdir dir1 List the directory1$ ls -al dir1 Dot, dot dot, dash, and tilde1$ cd . ; cd .. ; cd - ; cd ~ Rename/Move a directory1$ mv dir1 dir2 Nest directories (be careful)1$ mv dir2 dir3/ Removing files/directories Remove a file1$ rm file1 Remove an empty directory1$ rmdir dir1 Remove a directory and files in it (CAREFUL)1$ rm -r dir1 Remove a link. Careful with symlinks1$ rm linkname Try to remove a file you don’t have permissions to1$ rm linkname Links Create a hard link to a file. This creates another path to the file contents.1$ ln target linkname Create a symbolic link to a file or directory. This creates a link to the existing path, and not the file contents.1$ ln -s target linkname Ownership and Permissions Look at permissions and owners1$ ls -l file Change owners, groups1$ chown ambrish file1 Change file permissions of file11$ chmod a+x file1 Make readonly for g and o1$ chmod go-r file1 Or something more precise1$ chmod u=rx,g=rwx,o=r file1 Compiling a C file The original file can be checked1$ cat first.c To compile we use the GNU C compiler gcc1$ gcc -o first first.c This creates the file first, which you can see is executable1$ ls -l first* Run the file1$ ./first Processes Look at processes running1$ ps -ef Look at expensive processes1$ top Same thing (Newer)1$ htop Run something in the background (Get my prompt back)1$ htop &amp; Get running program back1$ fg Ask the computer itself (good for flags)1$ man command Top 50 Linux Commands You Should Know","categories":[{"name":"System","slug":"System","permalink":"https://stephen-cheng.github.io/categories/System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://stephen-cheng.github.io/tags/Linux/"},{"name":"File Systems","slug":"File-Systems","permalink":"https://stephen-cheng.github.io/tags/File-Systems/"},{"name":"Computer Systems","slug":"Computer-Systems","permalink":"https://stephen-cheng.github.io/tags/Computer-Systems/"}],"author":"Stephen Cheng"},{"title":"Create Virtual Environment for Python Project","slug":"Create-Virtual-Environment-for-Python-Project","date":"2023-03-12T22:23:27.000Z","updated":"2024-05-14T22:30:40.492Z","comments":true,"path":"2023/03/12/Create-Virtual-Environment-for-Python-Project/","link":"","permalink":"https://stephen-cheng.github.io/2023/03/12/Create-Virtual-Environment-for-Python-Project/","excerpt":"","text":"&nbsp; Stephen Cheng IntroIt is suggested to have a dedicated virtual environment for each Python/Django project, and one way to manage a virtual environment is venv, which is included in Python. The name of the virtual environment is your choice, in this tutorial we will call it myenv. Type the following in the command prompt: Windows: 1py -m venv myenv Unix/MacOS: 1python -m venv myenv This will set up a virtual environment, and create a folder named “myenv” with subfolders and files. Activate the Virtual EnvironmentYou must activate the virtual environment every time you open the command prompt to work on your project. You can activate the environment by typing this command: Windows: 1myenv\\Scripts\\activate.bat Unix/MacOS: 1source myworld/bin/activate Once the environment is activated, you will see this result in the command prompt: Windows: 1(myenv) C:\\Users\\Your Name&gt; Unix/MacOS: 1(myenv) ... $ Deactivate the Virtual EnvironmentYou can deactivate the virtual environment by typing this command: 1deactivate","categories":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Virtual Environment","slug":"Virtual-Environment","permalink":"https://stephen-cheng.github.io/tags/Virtual-Environment/"},{"name":"Django","slug":"Django","permalink":"https://stephen-cheng.github.io/tags/Django/"}],"author":"Stephen Cheng"},{"title":"Pre-order, In-order and Post-order Traversal of Binary Trees in Python","slug":"Pre-order-In-order-and-Post-order-Traversal-of-Binary-Trees-in-Python","date":"2023-01-08T18:54:43.000Z","updated":"2024-04-27T18:34:09.066Z","comments":true,"path":"2023/01/08/Pre-order-In-order-and-Post-order-Traversal-of-Binary-Trees-in-Python/","link":"","permalink":"https://stephen-cheng.github.io/2023/01/08/Pre-order-In-order-and-Post-order-Traversal-of-Binary-Trees-in-Python/","excerpt":"","text":"&nbsp; Stephen Cheng IntroThe Tree data structure is similar to linked lists in that each node contains data and can be linked to other nodes. In a Tree, a single element can have multiple ‘next’ elements, allowing the data structure to branch out in various directions. The data structure is called a “tree” because it looks like a tree, only upside down. The Tree data structure can be useful in many cases: Hierarchical Data: File systems, organizational models, etc. Databases: Used for quick data retrieval. Routing Tables: Used for routing data in network algorithms. Sorting/Searching: Used for sorting data and searching for data. Priority Queues: Priority queue data structures are commonly implemented using trees, such as binary heaps. Types of TreesTrees are a fundamental data structure in computer science, used to represent hierarchical relationships. Binary Trees: Each node has up to two children, the left child node and the right child node. This structure is the foundation for more complex tree types like Binay Search Trees and AVL Trees. Binary Search Trees (BSTs): A type of Binary Tree where for each node, the left child node has a lower value, and the right child node has a higher value. AVL Trees: A type of Binary Search Tree that self-balances so that for every node, the difference in height between the left and right subtrees is at most one. This balance is maintained through rotations when nodes are inserted or deleted. Binary TreesA Binary Tree is a type of tree data structure where each node can have a maximum of two child nodes, a left child node and a right child node. This restriction, that a node can have a maximum of two child nodes, gives us many benefits: Algorithms like traversing, searching, insertion and deletion become easier to understand, to implement, and run faster. Keeping data sorted in a Binary Search Tree (BST) makes searching very efficient. Balancing trees is easier to do with a limited number of child nodes, using an AVL Binary Tree for example. Binary Trees can be represented as arrays, making the tree more memory efficient. Types of Binary TreesThere are different variants, or types, of Binary Trees worth discussing to get a better understanding of how Binary Trees can be structured. Below are short explanations of different types of Binary Tree structures. A balanced Binary Tree has at most 1 in difference between its left and right subtree heights, for each node in the tree. A complete Binary Tree has all levels full of nodes, except the last level, which is can also be full, or filled from left to right. The properties of a complete Binary Tree means it is also balanced. A full Binary Tree is a kind of tree where each node has either 0 or 2 child nodes. A perfect Binary Tree has all leaf nodes on the same level, which means that all levels are full of nodes, and all internal nodes have two child nodes.The properties of a perfect Binary Tree means it is also full, balanced, and complete. Implementation of Binary TreesTo avoid the cost of all the shifts in memory that we get from using Arrays, it is useful to implement Binary Trees with pointers from one element to the next, just like Binary Trees are implemented before this point, especially when the Binary Tree is modified often. But in case we read from the Binary Tree a lot more than we modify it, an Array implementation of a Binary Tree can make sense as it needs less memory, it can be easier to implement, and it can be faster for certain operations due to cache locality. Consider this Binary Tree: This Binary Tree can be stored in an Array starting with the root node R on index 0. The rest of the tree can be built by taking a node stored on index i, and storing its left child node on index 2⋅i + 1, and its right child node on index 2⋅i + 2. Below is an Array implementation of the Binary Tree. By comparing how these traversals are done in an array implementation to how the pointer implementation was traversed, you can see that the pre-order, in-order, and post-order traversals works in the same recursive way. 1234567891011121314151617181920212223242526binary_tree_array = ['R', 'A', 'B', 'C', 'D', 'E', 'F', None, None, None, None, None, None, 'G']def left_child_index(index): return 2 * index + 1def right_child_index(index): return 2 * index + 2def pre_order(index): if index &gt;= len(binary_tree_array) or binary_tree_array[index] is None: return [] return [binary_tree_array[index]] + pre_order(left_child_index(index)) + pre_order(right_child_index(index))def in_order(index): if index &gt;= len(binary_tree_array) or binary_tree_array[index] is None: return [] return in_order(left_child_index(index)) + [binary_tree_array[index]] + in_order(right_child_index(index))def post_order(index): if index &gt;= len(binary_tree_array) or binary_tree_array[index] is None: return [] return post_order(left_child_index(index)) + post_order(right_child_index(index)) + [binary_tree_array[index]]print(\"Pre-order Traversal:\", pre_order(0))print(\"In-order Traversal:\", in_order(0))print(\"Post-order Traversal:\", post_order(0))","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Binary Trees","slug":"Binary-Trees","permalink":"https://stephen-cheng.github.io/tags/Binary-Trees/"}],"author":"Stephen Cheng"},{"title":"Building A Hash Set in Python","slug":"Building-A-Hash-Set-in-Python","date":"2022-11-20T16:37:02.000Z","updated":"2024-04-27T18:33:56.726Z","comments":true,"path":"2022/11/20/Building-A-Hash-Set-in-Python/","link":"","permalink":"https://stephen-cheng.github.io/2022/11/20/Building-A-Hash-Set-in-Python/","excerpt":"","text":"&nbsp; Stephen Cheng IntroA Hash Set is a form of Hash Table data structure that usually holds a large number of elements. Using a Hash Set we can search, add, and remove elements really fast. Hash Sets are used for lookup, to check if an element is part of a set. A Hash Set stores unique elements in buckets according to the element’s hash code. Hash code: A number generated from an element’s unique value (key), to determine what bucket that Hash Set element belongs to. Unique elements: A Hash Set cannot have more than one element with the same value. Bucket: A Hash Set consists of many such buckets, or containers, to store elements. If two elements have the same hash code, they belong to the same bucket. Direct Access in Hash SetsSearching for Peter in the Hash Set above, means that the hash code 2 is generated (512 % 10), and that directs us right to the bucket Peter is in. If that is the only name in that bucket, we will find Peter right away. In cases like this we say that the Hash Set has constant time O(1) for searching, adding, and removing elements, which is really fast. But, if we search for Jens, we need to search through the other names in that bucket before we find Jens. In a worst case scenario, all names end up in the same bucket, and the name we are searching for is the last one. In such a worst case scenario the Hash Set has time complexity O(n), which is the same time complexity as arrays and linked lists. To keep Hash Sets fast, it is therefore important to have a hash function that will distribute the elements evenly between the buckets, and to have around as many buckets as Hash Set elements. Having a lot more buckets than Hash Set elements is a waste of memory, and having a lot less buckets than Hash Set elements is a waste of time. Hash Set ImplementationHash Sets in Python are typically done by using Python’s own set data type, but to get a better understanding of how Hash Sets work we will not use that here. To implement a Hash Set in Python we create a class SimpleHashSet. Inside the SimpleHashSet class we have a method __init__ to initialize the Hash Set, a method hash_function for the hash function, and methods for the basic Hash Set operations: add, contains, and remove. We also create a method print_set to better see how the Hash Set looks like. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class SimpleHashSet: def __init__(self, size=100): self.size = size self.buckets = [[] for _ in range(size)] # A list of buckets, each is a list (to handle collisions) def hash_function(self, value): # Simple hash function: sum of character codes modulo the number of buckets return sum(ord(char) for char in value) % self.size def add(self, value): # Add a value if it's not already present index = self.hash_function(value) bucket = self.buckets[index] if value not in bucket: bucket.append(value) def contains(self, value): # Check if a value exists in the set index = self.hash_function(value) bucket = self.buckets[index] return value in bucket def remove(self, value): # Remove a value index = self.hash_function(value) bucket = self.buckets[index] if value in bucket: bucket.remove(value) def print_set(self): # Print all elements in the hash set print(\"Hash Set Contents:\") for index, bucket in enumerate(self.buckets): print(f\"Bucket &#123;index&#125;: &#123;bucket&#125;\")# Creating the Hash Set from the simulationhash_set = SimpleHashSet(size=10)hash_set.add(\"Charlotte\")hash_set.add(\"Thomas\")hash_set.add(\"Jens\")hash_set.add(\"Peter\")hash_set.add(\"Lisa\")hash_set.add(\"Adele\")hash_set.add(\"Michaela\")hash_set.add(\"Bob\")hash_set.print_set()print(\"\\n'Peter' is in the set:\",hash_set.contains('Peter'))print(\"Removing 'Peter'\")hash_set.remove('Peter')print(\"'Peter' is in the set:\",hash_set.contains('Peter'))print(\"'Adele' has hash code:\",hash_set.hash_function('Adele'))","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Hash Set","slug":"Hash-Set","permalink":"https://stephen-cheng.github.io/tags/Hash-Set/"}],"author":"Stephen Cheng"},{"title":"Building A Hash Table from Scratch in Python","slug":"Building-A-Hash-Table-from-Scratch-in-Python","date":"2022-09-13T03:07:23.000Z","updated":"2024-04-27T18:34:00.693Z","comments":true,"path":"2022/09/12/Building-A-Hash-Table-from-Scratch-in-Python/","link":"","permalink":"https://stephen-cheng.github.io/2022/09/12/Building-A-Hash-Table-from-Scratch-in-Python/","excerpt":"","text":"&nbsp; Stephen Cheng IntroA Hash Table is a data structure designed to be fast to work with. The reason Hash Tables are sometimes preferred instead of arrays or linked lists is because searching for, adding, and deleting data can be done really quickly, even for large amounts of data. For example, with a Hash Table, finding “Bob” inside is done really fast because there is a way to go directly to where “Bob” is stored, using something called a hash function. Building A Hash Table from ScratchTo get the idea of what a Hash Table is, let’s try to build one from scratch, to store unique first names inside it. We will build the Hash Set in 5 steps: Starting with an array. Storing names using a hash function. Looking up an element using a hash function. Handling collisions. The basic Hash Set code example and simulation. Step 1: Starting with an arrayTo make interacting with the list of names really fast, let’s use a Hash Table, or a Hash Set, which is a simplified version of a Hash Table. To keep it simple, let’s assume there is at most 10 names in the list, so the array must be a fixed size of 10 elements. When talking about Hash Tables, each of these elements is called a bucket. 1my_hash_set = [None,None,None,None,None,None,None,None,None,None] Step 2: Storing names using a hash functionWe want to store a name directly into its right place in the array, and this is where the hash function comes in. A hash function can be made in many ways, it is up to the creator of the Hash Table. A common way is to find a way to convert the value into a number that equals one of the Hash Set’s index numbers, in this case a number from 0 to 9. In our example we will use the Unicode number of each character, summarize them and do a modulo 10 operation to get index numbers 0-9. The character “B” has Unicode code point 66, “o” has 111, and “b” has 98. Adding those together we get 275. Modulo 10 of 275 is 5, so “Bob” should be stored as an array element at index 5. The number returned by the hash function is called the hash code. 12345678def hash_function(value): sum_of_chars = 0 for char in value: sum_of_chars += ord(char) return sum_of_chars % 10print(\"'Bob' has hash code:\",hash_function('Bob')) After storing “Bob” where the hash code tells us (index 5), our array now looks like this: 1my_hash_set = [None,None,None,None,None,'Bob',None,None,None,None] Step 3: Looking up a name using a hash functionWe have now established a super basic Hash Set. To find out if “Pete” is stored in the array, we give the name “Pete” to our hash function, we get back hash code 9, we go directly to the element at index 9, and there he is. We found “Pete” without checking any other elements. When deleting a name from our Hash Set, we can also use the hash function to go straight to where the name is, and set that element value to None. 1234567891011121314my_hash_set = [None,'Jones',None,'Lisa',None,'Bob',None,'Siri','Pete',None]def hash_function(value): sum_of_chars = 0 for char in value: sum_of_chars += ord(char) return sum_of_chars % 10 def contains(name): index = hash_function(name) return my_hash_set[index] == nameprint(\"'Pete' is in the Hash Set:\",contains('Pete')) Step 4: Handling collisionsLet’s also add “Stuart” to our Hash Set. We give “Stuart” to our hash function, and we get the hash code 3, meaning “Stuart” should be stored at index 3. Trying to store “Stuart” creates what is called a collision, because “Lisa” is already stored at index 3. To fix the collision, we can make room for more elements in the same bucket, and solving the collision problem in this way is called chaining. We can give room for more elements in the same bucket by implementing each bucket as a linked list, or as an array. After implementing each bucket as an array, to give room for potentially more than one name in each bucket, “Stuart” can also be stored at index 3, and our Hash Set now looks like this: 123456789101112my_hash_set = [ [None], ['Jones'], [None], ['Lisa', 'Stuart'], [None], ['Bob'], [None], ['Siri'], ['Pete'], [None]] Step 5: Hash Set code exampleTo complete our very basic Hash Set code, let’s have functions for adding and searching for names in the Hash Set, which is now a two dimensional array. 12345678910111213141516171819202122232425262728293031my_hash_set = [ [None], ['Jones'], [None], ['Lisa'], [None], ['Bob'], [None], ['Siri'], ['Pete'], [None]]def hash_function(value): return sum(ord(char) for char in value) % 10 def add(value): index = hash_function(value) bucket = my_hash_set[index] if value not in bucket: bucket.append(value) def contains(value): index = hash_function(value) bucket = my_hash_set[index] return value in bucketadd('Stuart')print(my_hash_set)print('Contains Stuart:',contains('Stuart')) Uses of Hash TablesHash Tables are great for: Checking if something is in a collection (like finding a book in a library). Storing unique items and quickly finding them (like storing phone numbers). Connecting values to keys (like linking names to phone numbers). The most important reason why Hash Tables are great for these things is that Hash Tables are very fast compared Arrays and Linked Lists, especially for large sets. Arrays and Linked Lists have time complexity O(n) for search and delete, while Hash Tables have just O(1) on average! SummarizedA Hash Table can be a Hash Set or a Hash Map. Hash Table elements are stored in storage containers called buckets. Every Hash Table element has a part that is unique that is called the key. A hash function takes the key of an element to generate a hash code.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Hash Table","slug":"Hash-Table","permalink":"https://stephen-cheng.github.io/tags/Hash-Table/"}],"author":"Stephen Cheng"},{"title":"Delete and Insert a Node in a Linked List in Python","slug":"Delete-and-Insert-a-Node-in-a-Linked-List","date":"2022-07-22T18:03:20.000Z","updated":"2024-04-27T18:33:26.400Z","comments":true,"path":"2022/07/22/Delete-and-Insert-a-Node-in-a-Linked-List/","link":"","permalink":"https://stephen-cheng.github.io/2022/07/22/Delete-and-Insert-a-Node-in-a-Linked-List/","excerpt":"","text":"&nbsp; Stephen Cheng IntroBasic things we can do with linked lists are: Traversal Remove a node Insert a node Sort For simplicity, singly linked lists will be used to explain these operations below. Delete a Node in a Linked ListIn this case we have the link (or pointer or address) to a node that we want to delete. It is important to connect the nodes on each side of the node before deleting it, so that the linked list is not broken. So before deleting the node, we need to get the next pointer from the previous node, and connect the previous node to the new next node before deleting the node in between. In a singly linked list, like we have here, to get the next pointer from the previous node we actually need traverse the list from the start, because there is no way to go backwards from the node we want to delete. In the code below, the algorithm to delete a node is moved into a function called deleteSpecificNode, the return value is the new head of the linked list. So for example, if the node to be deleted is the first node, the new head returned will be the next node. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Node: def __init__(self, data): self.data = data self.next = Nonedef traverseAndPrint(head): currentNode = head while currentNode: print(currentNode.data, end=\" -&gt; \") currentNode = currentNode.next print(\"null\")def deleteSpecificNode(head, nodeToDelete): if head == nodeToDelete: return head.next currentNode = head while currentNode.next and currentNode.next != nodeToDelete: currentNode = currentNode.next if currentNode.next is None: return head currentNode.next = currentNode.next.next return headnode1 = Node(7)node2 = Node(11)node3 = Node(3)node4 = Node(2)node5 = Node(9)node1.next = node2node2.next = node3node3.next = node4node4.next = node5print(\"Before deletion:\")traverseAndPrint(node1)# Delete node4node1 = deleteSpecificNode(node1, node4)print(\"\\nAfter deletion:\")traverseAndPrint(node1) Insert a Node in a Linked ListInserting a node into a linked list is very similar to deleting a node, because in both cases we need to take care of the next pointers to make sure we do not break the linked list. To insert a node in a linked list we first need to create the node, and then at the position where we insert it, we need to adjust the pointers so that the previous node points to the new node, and the new node points to the correct next node. In the insertNodeAtPosition function below, the return value is the new head of the linked list. So for example, if the node is inserted at the start of the linked list, the new head returned will be the new node. 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Node: def __init__(self, data): self.data = data self.next = Nonedef traverseAndPrint(head): currentNode = head while currentNode: print(currentNode.data, end=\" -&gt; \") currentNode = currentNode.next print(\"null\")def insertNodeAtPosition(head, newNode, position): if position == 1: newNode.next = head return newNode currentNode = head for _ in range(position - 2): if currentNode is None: break currentNode = currentNode.next newNode.next = currentNode.next currentNode.next = newNode return headnode1 = Node(7)node2 = Node(3)node3 = Node(2)node4 = Node(9)node1.next = node2node2.next = node3node3.next = node4print(\"Original list:\")traverseAndPrint(node1)# Insert a new node with value 97 at position 2newNode = Node(97)node1 = insertNodeAtPosition(node1, newNode, 2)print(\"\\nAfter insertion:\")traverseAndPrint(node1)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Linked List","slug":"Linked-List","permalink":"https://stephen-cheng.github.io/tags/Linked-List/"}],"author":"Stephen Cheng"},{"title":"Doubly Linked List in Python","slug":"Doubly-Linked-List-in-Python","date":"2022-05-05T15:26:08.000Z","updated":"2024-04-27T18:33:16.540Z","comments":true,"path":"2022/05/05/Doubly-Linked-List-in-Python/","link":"","permalink":"https://stephen-cheng.github.io/2022/05/05/Doubly-Linked-List-in-Python/","excerpt":"","text":"&nbsp; Stephen Cheng IntroThere are three basic forms of linked lists: Singly linked lists Doubly linked lists Circular linked lists A doubly linked list has nodes with addresses to both the previous and the next node, like in the image below, and therefore takes up more memory. But doubly linked lists are good if you want to be able to move both up and down in the list. ImplementationBelow is an implementation of a basic doubly linked list in Python: 12345678910111213141516171819202122232425262728293031323334class Node: def __init__(self, data): self.data = data self.next = None self.prev = None node1 = Node(3)node2 = Node(5)node3 = Node(13)node4 = Node(2)node1.next = node2node2.prev = node1node2.next = node3node3.prev = node2node3.next = node4node4.prev = node3print(\"\\nTraversing forward:\")currentNode = node1while currentNode: print(currentNode.data, end=\" -&gt; \") currentNode = currentNode.nextprint(\"null\")print(\"\\nTraversing backward:\")currentNode = node4while currentNode: print(currentNode.data, end=\" -&gt; \") currentNode = currentNode.prevprint(\"null\")","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Linked List","slug":"Linked-List","permalink":"https://stephen-cheng.github.io/tags/Linked-List/"}],"author":"Stephen Cheng"},{"title":"Quicksort Algorithm","slug":"Quicksort-algorithm","date":"2022-02-16T18:39:38.000Z","updated":"2024-04-27T18:22:37.690Z","comments":true,"path":"2022/02/16/Quicksort-algorithm/","link":"","permalink":"https://stephen-cheng.github.io/2022/02/16/Quicksort-algorithm/","excerpt":"","text":"&nbsp; Stephen Cheng IntroThe Quicksort algorithm is one of the fastest sorting algorithms. It takes an array of values, chooses one of the values as the ‘pivot’ element, and moves the other values so that lower values are on the left of the pivot element, and higher values are on the right of it. In this tutorial the last element of the array is chosen to be the pivot element, but we could also have chosen the first element of the array, or any element in the array really. Then, the Quicksort algorithm does the same operation recursively on the sub-arrays to the left and right side of the pivot element. This continues until the array is sorted. How it works? Choose a value in the array to be the pivot element. Order the rest of the array so that lower values than the pivot element are on the left, and higher values are on the right. Swap the pivot element with the first element of the higher values so that the pivot element lands in between the lower and higher values. Do the same operations (recursively) for the sub-arrays on the left and right side of the pivot element. Manual Run ThroughStep 1: We start with an unsorted array. 1[ 11, 9, 12, 7, 3] Step 2: We choose the last value 3 as the pivot element. 1[ 11, 9, 12, 7, 3] Step 3: The rest of the values in the array are all lower than 3, an must be on the right side of 3. Swap 3 with 11. 1[ 3, 9, 12, 7, 11] Step 4: Value 3 is now in the correct position. We need to sort the values to the right of 3. We choose the last value 11 as the new pivot element. 1[ 3, 9, 12, 7, 11] Step 5: The value 7 must be to the left of pivot value 11, and 12 must be to the right of it. Move 7 and 12. 1[ 3, 9, 7, 12, 11] Step 6: Swap 11 with 12 so that lower values 9 anf 7 are on the left side of 11, and 12 is on the right side. 1[ 3, 9, 7, 11, 12] Step 7: 11 and 12 are in the correct positions. We choose 7 as the pivot element in sub-array [ 9, 7], to the left of 11. 1[ 3, 9, 7, 11, 12] Step 8: We must swap 9 with 7. 1[ 3, 7, 9, 11, 12] Finally, the array is sorted. ImplementationTo implement the Quicksort algorithm in a programming language, we need: An array with values to sort. A quickSort method that calls itself (recursion) if the sub-array has a size larger than 1. A partition method that receives a sub-array, moves values around, swaps the pivot element into the sub-array and returns the index where the next split in sub-arrays happens. 12345678910111213141516171819202122232425def partition(array, low, high): pivot = array[high] i = low - 1 for j in range(low, high): if array[j] &lt;= pivot: i += 1 array[i], array[j] = array[j], array[i] array[i+1], array[high] = array[high], array[i+1] return i+1def quicksort(array, low=0, high=None): step = 0 if high is None: high = len(array) - 1 if low &lt; high: pivot_index = partition(array, low, high) print(\"The sorted array after &#123;0&#125; step: \".format(low+1), array) quicksort(array, low, pivot_index-1) quicksort(array, pivot_index+1, high)my_array = [64, 34, 25, 12, 22, 11, 90, 5]quicksort(my_array)print(\"Sorted array:\", my_array) Time ComplexityThe worst case scenario for Quicksort is O(nn). This is when the pivot element is either the highest or lowest value in every sub-array, which leads to a lot of recursive calls. With our implementation above, this happens when the array is already sorted But on average, the time complexity for Quicksort is actually just O(nlogn). The recursion part of the Quicksort algorithm is actually a reason why the average sorting scenario is so fast, because for good picks of the pivot element, the array will be split in half somewhat evenly each time the algorithm calls itself. So the number of recursive calls do not double, even if the number of values n double.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Sort","slug":"Sort","permalink":"https://stephen-cheng.github.io/tags/Sort/"},{"name":"Quicksort","slug":"Quicksort","permalink":"https://stephen-cheng.github.io/tags/Quicksort/"}],"author":"Stephen Cheng"},{"title":"How to Choose the Right Machine Learning Model for Different Data and Different Problems","slug":"How-to-Choose-the-Right-Machine-Learning-Model-for-Different-Data-and-Different-Problems","date":"2021-11-22T18:37:44.000Z","updated":"2024-04-27T18:22:23.469Z","comments":true,"path":"2021/11/22/How-to-Choose-the-Right-Machine-Learning-Model-for-Different-Data-and-Different-Problems/","link":"","permalink":"https://stephen-cheng.github.io/2021/11/22/How-to-Choose-the-Right-Machine-Learning-Model-for-Different-Data-and-Different-Problems/","excerpt":"","text":"&nbsp; Stephen Cheng IntroDiscovering a ideal model, an estimator or a classifier for a machine learning task can often pose the greatest challenge. Given the diversity of data types and problem complexities, certain models outperform others. This necessitates a tailored selection process. The flowchart presented below is designed to give us a bit of a rough guide on how to approach problems with regard to which models to try on our data.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Classifier","slug":"Classifier","permalink":"https://stephen-cheng.github.io/tags/Classifier/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Estimator","slug":"Estimator","permalink":"https://stephen-cheng.github.io/tags/Estimator/"}],"author":"Stephen Cheng"},{"title":"Increasing Overall Model Performance on Unseen Data with Cross Validation","slug":"Increasing-Overall-Model-Performance-on-Unseen-Data-with-Cross-Validation","date":"2021-08-06T18:20:45.000Z","updated":"2024-04-27T18:19:57.542Z","comments":true,"path":"2021/08/06/Increasing-Overall-Model-Performance-on-Unseen-Data-with-Cross-Validation/","link":"","permalink":"https://stephen-cheng.github.io/2021/08/06/Increasing-Overall-Model-Performance-on-Unseen-Data-with-Cross-Validation/","excerpt":"","text":"&nbsp; Stephen Cheng IntroWhen adjusting models we are aiming to increase overall model performance on unseen data. Hyperparameter tuning can lead to much better performance on test sets. However, optimizing parameters to the test set can lead information leakage causing the model to preform worse on unseen data. To correct for this we can perform cross validation. To better understand CV, we will be performing different methods on the iris dataset. K-FoldThe training data used in the model is split, into k number of smaller sets, to be used to validate the model. The model is then trained on k-1 folds of training set. The remaining fold is then used as a validation set to evaluate the model. As we will be trying to classify different species of iris flowers we will need to import a classifier model, for this exercise we will be using a DecisionTreeClassifier. 123456789101112131415from sklearn import datasetsfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.model_selection import KFold, StratifiedKFoldfrom sklearn.model_selection import LeaveOneOut, LeavePOutfrom sklearn.model_selection import ShuffleSplit, cross_val_scoreX, y = datasets.load_iris(return_X_y=True)clf = DecisionTreeClassifier(random_state=42)k_folds = KFold(n_splits = 5)scores = cross_val_score(clf, X, y, cv = k_folds)print(\"Cross Validation Scores: \", scores[:3])print(\"Average CV Score: \", scores.mean())print(\"Number of CV Scores used in Average: \", len(scores)) 123Cross Validation Scores: [1. 1. 0.83333333]Average CV Score: 0.9133333333333333Number of CV Scores used in Average: 5 Stratified K-FoldIn cases where classes are imbalanced we need a way to account for the imbalance in both the train and validation sets. To do so we can stratify the target classes, meaning that both sets will have an equal proportion of all classes. While the number of folds is the same, the average CV increases from the basic k-fold when making sure there is stratified classes. 123456sk_folds = StratifiedKFold(n_splits = 5)scores = cross_val_score(clf, X, y, cv = sk_folds)print(\"Cross Validation Scores: \", scores[:3])print(\"Average CV Score: \", scores.mean())print(\"Number of CV Scores used in Average: \", len(scores)) 123Cross Validation Scores: [0.96666667 0.96666667 0.9]Average CV Score: 0.9533333333333334Number of CV Scores used in Average: 5 Leave-One-Out (LOO)Instead of selecting the number of splits in the training data set like k-fold LeaveOneOut, utilize 1 observation to validate and n-1 observations to train. This method is an exaustive technique. 123456loo = LeaveOneOut()scores = cross_val_score(clf, X, y, cv = loo)print(\"Cross Validation Scores: \", scores[:3])print(\"Average CV Score: \", scores.mean())print(\"Number of CV Scores used in Average: \", len(scores)) 123Cross Validation Scores: [1. 1. 1.]Average CV Score: 0.94Number of CV Scores used in Average: 150 We can observe that the number of cross validation scores performed is equal to the number of observations in the dataset. In this case there are 150 observations in the iris dataset. The average CV score is 94%. Leave-P-Out (LPO)Leave-P-Out is simply a nuanced diffence to the Leave-One-Out idea, in that we can select the number of p to use in our validation set. 123456lpo = LeavePOut(p=2)scores = cross_val_score(clf, X, y, cv = lpo)print(\"Cross Validation Scores: \", scores[:3])print(\"Average CV Score: \", scores.mean())print(\"Number of CV Scores used in Average: \", len(scores)) 123Cross Validation Scores: [1. 1. 1.]Average CV Score: 0.9382997762863534Number of CV Scores used in Average: 11175 As we can see this is an exhaustive method we many more scores being calculated than Leave-One-Out, even with a p = 2, yet it achieves roughly the same average CV score. Shuffle SplitUnlike KFold, ShuffleSplit leaves out a percentage of the data, not to be used in the train or validation sets. To do so we must decide what the train and test sizes are, as well as the number of splits. 123456ss = ShuffleSplit(train_size=0.6, test_size=0.3, n_splits = 5)scores = cross_val_score(clf, X, y, cv = ss)print(\"Cross Validation Scores: \", scores[:3])print(\"Average CV Score: \", scores.mean())print(\"Number of CV Scores used in Average: \", len(scores)) 123Cross Validation Scores: [0.93333333 0.93333333 0.97777778]Average CV Score: 0.9511111111111111Number of CV Scores used in Average: 5","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Cross Validation","slug":"Cross-Validation","permalink":"https://stephen-cheng.github.io/tags/Cross-Validation/"},{"name":"Data","slug":"Data","permalink":"https://stephen-cheng.github.io/tags/Data/"}],"author":"Stephen Cheng"},{"title":"Improving the Accuracy and Performance of ML Algorithms with a Bagging (Bootstrap Aggregation) Classifier","slug":"Improving-the-Accuracy-and-Performance-of-ML-Algorithms-with-a-Bagging-Bootstrap-Aggregation-Classifier","date":"2021-06-18T16:45:33.000Z","updated":"2024-04-27T18:22:07.364Z","comments":true,"path":"2021/06/18/Improving-the-Accuracy-and-Performance-of-ML-Algorithms-with-a-Bagging-Bootstrap-Aggregation-Classifier/","link":"","permalink":"https://stephen-cheng.github.io/2021/06/18/Improving-the-Accuracy-and-Performance-of-ML-Algorithms-with-a-Bagging-Bootstrap-Aggregation-Classifier/","excerpt":"","text":"&nbsp; Stephen Cheng IntroMachine Learning models such as Decision Trees, can be prone to overfitting on the training set which can lead to wrong predictions on new data. Bootstrap Aggregation (bagging) is a ensembling method that attempts to resolve overfitting for classification or regression problems. Bagging aims to improve the accuracy and performance of machine learning algorithms. It does this by taking random subsets of an original dataset, with replacement, and fits either a classifier (for classification) or regressor (for regression) to each subset. The predictions for each subset are then aggregated through majority vote for classification or averaging for regression, increasing prediction accuracy. Evaluating the Base ClassifierTo see how bagging can improve model performance, we must start by evaluating how the base classifier performs on the dataset. We will be looking to identify different classes of wines found in Sklearn’s wine dataset. The parameter as_frame is set equal to True so we do not lose the feature names when loading the data. We can predict the class of wine the unseen test set and evaluate the model performance. 12345678910111213141516171819202122from sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import BaggingClassifierfrom sklearn.tree import plot_treeimport matplotlib.pyplot as pltdata = datasets.load_wine(as_frame = True)X = data.datay = data.targetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)dtree = DecisionTreeClassifier(random_state = 22)dtree.fit(X_train,y_train)y_pred = dtree.predict(X_test)print(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))print(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred)) 12Train data accuracy: 1.0Test data accuracy: 0.8222222222222222 The base classifier performs reasonably well on the dataset achieving 82% accuracy on the test dataset with the current parameters (Different results may occur if you do not have the random_state parameter set). Now that we have a baseline accuracy for the test dataset, we can see how the Bagging Classifier out performs a single Decision Tree Classifier. Creating a Bagging ClassifierFor bagging we need to set the parameter n_estimators, this is the number of base classifiers that our model is going to aggregate together. For this sample dataset the number of estimators is relatively low, it is often the case that much larger ranges are explored. Hyperparameter tuning is usually done with a grid search, but for now we will use a select set of values for the number of estimators. We start by importing the necessary model. To see how the Bagging Classifier performs with differing values of n_estimators we need a way to iterate over the range of values and store the results from each ensemble. The default parameter for the base classifier in BaggingClassifier is the DicisionTreeClassifier therefore we do not need to set it when instantiating the bagging model. With the models and scores stored, we can evaluate and visualize the BaggingClassifier performance. 12345678910111213141516171819202122232425262728estimator_range = [2,4,6,8,10,12,14,16]models = []scores = []for n_estimators in estimator_range: # Create bagging classifier clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22) # Fit the model clf.fit(X_train, y_train) # Append the model and score to their respective list models.append(clf) scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))# Generate the plot of scores against number of estimatorsplt.figure(figsize=(9,6))plt.plot(estimator_range, scores)# Adjust labels and font (to make visable)plt.xlabel(\"n_estimators\", fontsize = 18)plt.ylabel(\"score\", fontsize = 18)plt.tick_params(labelsize = 16)# Visualize plotplt.show() By iterating through different values for the number of estimators we can see an increase in model performance from 82.2% to 95.5%. After 14 estimators the accuracy begins to drop, again if you set a different random_state the values you see will vary. That is why it is best practice to use cross validation to ensure stable results. In this case, we see a 13.3% increase in accuracy when it comes to identifying the type of the wine. Another Form of EvaluationAs bootstrapping chooses random subsets of observations to create classifiers, there are observations that are left out in the selection process. These “out-of-bag” observations can then be used to evaluate the model, similarly to that of a test set. Keep in mind, that out-of-bag estimation can overestimate error in binary classification problems and should only be used as a compliment to other metrics. We saw in the last example that 12 estimators yielded the highest accuracy, so we will use that to create our model. This time setting the parameter oob_score to true to evaluate the model with out-of-bag score. 12345678oob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)oob_model.fit(X_train, y_train)y_pred2 = oob_model.predict(X_test)print(\"Out-of-bag test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred2))print(\"Out-of-bag score:\", oob_model.oob_score_) 12Out-of-bag test data accuracy: 0.9555555555555556Out-of-bag score: 0.9398496240601504 Since the samples used in OOB and the test set are different, and the dataset is relatively small, there is a difference in the accuracy score (93.98%). It is rare that they would be exactly the same, again OOB should be used quick means for estimating error, but is not the only evaluation metric. The bagging classifier performs pretty well on the dataset achieving 95.5% accuracy on the test dataset with 12 estimators. Generating Decision TreesIt is possible to see the individual decision trees that went into the aggregated classifier. This helps us to gain a more intuitive understanding on how the bagging model arrives at its predictions. However, this is only functional with smaller datasets, where the trees are relatively shallow and narrow making them easy to visualize. The different trees can be graphed by changing the estimator you wish to visualize. 123456789clf2 = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)clf2.fit(X_train, y_train)plt.figure(figsize=(15, 10))plot_tree(clf2.estimators_[0], feature_names = X.columns)plt.show() Here we can see just the first decision tree that was used to vote on the final prediction. Again, by changing the index of the classifier you can see each of the trees that have been aggregated.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Bagging Classifier","slug":"Bagging-Classifier","permalink":"https://stephen-cheng.github.io/tags/Bagging-Classifier/"},{"name":"Bootstrap Aggregation","slug":"Bootstrap-Aggregation","permalink":"https://stephen-cheng.github.io/tags/Bootstrap-Aggregation/"}],"author":"Stephen Cheng"},{"title":"Choosing the Best Value for K in K-means by Using the Elbow Method","slug":"choosing-the-best-value-for-K-in-K-means-byusing-the-elbow-method","date":"2021-03-11T02:24:38.000Z","updated":"2024-11-13T22:04:23.299Z","comments":true,"path":"2021/03/10/choosing-the-best-value-for-K-in-K-means-byusing-the-elbow-method/","link":"","permalink":"https://stephen-cheng.github.io/2021/03/10/choosing-the-best-value-for-K-in-K-means-byusing-the-elbow-method/","excerpt":"","text":"&nbsp; Stephen Cheng IntroK-means is an unsupervised learning method for clustering data points. The algorithm iteratively divides data points into K clusters by minimizing the variance in each cluster. Here, we will show you how to estimate the best value for K using the elbow method, then use K-means clustering to group the data points into clusters. K-meansFirst, each data point is randomly assigned to one of the K clusters. Then, we compute the centroid (functionally the center) of each cluster, and reassign each data point to the cluster with the closest centroid. We repeat this process until the cluster assignments for each data point are no longer changing. K-means clustering requires us to select K, the number of clusters we want to group the data into. The elbow method lets us graph the inertia (a distance-based metric) and visualize the point at which it starts decreasing linearly. This point is referred to as the “eblow” and is a good estimate for the best value for K based on our data. ExampleIn order to find the best value for K, we need to run K-means across our data for a range of possible values. We only have 10 data points, so the maximum number of clusters is 10. So for each value K in range(1,11), we train a K-means model and plot the intertia at that number of clusters: 12345678910111213141516171819import matplotlib.pyplot as pltfrom sklearn.cluster import KMeansx = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]data = list(zip(x, y))inertias = []for i in range(1,11): kmeans = KMeans(n_clusters=i) kmeans.fit(data) inertias.append(kmeans.inertia_)plt.plot(range(1,11), inertias, marker='o')plt.title('Elbow method')plt.xlabel('Number of clusters')plt.ylabel('Inertia')plt.show() We can see that the “elbow” on the graph above (where the interia becomes more linear) is at K=2. We can then fit our K-means algorithm one more time and plot the different clusters assigned to the data: 12345kmeans = KMeans(n_clusters=2)kmeans.fit(data)plt.scatter(x, y, c=kmeans.labels_)plt.show()","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Kmeans","slug":"Kmeans","permalink":"https://stephen-cheng.github.io/tags/Kmeans/"}],"author":"Stephen Cheng"},{"title":"Table Detection with Detectron2 & Mask R-CNN","slug":"table-detection-with-detectron2-n-maskrcnn","date":"2020-11-22T17:13:38.000Z","updated":"2023-11-30T19:55:51.440Z","comments":true,"path":"2020/11/22/table-detection-with-detectron2-n-maskrcnn/","link":"","permalink":"https://stephen-cheng.github.io/2020/11/22/table-detection-with-detectron2-n-maskrcnn/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Detectron2 is Facebook AI Research’s new software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from Mask R-CNN. Table detection is a crucial step in many document analysis applications as tables are used for presenting essential information to the reader in a structured manner. It is a hard problem due to varying layouts and encodings of the tables. Researchers have proposed numerous techniques for table detection based on layout analysis of documents. Most of these techniques fail to generalize because they rely on hand engineered features which are not robust to layout variations. In this post, we propose a detectron2 based method for table detection. Why use detectron2? It is powered by the PyTorch deep learning framework. It Include more features such as panoptic segmentation, Densepose, Cascade R-CNN, rotated bounding boxes, PointRend, DeepLab, etc. It can be used as a library to support different projects on top of it. It trains very faster. The Models can be exported to torchscript format or caffe2 format for deployment. How to implement?The implemented CODE contains THREE parts: Create custom COCO dataset You can run the voc2coco.py script to generate a COCO data formatted JSON file. 1python voc2coco.py ./dataset/annotations ./dataset/coco/output.json Then you can run the following Jupyter notebook to visualize the coco annotations. COCO_Image_Viewer.ipynb Training 1python table_detect_train.py Evaluation 1python table_detect_test.py","categories":[{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/categories/Computer-Vision/"}],"tags":[{"name":"Object-Detection","slug":"Object-Detection","permalink":"https://stephen-cheng.github.io/tags/Object-Detection/"},{"name":"Table-Detection","slug":"Table-Detection","permalink":"https://stephen-cheng.github.io/tags/Table-Detection/"}],"author":"Stephen Cheng"},{"title":"Grammatical-Error-Correction Sequence Tagging System with an Pretrained BERT-like Transformer Encoder","slug":"Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder","date":"2020-10-19T06:19:41.000Z","updated":"2023-11-30T19:56:47.192Z","comments":true,"path":"2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/","link":"","permalink":"https://stephen-cheng.github.io/2020/10/19/Grammatical-Error-Correction-with-The-Pretrained-BERT-Transformer-Encoder/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Here a simple and efficient GEC (Grammatical Error Correction) sequence tagger using a Transformer encoder is introduced. It is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. In addition, a custom token-level transformation to map input tokens to target corrections is designed. The original paper can be found here. Thus the GEC sequence tagging system here consists of three training stages: pretraining on synthetic data, fine-tuning on an errorful parallel corpus, and finally, fine-tuning on a combination of errorful and error-free parallel corpora. The GEC sequence tagging system incorporates a pre-trained Transformer encoder, those encoders from XLNet and RoBERTaoutperform three other cutting-edge Transformer encoders (ALBERT, BERT, and GPT-2). Use CaseThe original code of the GEC sequence tagging model is here, more details of running code are also included.","categories":[{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"}],"tags":[{"name":"Grammatical-Error-Correction","slug":"Grammatical-Error-Correction","permalink":"https://stephen-cheng.github.io/tags/Grammatical-Error-Correction/"},{"name":"BERT","slug":"BERT","permalink":"https://stephen-cheng.github.io/tags/BERT/"},{"name":"Transformers","slug":"Transformers","permalink":"https://stephen-cheng.github.io/tags/Transformers/"}],"author":"Stephen Cheng"},{"title":"Spelling Correction with Soft-Masked BERT","slug":"spelling-correction-with-soft-masked-bert","date":"2020-09-06T16:47:42.000Z","updated":"2023-11-30T19:55:57.694Z","comments":true,"path":"2020/09/06/spelling-correction-with-soft-masked-bert/","link":"","permalink":"https://stephen-cheng.github.io/2020/09/06/spelling-correction-with-soft-masked-bert/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Sotf-Masked BERT is a novel neural architecture to address the aforementioned issue, which consists of a network for error detection and a network for error correction based on BERT, with the former being connected to the latter with what we call soft-masking technique. The method uses ‘Soft-Masked BERT’ is general, and it may be employed in other language detection-correction problems not just focusing on CSC (Chinese Spelling error Correction) domain as it’s proposed in the original paper. The Architecture of Soft-Masked BERTSoft-Masked BERT is composed of a detection network based on Bi-GRU and a correction network based on BERT. The detection network predicts the probabilities of errors and the correction network predicts the probabilities of error corrections, while the former passes its prediction results to the latter using soft masking. The Model first creates an embedding for each character in the input sentence, referred to as input embedding. Next, it takes the sequence of embeddings as input and outputs the probabilities of errors for the sequence of characters (embeddings) using the detection network. After that it calculates the weighted sum of the input embeddings and [MASK] embeddings weighted by the error probabilities. The calculated embeddings mask the likely errors in the sequence in a soft way. Then it takes the sequence of soft-masked embeddings as input and outputs the probabilities of error corrections using the correction network, which is a BERT model whose final layer consists of a softmax function for all characters. There is also a residual connection between the input embeddings and the embeddings at the final layer. DemoDifferent with the original Sort-Masked BERT paper running models on Chinese dataset, here we modify a bit of code and use it in the English dataset. Dataset The data that we will use for this project will be 20 popular books from Project Gutenberg. Prerequired packages 1pip install -r requirements.txt Parameters The length of each sentence is between 4 and 200. So, 12max_len = 32min_len = 2 code You can find the code on Github How to run? Prepare Data: 1python data_prepare.py Process Data: 1python data_process.py Train Models: 1python train.py Test Models: 1python test.py","categories":[{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"}],"tags":[{"name":"BERT","slug":"BERT","permalink":"https://stephen-cheng.github.io/tags/BERT/"},{"name":"Spelling-Correction","slug":"Spelling-Correction","permalink":"https://stephen-cheng.github.io/tags/Spelling-Correction/"}],"author":"Stephen Cheng"},{"title":"Spelling Correction with Python Spellchecker","slug":"spelling-correction-with-python-spellchecker","date":"2020-08-16T18:52:42.000Z","updated":"2023-11-30T19:56:00.583Z","comments":true,"path":"2020/08/16/spelling-correction-with-python-spellchecker/","link":"","permalink":"https://stephen-cheng.github.io/2020/08/16/spelling-correction-with-python-spellchecker/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Spelling checking or spelling correction is a basic requirement in any text processing or analysis. The python package pyspellchecker provides us this feature to find the words that may have been mis-spelled and also suggest the possible corrections. pyspellchecker supports multiple languages including English, Spanish, German, French, and Portuguese. And it supports Python 3 and Python 2.7. pyspellchecker allows for the setting of the Levenshtein Distance to check. For longer words, it is highly recommended to use a distance of 1 and not the default 2. How to install?1pip install pyspellchecker How to use? With the default Word Frequency list 12345678910111213from spellchecker import SpellCheckerspell = SpellChecker()# find those words that may be misspelledmisspelled = spell.unknown(['let', 'us', 'wlak','on','the','groun'])for word in misspelled: # Get the one `most likely` answer print(spell.correction(word)) # Get a list of `likely` options print(spell.candidates(word)) Output: 1234group&#123;'group', 'ground', 'groan', 'grout', 'grown', 'groin'&#125;walk&#123;'flak', 'weak', 'walk'&#125; With the customized Word Frequency list You can add additional text to generate a more appropriate list for your use case. 12345678from spellchecker import SpellCheckerspell = SpellChecker() # loads default word frequency listspell.word_frequency.load_text_file('./word_frequency.txt')# if you just want to make sure some words are not flagged as misspelledspell.word_frequency.load_words(['microsoft', 'apple', 'google'])spell.known(['microsoft', 'google']) # will return both now! Set the distance parameter If the words that you wish to check are long, it is recommended to reduce the distance to 1. This can be accomplished either when initializing the spell check class or after the fact. 1234567from spellchecker import SpellCheckerspell = SpellChecker(distance=1) # set at initialization# do some work on longer wordsspell.distance = 2 # set the distance parameter back to the default Additional Methodscandidates(word): Returns a set of possible candidates for the misspelled word word_probability(word): The frequency of the given word out of all words in the frequency list correction(word): Returns the most probable result for the misspelled word known([words]): Returns those words that are in the word frequency list unknown([words]): Returns those words that are not in the frequency list","categories":[{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"}],"tags":[{"name":"Spelling-Correction","slug":"Spelling-Correction","permalink":"https://stephen-cheng.github.io/tags/Spelling-Correction/"},{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/tags/Natural-Language-Processing/"}],"author":"Stephen Cheng"},{"title":"Spelling Correction with The Pretrained BERT Model","slug":"spelling-correction-with-pretrained-bert","date":"2020-07-18T14:47:52.000Z","updated":"2023-11-30T19:55:38.898Z","comments":true,"path":"2020/07/18/spelling-correction-with-pretrained-bert/","link":"","permalink":"https://stephen-cheng.github.io/2020/07/18/spelling-correction-with-pretrained-bert/","excerpt":"","text":"&nbsp; Stephen Cheng Intro BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering, Natural Language Inference, and others. BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models. BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word). Demo Import necessary libraris 12345678910import reimport nltkimport numpy as npfrom PIL import Imageimport matplotlib.pyplot as pltfrom pytesseract import image_to_stringfrom enchant.checker import SpellCheckerfrom difflib import SequenceMatcherimport torchfrom pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM Process images by using OCR 12345678imagename = '1.png'pil_img = Image.open(imagename)text = image_to_string(pil_img)text_original = str(text)print(text)plt.figure(figsize = (12,4))plt.imshow(np.asarray(pil_img)) Output: 123national economy gained momentum in recent weeks as con@gmer spendingStrengthened, manufacturing activity cont@™ed to rise, and producersscheduled more investment in plant and equipment. Process text and mask incorrect words 12345678910111213141516171819202122232425262728293031323334353637383940414243# text cleanuprep = &#123;'\\n': ' ', '\\\\': ' ', '\\\"': '\"', '-': ' ', '\"': ' \" ', ',':' , ', '.':' . ', '!':' ! ', '?':' ? ', \"n't\": \" not\", \"'ll\": \" will\", '*':' * ', '(': ' ( ', ')': ' ) ', \"s'\": \"s '\"&#125;rep = dict((re.escape(k), v) for k, v in rep.items())pattern = re.compile(\"|\".join(rep.keys()))text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)def get_personslist(text): personslist = [] for sent in nltk.sent_tokenize(text): for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))): if isinstance(chunk, nltk.tree.Tree) and chunk.label() == 'PERSON': personslist.insert(0, (chunk.leaves()[0][0])) return list(set(personslist))personslist = get_personslist(text)ignorewords = personslist + [\"!\", \",\", \".\", \"\\\"\", \"?\", '(', ')', '*', \"''\"]# use SpellChecker to find incorrect wordsd = SpellChecker(\"en_US\")words = text.split()incorrectwords = [w for w in words if not d.check(w) and w not in ignorewords]# use SpellChecker to get suggested replacementssuggestedwords = [d.suggest(w) for w in incorrectwords]# replace incorrect words with [MASK]for w in incorrectwords: text = text.replace(w, '[MASK]')print(text) Output: 1national economy gained momentum in recent weeks as [MASK] spending Strengthened , manufacturing activity [MASK] to rise , and producers scheduled more investment in plant and equipment . Use the pretrained BERT model to predict words12345678910111213141516171819202122232425# Tokenize texttokenizer = BertTokenizer.from_pretrained('bert-base-uncased')tokenized_text = tokenizer.tokenize(text)indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)MASKIDS = [i for i, e in enumerate(tokenized_text) if e == '[MASK]']# Create the segments tensorssegs = [i for i, e in enumerate(tokenized_text) if e == \".\"]segments_ids = []prev = -1for k, s in enumerate(segs): segments_ids = segments_ids + [k] * (s-prev) prev = ssegments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))segments_tensors = torch.tensor([segments_ids])# prepare Torch inputstokens_tensors = torch.tensor([indexed_tokens])# Load pre-trained modelmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')# Predict all tokenswith torch.no_grad(): predictions = model(tokens_tensors, segments_tensors) Match with proposals from SpellChecker 1234567891011121314151617def predict_word(text_original, predictions, MASKIDS): pred_words = [] for i in range(len(MASKIDS)): preds = torch.topk(predictions[0, MASKIDS[i]], k=50) indices = preds.indices.tolist() pred_list = tokenizer.convert_ids_to_tokens(indices) sugg_list = suggestedwords[i] sim_max = 0 predicted_token = '' for word1 in pred_list: for word2 in sugg_list: s = SequenceMatcher(None, word1, word2).ratio() if s is not None and s &gt; sim_max: sim_max = s predicted_token = word1 text_original = text_original.replace('[MASK]', predicted_token, 1) return text_original 12text_refined = predict_word(text, predictions, MASKIDS)print(text_refined) Output: 1national economy gained momentum in recent weeks as consumer spending Strengthened , manufacturing activity continued to rise , and producers scheduled more investment in plant and equipment .","categories":[{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"}],"tags":[{"name":"BERT","slug":"BERT","permalink":"https://stephen-cheng.github.io/tags/BERT/"},{"name":"Spelling-Correction","slug":"Spelling-Correction","permalink":"https://stephen-cheng.github.io/tags/Spelling-Correction/"}],"author":"Stephen Cheng"},{"title":"Spelling Corrector from Scratch","slug":"Spelling-Corrector-from-Scratch","date":"2020-06-19T17:25:39.000Z","updated":"2023-11-30T19:55:54.119Z","comments":true,"path":"2020/06/19/Spelling-Corrector-from-Scratch/","link":"","permalink":"https://stephen-cheng.github.io/2020/06/19/Spelling-Corrector-from-Scratch/","excerpt":"","text":"&nbsp; Stephen Cheng Intro To a entry-level NLP learner, an industrial-strength spell corrector are quite complex, but writing a toy spelling corrector from scratch that achieves 80% or 90% accuracy at a processing speed of tens of words per second in a few dozens of lines of code is possible. Here is the code: 123456789101112131415161718192021222324252627282930313233343536import refrom collections import Counterdef words(text): return re.findall(r'\\w+', text.lower())WORDS = Counter(words(open('book.txt').read()))def P(word, N=sum(WORDS.values())): \"Probability of `word`.\" return WORDS[word] / Ndef correction(word): \"Most probable spelling correction for word.\" return max(candidates(word), key=P)def candidates(word): \"Generate possible spelling corrections for word.\" return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])def known(words): \"The subset of `words` that appear in the dictionary of WORDS.\" return set(w for w in words if w in WORDS)def edits1(word): \"All edits that are one edit away from `word`.\" letters = 'abcdefghijklmnopqrstuvwxyz' splits = [(word[:i], word[i:]) for i in range(len(word) + 1)] deletes = [L + R[1:] for L, R in splits if R] transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)&gt;1] replaces = [L + c + R[1:] for L, R in splits if R for c in letters] inserts = [L + c + R for L, R in splits for c in letters] return set(deletes + transposes + replaces + inserts)def edits2(word): \"All edits that are two edits away from `word`.\" return (e2 for e1 in edits1(word) for e2 in edits1(e1)) The book.txt dataset could be any English e-book. The function correction(word) returns a likely spelling correction: 12345&gt;&gt;&gt; correction('speling')'spelling'&gt;&gt;&gt; correction('korrectud')'corrected' How does it work?The above function uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results. The correction(A) function tries to choose the most likely spelling correction for A. There is no way to know for sure (for example, should “lates” be corrected to “late” or “latest” or “lattes” or …?), which suggests we use probabilities. We are trying to find the correction B, out of all possible candidate corrections, that maximizes the probability that B is the intended correction, given the original word A. ReferencePeter Norvig’s blog","categories":[{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"}],"tags":[{"name":"Spelling-Correction","slug":"Spelling-Correction","permalink":"https://stephen-cheng.github.io/tags/Spelling-Correction/"},{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/tags/Natural-Language-Processing/"}],"author":"Stephen Cheng"},{"title":"Convert Pre-trained Model from MXNet to PyTorch or TensorFlow","slug":"Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow","date":"2020-04-20T17:20:22.000Z","updated":"2023-11-30T19:56:54.364Z","comments":true,"path":"2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/","link":"","permalink":"https://stephen-cheng.github.io/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models. Sometimes, when you find a fantastic GitHub repository which share a pre-trained model on a framework which you are not familiar with. For example, you are an expert PyTorch deep learning code developer, meanwhile you find a great code with its pre-trained model on MXNet; and you want to modify this model according to your needs. Thus, deep learning model conversion tools are extremely needed. As each framework has its own structure, converting a model between two different frameworks requires a great knowledge of both of them. However, There are many fantastic model conversion tools such as ONNX, MMdnn, and etc. for converting and visualizing deep models between a wide collection of frameworks. Model Convertors ONNX ONNX is an effort to unify converters for neural networks in order to bring some sanity to the NN world. Released by Facebook and Microsoft. MMdnn MMdnn (Model Management Deep Neural Network) is supported by Microsoft, By using MMdnn, one can convert each model from the origin framework to a standard Intermediate Representation (IR), and then convert the IR format to the target framework structure. It can convert models between CaffeEmit, CNTK, CoreML, Keras, MXNet, ONNX, PyTorch and TensorFlow. PyTorch convertor PyTorch convertor can convert models to PyTorch model. TensorFlow convertor TensorFlow convertor can convert models to TensorFlow model. Keras convertor Keras convertor can convert models to Keras model. MXNet convertor MXNet convertor can convert models to MXNet model. Caffe convertor Caffe convertor can convert models to Caffe model. Caffe2 convertor Caffe2 convertor can convert models to Caffe2 model. CNTK convertor CNTK convertor can convert models to CNTK model. Theano/Lasagne convertor Theano/Lasagne convertor can convert models to Theano/Lasagne model. Darknet convertor Darknet convertor can convert models to Darknet model. Torch convertor Torch convertor can convert models to Torch model. Neon convertor Neon convertor can convert models to Neon model. CoreML convertor CoreML convertor can convert models to coreML model. Paddle convertor Paddle convertor can convert models to Paddle model. Chainer convertor Chainer convertor can convert models to Chainer model. A Demo of Model Convertion from MXNet to PyTorch Here is an appropriate example to convert the Full ImageNet pre-trained model from MXNet to PyTorch via MMdnn convertor. ImageNet is an image database organized according to the WordNet hierarchy, in which each node of the hierarchy is depicted by hundreds and thousands of images. Since 2010, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a competition where research teams evaluate their algorithms on the given data set, and compete to achieve higher accuracy on several visual recognition tasks. A common reason to train a network on ImageNet data is to use it for transfer learning (including feature extraction or fine-tuning other models). Having a pre-trained model which is trained on such a huge training data set (i.e., full ImageNet), would be a really valuable network. It can speed up the convergence early in the training phase, and also improves the target task accuracy in some scenarios. Prerequisites: 1sudo pip3 install --upgrade mmdnn 1sudo pip3 install --upgrade torch torchvision Download pre-trained models: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import osimport errno_base_model_url = 'http://data.mxnet.io/models/'_default_model_info = &#123; 'imagenet11k-resnet-152': &#123;'symbol':_base_model_url+'imagenet-11k/resnet-152/resnet-152-symbol.json', 'params':_base_model_url+'imagenet-11k/resnet-152/resnet-152-0000.params'&#125;,&#125;def download_file(url, local_fname=None, force_write=False): # requests is not default installed import requests if local_fname is None: local_fname = url.split('/')[-1] if not force_write and os.path.exists(local_fname): return local_fname dir_name = os.path.dirname(local_fname) if dir_name != \"\": if not os.path.exists(dir_name): try: # try to create the directory if it doesn't exists os.makedirs(dir_name) except OSError as exc: if exc.errno != errno.EEXIST: raise r = requests.get(url, stream=True) assert r.status_code == 200, \"failed to open %s\" % url with open(local_fname, 'wb') as f: for chunk in r.iter_content(chunk_size=1024): if chunk: # filter out keep-alive new chunks f.write(chunk) return local_fnamedef download_model(model_name, dst_dir='./', meta_info=None): if meta_info is None: meta_info = _default_model_info meta_info = dict(meta_info) if model_name not in meta_info: return (None, 0) if not os.path.isdir(dst_dir): os.mkdir(dst_dir) meta = dict(meta_info[model_name]) assert 'symbol' in meta, \"missing symbol url\" model_name = os.path.join(dst_dir, model_name) download_file(meta['symbol'], model_name+'-symbol.json') assert 'params' in meta, \"mssing parameter file url\" download_file(meta['params'], model_name+'-0000.params') return (model_name, 0)if __name__ == \"__main__\": # ***** Download synset (i.e., Synonym Set): synset_url = 'http://data.mxnet.io.s3-website-us-west-1.amazonaws.com/models/imagenet-11k/synset.txt' download_file(synset_url, 'synset.txt') # ***** Download Model: download_model('imagenet11k-resnet-152', dst_dir='./') Converting Full ImageNet Pre-trained Model from MXNet to PyTorch: 1python3 -m mmdnn.conversion._script.convertToIR -f mxnet -n imagenet11k-resnet-152-symbol.json -w imagenet11k-resnet-152-0000.params -d resnet152 --inputShape 3,224,224 1python3 -m mmdnn.conversion._script.IRToCode -f pytorch --IRModelPath resnet152.pb --dstModelPath kit_imagenet.py --IRWeightPath resnet152.npy -dw kit_pytorch.npy 1python3 -m mmdnn.conversion.examples.pytorch.imagenet_test --dump resnet152Full.pth -n kit_imagenet.py -w kit_pytorch.npy Testing the Converted Model: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import torchimport numpy as npfrom tensorflow.contrib.keras.api.keras.preprocessing import image# ************** Parameters:num_predictions = 5 # Top-k Resultsmodel_address = 'resnet152Full.pth' # for loading modelslexicon_address = 'synset.txt'test_image_address = 'seagull.jpg'device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")# Load Converted Model:model = torch.load(model_address).to(device)model.eval()# Read Input Image and Apply Pre-process:img = image.load_img(test_image_address, target_size=(224, 224))x = image.img_to_array(img)x = x[..., ::-1] # transform image from RGB to BGRx = np.transpose(x, (2, 0, 1))x = np.expand_dims(x, 0).copy()x = torch.from_numpy(x)x = x.to(device)# Load Full-ImageNet Dictionary (i.e., lexicon):with open(lexicon_address, 'r') as f: labels = [l.rstrip() for l in f]# Make prediction (forward pass):with torch.no_grad(): output = model(x)max, argmax = output.data.squeeze().max(0)class_id = argmax.item()class_name = labels[class_id]# Print the top-5 Results:h_x = output.data.squeeze()probs, idx = h_x.sort(0, True)print('Top-5 Results: ')for i in range(0, num_predictions): print('&#123;:.2f&#125;% -&gt; &#123;&#125;'.format(probs[i] * 100.0, labels[idx[i]]))str_final_label = 'The Image is a ' + class_name[10:] + '.'print(str_final_label)","categories":[{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"https://stephen-cheng.github.io/tags/PyTorch/"},{"name":"TenforFlow","slug":"TenforFlow","permalink":"https://stephen-cheng.github.io/tags/TenforFlow/"},{"name":"Pre-trained-Model","slug":"Pre-trained-Model","permalink":"https://stephen-cheng.github.io/tags/Pre-trained-Model/"}],"author":"Stephen Cheng"},{"title":"Automatic Clustering with Silhouette Analysis on Agglomerative Hierarchical Clustering","slug":"automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering","date":"2020-03-22T14:32:33.000Z","updated":"2023-11-30T19:57:01.882Z","comments":true,"path":"2020/03/22/automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering/","link":"","permalink":"https://stephen-cheng.github.io/2020/03/22/automatic-clustering-with-silhouette-analysis-on-agglomerative-hierarchical-clustering/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Automatic clustering algorithms are algorithms that can perform clustering without prior knowledge of data sets, and determine the optimal number of clusters even in the presence of noise and outlier points. Silhouette Analysis Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters. The silhouette score is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters. Thus silhouette analysis can be used to choose an optimal number for clusters automatically. Agglomerative Hierarchical Clustering Hierarchical clustering algorithms fall into 2 branches: top-down or bottom-up. Bottom-up algorithms treat each data point as a single cluster at the outset and then successively merge (or agglomerate) pairs of clusters until all clusters have been merged into a single cluster that contains all data points. Bottom-up hierarchical clustering is therefore called hierarchical agglomerative clustering or HAC. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample. The Steps of Hierarchical clustering: We start by treating each data point as a single cluster i.e. if there are N data points in our dataset then we have N clusters. We then select a distance metric that measures the distance between two clusters. As an example, we will use average linkage which defines the distance between two clusters to be the average distance between data points in the first cluster and data points in the second cluster. On each iteration, two clusters are combined into one. The two clusters to be combined are selected as those with the smallest average linkage. I.e. according to our selected distance metric, these two clusters have the smallest distance between each other and therefore are the most similar and should be combined. Step 2 is repeated until we reach the root of the tree that one cluster contains all data points. In this way we can select how many clusters we want in the end simply by choosing when to stop combining the clusters i.e. when we stop building the tree! Automatic ClusteringSince hierarchical clustering does not require us to specify the number of clusters and we can even select which number of clusters looks best since we are building a tree. Here we use the silhouette score to help us determine choosing the optimal number of clusters for clustering task automatically. An example of auto-clustering with silhouette analysis on agglomerative hierarchical clustering is shown as follows. 12345678import pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom sklearn.decomposition import PCAfrom sklearn.cluster import AgglomerativeClusteringfrom sklearn.preprocessing import StandardScaler, normalizefrom sklearn.metrics import silhouette_scoreimport scipy.cluster.hierarchy as shc Load and clean the data: 1234567X = pd.read_csv('customer_info.csv')# Dropping the CUST_ID column from the dataX = X.drop('CUST_ID', axis = 1)# Handling the missing valuesX.fillna(method ='ffill', inplace = True) Preprocess the data: 12345678910# Scaling the data so that all the features become comparablescaler = StandardScaler()X_scaled = scaler.fit_transform(X)# Normalizing the data so that the data approximately # follows a Gaussian distributionX_normalized = normalize(X_scaled)# Converting the numpy array into a pandas DataFrameX_normalized = pd.DataFrame(X_normalized) Reduce the dimensionality: 1234pca = PCA(n_components = 2)X_new = pca.fit_transform(X_normalized)df_new = pd.DataFrame(X_new)df_new.columns = ['P1', 'P2'] Visualize the dendograms: 123plt.figure(figsize =(8, 8))plt.title('Visualising Clustering')Dendrogram = shc.dendrogram((shc.linkage(df_new, method ='ward'))) Evaluate the clustering models: 123456789101112131415161718k = range(2,10)ac_list = [AgglomerativeClustering(n_clusters = i) for i in k]# Appending the silhouette scoressilhouette_scores = &#123;&#125;silhouette_scores.fromkeys(k)for i,j in enumerate(k): silhouette_scores[j] = silhouette_score(df_new, ac_list[i].fit_predict(df_new))# Plottingy = list(silhouette_scores.values())plt.bar(k, y)plt.xlabel('Number of clusters', fontsize = 20)plt.ylabel('S(i)', fontsize = 20)plt.show() From the result above, we can conclude that 3 clusters obtain the highest silhouette score so the optimal number of clusters is 3 in this case. The complete code and dataset can be found here Reference[1] Wikipedia-Automatic clustering algorithms[2] https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html[3] The 5 Clustering Algorithms Data Scientists Need to Know","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Hierarchical-Clustering","slug":"Hierarchical-Clustering","permalink":"https://stephen-cheng.github.io/tags/Hierarchical-Clustering/"},{"name":"Silhouette","slug":"Silhouette","permalink":"https://stephen-cheng.github.io/tags/Silhouette/"}],"author":"Stephen Cheng"},{"title":"Object Detection with Luminoth Step by Step","slug":"object-detection-with-luminoth-step-by-step","date":"2020-02-14T22:19:36.000Z","updated":"2023-11-30T19:56:22.663Z","comments":true,"path":"2020/02/14/object-detection-with-luminoth-step-by-step/","link":"","permalink":"https://stephen-cheng.github.io/2020/02/14/object-detection-with-luminoth-step-by-step/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Luminoth is an open source toolkit for computer vision. It supports object detection and it’s built in Python, using TensorFlow. The code is open source and available on GitHub. Detecting Objects with a Pre-trained ModelThe first thing is being familiarized with the Luminoth CLI tool, that is, the tool that you interact with using the lumi command. This is the main gate to Luminoth, allowing you to train new models, evaluate them, use them for predictions, manage the checkpoints and more. If we want Luminoth to predict the objects present in one of pictures (image.jpg). The way to do that is by running the following command: 1lumi predict image.jpg The result will be like this: 123Found 1 files to predict.Neither checkpoint not config specified, assuming `accurate`.Checkpoint not found. Check remote repository? [y/N]: Since you didn’t tell Luminoth what an “object” is for you, nor have taught it how to recognize said objects. So one way to do this is to use a pre-trained model that has been trained to detect popular types of objects. E.g., it can be a model trained with COCO dataset or Pascal VOC. What’s more, each pre-trained model might be associated with a different algorithm. The checkpoints correspond to the weights of a particular model (Faster R-CNN or SSD), trained with a particular dataset. The case of “accurate” is just a label for a particular Deep Learning model underneath, here, Faster R-CNN, trained with images from the COCO dataset. After the checkpoint download, with these commands we can output everything (a resulting image and a json file) to a preds directory: 12mkdir predslumi predict image.jpg -f preds/objects.json -d preds/ Exploring the Pre-trained CheckpointsFirst, run the lumi checkpoint refresh command, so Luminoth knows about the checkpoints that it has available for download. After refreshing the local index, you can list the available checkpoints running lumi checkpoint list: 123456================================================================================| id | name | alias | source | status |================================================================================| e1c2565b51e9 | Faster R-CNN w/COCO | accurate | remote | DOWNLOADED || aad6912e94d9 | SSD w/Pascal VOC | fast | remote | NOT_DOWNLOADED |================================================================================ Here, you can see the “accurate” checkpoint and another “fast” checkpoint that is the SSD model trained with Pascal VOC dataset. Let’s get some information about the “accurate” checkpoint by the following command: 1lumi checkpoint info e1c2565b51e9 or 1lumi checkpoint info accurate If getting predictions for an image or video using a specific checkpoint (e.g., fast) you can do so by using the –checkpoint parameter: 1lumi predict img.jpg --checkpoint fast -f preds/objects.json -d preds/ Playing Around with the Built-in InterfaceLuminoth includes a simple web frontend so you can play around with detected objects in images using different thresholds. To launch this, simply type lumi server web and then open your browser at http://localhost:5000. If you are running on an external VM, you can do lumi server web –host 0.0.0.0 –port to open in a custom port. Building Custom datasetIn order to use a custom dataset, we must first transform whatever format your data is in, to TFRecords files (one for each split — train, val, test). Luminoth reads datasets natively only in TensorFlow’s TFRecords format. This is a binary format that will let Luminoth consume the data very efficiently. Fortunately, Luminoth provides several CLI tools for transforming popular dataset format (such as Pascal VOC, ImageNet, COCO, CSV, etc.) into TFRecords. We should start by downloading the annotation files (this and this, for train) and the class description file. After we get the class-descriptions-boxable.csv file, we can go over all the classes available in the OpenImages dataset and see which ones are related to traffic dataset. The following were hand-picked after examining the full file: 12345678/m/015qff,Traffic light/m/0199g,Bicycle/m/01bjv,Bus/m/01g317,Person/m/04_sv,Motorcycle/m/07r04,Truck/m/0h2r6,Van/m/0k4j,Car Luminoth includes a dataset reader that can take OpenImages format, the dataset reader expects a particular directory layout so it knows where the files are located. In this case, files corresponding to the examples must be in a folder named like their split (train, test, …). So, you should have the following: 12345.├── class-descriptions-boxable.csv└── train ├── train-annotations-bbox.csv └── train-annotations-human-imagelabels-boxable.csv Then run the following command: 1234567lumi dataset transform \\ --type openimages \\ --data-dir . \\ --output-dir ./out \\ --split train \\ --class-examples 100 \\ --only-classes=/m/015qff,/m/0199g,/m/01bjv,/m/01g317,/m/04_sv,/m/07r04,/m/0h2r6,/m/0k4j This will generate TFRecord file for the train split: 12345678910INFO:tensorflow:Saved 360 records to \"./out/train.tfrecords\"INFO:tensorflow:Composition per class (train):INFO:tensorflow: Person (/m/01g317): 380INFO:tensorflow: Car (/m/0k4j): 255INFO:tensorflow: Bicycle (/m/0199g): 126INFO:tensorflow: Bus (/m/01bjv): 106INFO:tensorflow: Traffic light (/m/015qff): 105INFO:tensorflow: Truck (/m/07r04): 101INFO:tensorflow: Van (/m/0h2r6): 100INFO:tensorflow: Motorcycle (/m/04_sv): 100 Training the ModelTraining orchestration, including the model to be used, the dataset location and training schedule, is specified in a YAML config file. This file will be consumed by Luminoth and merged to the default configuration, to start the training session. You can see a minimal config file example in sample_config.yml. This file illustrates the entries you’ll most probably need to modify, which are: 1) train.run_name: the run name for the training session, used to identify it.2) train.job_dir: directory in which both model checkpoints and summaries (for TensorBoard consumption) will be saved. The actual files will be stored under /.3) dataset.dir: directory from which to read the TFRecord files.4) model.type: model to use for object detection (fasterrcnn, or ssd).5) network.num_classes: number of classes to predict (depends on your dataset). For looking at all the possible configuration options, mostly related to the model itself, you can check the base_config.yml file. Building the config file for the datasetProbably the most important setting for training is the learning rate. You will most likely want to tune this depending on your dataset, and you can do it via the train.learning_rate setting in the configuration. For example, this would be a good setting for training on the full COCO dataset: 1234learning_rate: decay_method: piecewise_constant boundaries: [250000, 450000, 600000] values: [0.0003, 0.0001, 0.00003, 0.00001] To get to this, you will need to run some experiments and see what works best. 12345678910111213141516171819train: # Run name for the training session. run_name: traffic job_dir: &lt;change this directory&gt; learning_rate: decay_method: piecewise_constant # Custom dataset for Luminoth Tutorial boundaries: [90000, 160000, 250000] values: [0.0003, 0.0001, 0.00003, 0.00001]dataset: type: object_detection dir: &lt;directory with your dataset&gt;model: type: fasterrcnn network: num_classes: 8 anchors: # Add one more scale to be better at detecting small objects scales: [0.125, 0.25, 0.5, 1, 2] Running the trainingAssuming you already have both your dataset (TFRecords) and the config file ready, you can start your training session by running the command as follows: 1lumi train -c config.yml You can use the -o option to override any configuration option using dot notation (e.g. -o model.rpn.proposals.nms_threshold=0.8). If you are using a CUDA-based GPU, you can select the GPU to use by setting the CUDA_VISIBLE_DEVICES environment variable. Storing checkpoints (partial weights)As the training progresses, Luminoth will periodically save a checkpoint with the current weights of the model. The files will be output in your / folder. By default, they will be saved every 600 seconds of training, but you can configure this with the train.save_checkpoint_secs setting in your config file. The default is to only store the latest checkpoint (that is, when a checkpoint is generated, the previous checkpoint gets deleted) in order to conserve storage. Evaluating ModelsGenerally, datasets (like OpenImages, which we just used) provide “splits”. The “train” split is the largest, and the one from which the model actually does the learning. Then, you have the “validation” (or “val”) split, which consists of different images, in which you can draw metrics of your model’s performance, in order to better tune your hyperparameters. Finally, a “test” split is provided in order to conduct the final evaluation of how your model would perform in the real world once it is trained. Building a validation datasetLet’s start by building TFRecords from the validation split of OpenImages. For this, we can download the files with the annotations and use the same lumi dataset transform that we used to build our training data. In your dataset folder (where the class-descriptions-boxable.csv is located), run the following commands: 123mkdir validationwget -P validation https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csvwget -P validation https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-human-imagelabels-boxable.csv After the downloads finish, we can build the TFRecords with the following: 1234567lumi dataset transform \\ --type openimages \\ --data-dir . \\ --output-dir ./out \\ --split validation \\ --class-examples 100 \\ --only-classes=/m/015qff,/m/0199g,/m/01bjv,/m/01g317,/m/04_sv,/m/07r04,/m/0h2r6,/m/0k4j The lumi eval commandIn Luminoth, lumi eval will make a run through your chosen dataset split (ie. validation or test), and run the model through every image, and then compute metrics like loss and mAP. If you are lucky and happen to have more than one GPU in your machine, it is advisable to run both train and eval at the same time. Start by running the evaluation: 1lumi eval --split validation -c custom.yml The mAP metricsMean Average Precision (mAP) is the metric commonly used to evaluate object detection task. It computes how well your classifier works across all classes, mAP will be a number between 0 and 1, and the higher the better. Moreover, it can be calculated across different IoU (Intersection over Union) thresholds. For example, Pascal VOC challenge metric uses 0.5 as threshold (notation mAP@0.5), and COCO dataset uses mAP at different thresholds and averages them all out (notation mAP@[0.5:0.95]). Luminoth will print out several of these metrics, specifying the thresholds that were used under this notation. Using TensorBoard for VisualizingTensorBoard is a very good tool for this, allowing you to see plenty of plots with the training related metrics. By default, Luminoth writes TensorBoard summaries during training, so you can leverage this tool without any effort: 1tensorboard --logdir &lt;job_dir&gt;/&lt;run_name&gt; If you are running from an external VM, make sure to use --host 0.0.0.0 and --port if you need other one than the default 6006. What to look forFirst, go to the “Scalars” tab. You are going to see several tags. validation_lossesHere, you will get the same loss values that Luminoth computes for the train, but for the chosen dataset split (validation, in this case). As in the case of train, you should mostly look at validation_losses/no_reg_loss. These will be the mAP metrics that will help you judge how well your model perform: The mAP values refer to the entire dataset split, so it will not jump around as much as other metrics. Manually inspecting with lumi server webYou can also use lumi server web command that we have seen before and try your partially trained model in a bunch of novel images. For this, you can launch it with a config file like: 1lumi server web -c config.yml Here you can also use –host and –port options. Creating and Sharing Your Own CheckpointsCreating a checkpointWe can create checkpoints and set some metadata like name, alias, etc. This time, we are going to create the checkpoint for our traffic model: 1234lumi checkpoint create \\ config.yml \\ -e name=\"OpenImages Traffic\" \\ -e alias=traffic You can verify that you do indeed have the checkpoint when running lumi checkpoint list, which should get you an output similar to this: 1234567================================================================================| id | name | alias | source | status |================================================================================| e1c2565b51e9 | Faster R-CNN w/COCO | accurate | remote | DOWNLOADED || aad6912e94d9 | SSD w/Pascal VOC | fast | remote | DOWNLOADED || cb0e5d92a854 | OpenImages Traffic | traffic | local | LOCAL |================================================================================ Moreover, if you inspect the ~/.luminoth/checkpoints/ folder, you will see that now you have a folder that corresponds to your newly created checkpoint. Inside this folder are the actual weights of the model, plus some metadata and the configuration file that was used during training. Sharing checkpointsSimply run lumi checkpoint export cb0e5d92a854. You will get a file named cb0e5d92a854.tar in your current directory, which you can easily share to somebody else. By running lumi checkpoint import cb0e5d92a854.tar, the checkpoint will be listed locally. Using Luminoth with PythonCalling Luminoth from your Python app is very straightforward. 123456789101112131415from luminoth import Detector, read_image, vis_objectsimage = read_image('traffic-image.png')# If no checkpoint specified, will assume `accurate` by default. In this case,# we want to use our traffic checkpoint. The Detector can also take a config# object.detector = Detector(checkpoint='traffic')# Returns a dictionary with the detections.objects = detector.predict(image)print(objects)vis_objects(image, objects).save('traffic-out.png') The EndHope you enjoyed the simple tutorial! :)","categories":[{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/categories/Computer-Vision/"}],"tags":[{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/tags/Computer-Vision/"},{"name":"Object-Detection","slug":"Object-Detection","permalink":"https://stephen-cheng.github.io/tags/Object-Detection/"}],"author":"Stephen Cheng"},{"title":"Usage of PyTessBaseAPI in Tesserocr","slug":"Usage-of-PyTessBaseAPI-in-Tesserocr","date":"2020-01-18T20:16:21.000Z","updated":"2023-11-30T19:55:16.263Z","comments":true,"path":"2020/01/18/Usage-of-PyTessBaseAPI-in-Tesserocr/","link":"","permalink":"https://stephen-cheng.github.io/2020/01/18/Usage-of-PyTessBaseAPI-in-Tesserocr/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Tesseroct is a simple, Pillow-friendly, wrapper around the tesseract-ocr API for Optical Character Recognition (OCR), it integrates directly with Tesseract’s C++ API using Cython which allows for a simple Pythonic and easy-to-read source code. It enables real concurrent execution when used with Python’s threading module by releasing the GIL while processing an image in tesseract. Installation Linux and BSD/MacOS 1$ pip install tesserocr Windows The proposed downloads consist of stand-alone packages containing all the Windows libraries needed for execution. The recommended method of installation is via Conda as described below. 1) Conda 1&gt; conda install -c conda-forge tesserocr 2) pipDownload the wheel file corresponding to your Windows platform and Python installation from tesserocr-windows_build and install them via: 1&gt; pip install &lt;package_name&gt;.whl Usage Initialize and re-use the tesseract API instance to score multiple images: 1234567891011from tesserocr import PyTessBaseAPIimages = ['sample.jpg', 'sample2.jpg', 'sample3.jpg']with PyTessBaseAPI() as api: for img in images: api.SetImageFile(img) print(api.GetUTF8Text()) print(api.AllWordConfidences())# api is automatically finalized when used in a with-statement (context manager).# otherwise api.End() should be explicitly called when it's no longer needed. Advanced API Examples 1) GetComponentImages example: 12345678910111213141516from PIL import Imagefrom tesserocr import PyTessBaseAPI, RILimage = Image.open('/usr/src/tesseract/testing/phototest.tif')with PyTessBaseAPI() as api: api.SetImage(image) boxes = api.GetComponentImages(RIL.TEXTLINE, True) print('Found &#123;&#125; textline image components.'.format(len(boxes))) for i, (im, box, _, _) in enumerate(boxes): # im is a PIL image object # box is a dict with x, y, w and h keys api.SetRectangle(box['x'], box['y'], box['w'], box['h']) ocrResult = api.GetUTF8Text() conf = api.MeanTextConf() print(u\"Box[&#123;0&#125;]: x=&#123;x&#125;, y=&#123;y&#125;, w=&#123;w&#125;, h=&#123;h&#125;, \" \"confidence: &#123;1&#125;, text: &#123;2&#125;\".format(i, conf, ocrResult, **box)) 2) Orientation and script detection (OSD): 1234567891011121314from PIL import Imagefrom tesserocr import PyTessBaseAPI, PSMwith PyTessBaseAPI(psm=PSM.AUTO_OSD) as api: image = Image.open(\"/usr/src/tesseract/testing/eurotext.tif\") api.SetImage(image) api.Recognize() it = api.AnalyseLayout() orientation, direction, order, deskew_angle = it.Orientation() print(\"Orientation: &#123;:d&#125;\".format(orientation)) print(\"WritingDirection: &#123;:d&#125;\".format(direction)) print(\"TextlineOrder: &#123;:d&#125;\".format(order)) print(\"Deskew angle: &#123;:.4f&#125;\".format(deskew_angle)) or simply with OSD_ONLY page segmentation mode: 12345678from tesserocr import PyTessBaseAPI, PSMwith PyTessBaseAPI(psm=PSM.OSD_ONLY) as api: api.SetImageFile(\"/usr/src/tesseract/testing/eurotext.tif\") os = api.DetectOS() print(\"Orientation: &#123;orientation&#125;\\nOrientation confidence: &#123;oconfidence&#125;\\n\" \"Script: &#123;script&#125;\\nScript confidence: &#123;sconfidence&#125;\".format(**os)) more human-readable info with tesseract 4+ (with LSTM engine): 12345678from tesserocr import PyTessBaseAPI, PSM, OEMwith PyTessBaseAPI(psm=PSM.OSD_ONLY, oem=OEM.LSTM_ONLY) as api: api.SetImageFile(\"/usr/src/tesseract/testing/eurotext.tif\") os = api.DetectOrientationScript() print(\"Orientation: &#123;orient_deg&#125;\\nOrientation confidence: &#123;orient_conf&#125;\\n\" \"Script: &#123;script_name&#125;\\nScript confidence: &#123;script_conf&#125;\".format(**os)) 3） Iterator over the classifier choices for a single symbol: 123456789101112131415161718192021222324252627from __future__ import print_functionfrom tesserocr import PyTessBaseAPI, RIL, iterate_levelwith PyTessBaseAPI() as api: api.SetImageFile('/usr/src/tesseract/testing/phototest.tif') api.SetVariable(\"save_blob_choices\", \"T\") api.SetRectangle(37, 228, 548, 31) api.Recognize() ri = api.GetIterator() level = RIL.SYMBOL for r in iterate_level(ri, level): symbol = r.GetUTF8Text(level) # r == ri conf = r.Confidence(level) if symbol: print(u'symbol &#123;&#125;, conf: &#123;&#125;'.format(symbol, conf), end='') indent = False ci = r.GetChoiceIterator() for c in ci: if indent: print('\\t\\t ', end='') print('\\t- ', end='') choice = c.GetUTF8Text() # c == ci print(u'&#123;&#125; conf: &#123;&#125;'.format(choice, c.Confidence())) indent = True print('----------')","categories":[{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/categories/Computer-Vision/"}],"tags":[{"name":"OCR","slug":"OCR","permalink":"https://stephen-cheng.github.io/tags/OCR/"},{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/tags/Computer-Vision/"}],"author":"Stephen Cheng"},{"title":"PyCharm Keyboard Shortcuts","slug":"PyCharm-keyboard-shortcuts","date":"2019-12-20T03:17:38.000Z","updated":"2023-11-30T19:56:18.863Z","comments":true,"path":"2019/12/19/PyCharm-keyboard-shortcuts/","link":"","permalink":"https://stephen-cheng.github.io/2019/12/19/PyCharm-keyboard-shortcuts/","excerpt":"","text":"&nbsp; Stephen Cheng Intro PyCharm is an integrated development environment for computer programming, specifically for the Python language. It is developed by the Czech company JetBrains on February 3, 2010. Part one Part two Part three","categories":[{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/categories/Programming/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"PyCharm","slug":"PyCharm","permalink":"https://stephen-cheng.github.io/tags/PyCharm/"},{"name":"Shortcuts","slug":"Shortcuts","permalink":"https://stephen-cheng.github.io/tags/Shortcuts/"}],"author":"Stephen Cheng"},{"title":"Keras for Data Science","slug":"Keras-for-Data-Science","date":"2019-09-22T01:36:52.000Z","updated":"2023-11-30T19:56:34.417Z","comments":true,"path":"2019/09/21/Keras-for-Data-Science/","link":"","permalink":"https://stephen-cheng.github.io/2019/09/21/Keras-for-Data-Science/","excerpt":"","text":"&nbsp; Stephen Cheng Intro Keras is a powerful and easy-to-use deep learning library for Theano and TensorFlow that provides a high-level neural networks API to develop and evaluate deep learning models. A Basic Example:123456789101112131415&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from keras.models import Sequential&gt;&gt;&gt; from keras.layers import Dense&gt;&gt;&gt; data = np.random.random((1000,100))&gt;&gt;&gt; labels = np.random.randint(2,size=(1000,1))&gt;&gt;&gt; model = Sequential()&gt;&gt;&gt; model.add(Dense(32, activation='relu', input_dim=100))&gt;&gt;&gt; model.add(Dense(1, activation='sigmoid'))&gt;&gt;&gt; model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])&gt;&gt;&gt; model.fit(data,labels,epochs=10,batch_size=32)&gt;&gt;&gt; predictions = model.predict(data) DataYour data needs to be stored as NumPy arrays or as a list of NumPy arrays. Ideally, you split the data in training and test sets, for which you can also resort to the train_test_split module of sklearn.cross_validation. Keras Data Sets:123456789&gt;&gt;&gt; from keras.datasets import boston_housing, mnist, cifar10, imdb&gt;&gt;&gt; (x_train,y_train),(x_test,y_test) = mnist.load_data()&gt;&gt;&gt; (x_train2,y_train2),(x_test2,y_test2) = boston_housing.load_data()&gt;&gt;&gt; (x_train3,y_train3),(x_test3,y_test3) = cifar10.load_data()&gt;&gt;&gt; (x_train4,y_train4),(x_test4,y_test4) = imdb.load_data(num_words=20000)&gt;&gt;&gt; num_classes = 10 Other:1234&gt;&gt;&gt; from urllib.request import urlopen&gt;&gt;&gt; data = np.loadtxt(urlopen(\"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"),delimiter=\",\")&gt;&gt;&gt; X = data[:,0:8]&gt;&gt;&gt; y = data [:,8] PreprocessingSequence Padding:123&gt;&gt;&gt; from keras.preprocessing import sequence&gt;&gt;&gt; x_train4 = sequence.pad_sequences(x_train4,maxlen=80)&gt;&gt;&gt; x_test4 = sequence.pad_sequences(x_test4,maxlen=80) One-Hot Encoding:12345&gt;&gt;&gt; from keras.utils import to_categorical&gt;&gt;&gt; Y_train = to_categorical(y_train, num_classes)&gt;&gt;&gt; Y_test = to_categorical(y_test, num_classes)&gt;&gt;&gt; Y_train3 = to_categorical(y_train3, num_classes)&gt;&gt;&gt; Y_test3 = to_categorical(y_test3, num_classes) Train and Test Sets:12&gt;&gt;&gt; from sklearn.model_selection import train_test_split&gt;&gt;&gt; X_train5,X_test5,y_train5,y_test5 = train_test_split(X, y, test_size=0.33, random_state=42) Standardization/Normalization:1234&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler&gt;&gt;&gt; scaler = StandardScaler().fit(x_train2)&gt;&gt;&gt; standardized_X = scaler.transform(x_train2)&gt;&gt;&gt; standardized_X_test = scaler.transform(x_test2) Model ArchitectureSequential Model:1234&gt;&gt;&gt; from keras.models import Sequential&gt;&gt;&gt; model = Sequential()&gt;&gt;&gt; model2 = Sequential()&gt;&gt;&gt; model3 = Sequential() Multilayer Perceptron (MLP):Binary Classification 1234567&gt;&gt;&gt; from keras.layers import Dense&gt;&gt;&gt; model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))&gt;&gt;&gt; model.add(Dense(8,kernel_initializer='uniform',activation='relu'))&gt;&gt;&gt; model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid')) Multi-Class Classification 123456&gt;&gt;&gt; from keras.layers import Dropout&gt;&gt;&gt; model.add(Dense(512,activation='relu',input_shape=(784,)))&gt;&gt;&gt; model.add(Dropout(0.2))&gt;&gt;&gt; model.add(Dense(512,activation='relu'))&gt;&gt;&gt; model.add(Dropout(0.2))&gt;&gt;&gt; model.add(Dense(10,activation='softmax')) Regression 12&gt;&gt;&gt; model.add(Dense(64,activation='relu',input_dim=train_data.shape[1]))&gt;&gt;&gt; model.add(Dense(1)) Convolutional Neural Network (CNN):12345678910111213141516171819&gt;&gt;&gt; from keras.layers import Activation,Conv2D,MaxPooling2D,Flatten&gt;&gt;&gt; model2.add(Conv2D(32,(3,3),padding='same',input_shape=x_train.shape[1:]))&gt;&gt;&gt; model2.add(Activation('relu'))&gt;&gt;&gt; model2.add(Conv2D(32,(3,3)))&gt;&gt;&gt; model2.add(Activation('relu'))&gt;&gt;&gt; model2.add(MaxPooling2D(pool_size=(2,2)))&gt;&gt;&gt; model2.add(Dropout(0.25))&gt;&gt;&gt; model2.add(Conv2D(64,(3,3), padding='same'))&gt;&gt;&gt; model2.add(Activation('relu'))&gt;&gt;&gt; model2.add(Conv2D(64,(3, 3)))&gt;&gt;&gt; model2.add(Activation('relu'))&gt;&gt;&gt; model2.add(MaxPooling2D(pool_size=(2,2)))&gt;&gt;&gt; model2.add(Dropout(0.25))&gt;&gt;&gt; model2.add(Flatten())&gt;&gt;&gt; model2.add(Dense(512))&gt;&gt;&gt; model2.add(Activation('relu'))&gt;&gt;&gt; model2.add(Dropout(0.5))&gt;&gt;&gt; model2.add(Dense(num_classes))&gt;&gt;&gt; model2.add(Activation('softmax')) Recurrent Neural Network (RNN):1234&gt;&gt;&gt; from keras.klayers import Embedding,LSTM&gt;&gt;&gt; model3.add(Embedding(20000,128))&gt;&gt;&gt; model3.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))&gt;&gt;&gt; model3.add(Dense(1,activation='sigmoid')) Inspect Model12345678# Model output shape&gt;&gt;&gt; model.output_shape# Model summary representation&gt;&gt;&gt; model.summary()# Model configuration&gt;&gt;&gt; model.get_config()# List all weight tensors in the model&gt;&gt;&gt; model.get_weights() Compile ModelMLP: Binary Classification 123&gt;&gt;&gt; model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) MLP: Multi-Class Classification 123&gt;&gt;&gt; model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) MLP: Regression 1&gt;&gt;&gt; model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) Recurrent Neural Network 123&gt;&gt;&gt; model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) Model Training123456&gt;&gt;&gt; model3.fit(x_train4, y_train4, batch_size=32, epochs=15, verbose=1, validation_data=(x_test4,y_test4)) Evaluate Your Model’s Performance123&gt;&gt;&gt; score = model3.evaluate(x_test, y_test, batch_size=32) Prediction12&gt;&gt;&gt; model3.predict(x_test4, batch_size=32)&gt;&gt;&gt; model3.predict_classes(x_test4,batch_size=32) Save/ Reload Models123&gt;&gt;&gt; from keras.models import load_model&gt;&gt;&gt; model3.save('model_file.h5')&gt;&gt;&gt; my_model = load_model('my_model.h5') Model Fine-tuningOptimization Parameters:1234&gt;&gt;&gt; from keras.optimizers import RMSprop&gt;&gt;&gt; opt = RMSprop(lr=0.0001, decay=1e-6)&gt;&gt;&gt; model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) Early Stopping:12345678&gt;&gt;&gt; from keras.callbacks import EarlyStopping&gt;&gt;&gt; early_stopping_monitor = EarlyStopping(patience=2)&gt;&gt;&gt; model3.fit(x_train4, y_train4, batch_size=32, epochs=15, validation_data=(x_test4,y_test4), callbacks=[early_stopping_monitor])","categories":[{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Data-Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Keras","slug":"Keras","permalink":"https://stephen-cheng.github.io/tags/Keras/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"}],"author":"Stephen Cheng"},{"title":"Python for Data Science Cheat Sheet with Scikit-Learn","slug":"Python-for-Data-Science-Cheat-Sheet-with-Scikit-Learn","date":"2019-06-18T20:33:19.000Z","updated":"2023-11-30T19:56:15.077Z","comments":true,"path":"2019/06/18/Python-for-Data-Science-Cheat-Sheet-with-Scikit-Learn/","link":"","permalink":"https://stephen-cheng.github.io/2019/06/18/Python-for-Data-Science-Cheat-Sheet-with-Scikit-Learn/","excerpt":"","text":"&nbsp; Stephen Cheng Intro of Scikit-LearnScikit-learn is an open source Python library that implements a range of machine learning, data preprocessing, cross-validation and visualization algorithms using a unified interface. The whole workflow of data science includes: Loading the data Training and test data Preprocessing ehe data Create your model Model fitting Prediction Evaluate your model’a performance Tune your model Here I give you a basic example for reference. 12345678910111213&gt;&gt;&gt; from sklearn import neighbors, datasets, preprocessing&gt;&gt;&gt; from sklearn.model_selection import train_test_split&gt;&gt;&gt; from sklearn.metrics import accuracy_score&gt;&gt;&gt; iris = datasets.load_iris()&gt;&gt;&gt; X, y = iris.data[:, :2], iris.target&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)&gt;&gt;&gt; scaler = preprocessing.StandardScaler().fit(X_train)&gt;&gt;&gt; X_train = scaler.transform(X_train)&gt;&gt;&gt; X_test = scaler.transform(X_test)&gt;&gt;&gt; knn = neighbors.KNeighborsClassifier(n_neighbors=5)&gt;&gt;&gt; knn.fit(X_train, y_train)&gt;&gt;&gt; y_pred = knn.predict(X_test)&gt;&gt;&gt; accuracy_score(y_test, y_pred) Loading The DataYour data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable. 1234&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; X = np.random.random((10,5))&gt;&gt;&gt; y = np.array(['M','M','F','F','M','F','M','M','F','F','F'])&gt;&gt;&gt; X[X &lt; 0.7] = 0 Training And Test Data12&gt;&gt;&gt; from sklearn.model_selection import train_test_split&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) Preprocessing The DataImputing Missing Values123&gt;&gt;&gt; from sklearn.preprocessing import Imputer&gt;&gt;&gt; imp = Imputer(missing_values=0, strategy='mean', axis=0)&gt;&gt;&gt; imp.fit_transform(X_train) Standardization1234&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler&gt;&gt;&gt; scaler = StandardScaler().fit(X_train)&gt;&gt;&gt; standardized_X = scaler.transform(X_train)&gt;&gt;&gt; standardized_X_test = scaler.transform(X_test) Normalization1234&gt;&gt;&gt; from sklearn.preprocessing import Normalizer&gt;&gt;&gt; scaler = Normalizer().fit(X_train)&gt;&gt;&gt; normalized_X = scaler.transform(X_train)&gt;&gt;&gt; normalized_X_test = scaler.transform(X_test) Binarization123&gt;&gt;&gt; from sklearn.preprocessing import Binarizer&gt;&gt;&gt; binarizer = Binarizer(threshold=0.0).fit(X)&gt;&gt;&gt; binary_X = binarizer.transform(X) Encoding Categorical Features123&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder&gt;&gt;&gt; enc = LabelEncoder()&gt;&gt;&gt; y = enc.fit_transform(y) Generating Polynomial Features123&gt;&gt;&gt; from sklearn.preprocessing import PolynomialFeatures&gt;&gt;&gt; poly = PolynomialFeatures(5)&gt;&gt;&gt; poly.fit_transform(X) Create Your ModelSupervised Learning EstimatorsLinear Regression 12&gt;&gt;&gt; from sklearn.linear_model import LinearRegression&gt;&gt;&gt; lr = LinearRegression(normalize=True) Support Vector Machines (SVM) 12&gt;&gt;&gt; from sklearn.svm import SVC&gt;&gt;&gt; svc = SVC(kernel='linear') Naive Bayes 12&gt;&gt;&gt; from sklearn.naive_bayes import GaussianNB&gt;&gt;&gt; gnb = GaussianNB() KNN 12&gt;&gt;&gt; from sklearn import neighbors&gt;&gt;&gt; knn = neighbors.KNeighborsClassifier(n_neighbors=5) Unsupervised Learning EstimatorsPrincipal Component Analysis (PCA) 12&gt;&gt;&gt; from sklearn.decomposition import PCA&gt;&gt;&gt; pca = PCA(n_components=0.95) K Means 12&gt;&gt;&gt; from sklearn.cluster import KMeans&gt;&gt;&gt; k_means = KMeans(n_clusters=3, random_state=0) Model FittingSupervised learningFit the model to the data. 123&gt;&gt;&gt; lr.fit(X, y)&gt;&gt;&gt; knn.fit(X_train, y_train)&gt;&gt;&gt; svc.fit(X_train, y_train) Unsupervised LearningFit the model to the data.Fit to data, then transform it. 12&gt;&gt;&gt; k_means.fit(X_train)&gt;&gt;&gt; pca_model = pca.fit_transform(X_train) PredictionSupervised EstimatorsPredict labels. Predict labels. Estimate probability of a label. 123&gt;&gt;&gt; y_pred = svc.predict(np.random.random((2,5)))&gt;&gt;&gt; y_pred = lr.predict(X_test)&gt;&gt;&gt; y_pred = knn.predict_proba(X_test) Unsupervised EstimatorsPredict labels in clustering algos. 1&gt;&gt;&gt; y_pred = k_means.predict(X_test) Evaluate Your Model’s PerformanceClassification MetricsAccuracy Score Estimator score method. Metric scoring functions. 123&gt;&gt;&gt; knn.score(X_test, y_test)&gt;&gt;&gt; from sklearn.metrics import accuracy_score&gt;&gt;&gt; accuracy_score(y_test, y_pred) Classification Report Precision, recall, f1-score and support. 12&gt;&gt;&gt; from sklearn.metrics import classification_report&gt;&gt;&gt; print(classification_report(y_test, y_pred)) Confusion Matrix 12&gt;&gt;&gt; from sklearn.metrics import confusion_matrix&gt;&gt;&gt; print(confusion_matrix(y_test, y_pred)) Regression MetricsMean Absolute Error 123&gt;&gt;&gt; from sklearn.metrics import mean_absolute_error&gt;&gt;&gt; y_true = [3, -0.5, 2]&gt;&gt;&gt; mean_absolute_error(y_true, y_pred) Mean Squared Error 12&gt;&gt;&gt; from sklearn.metrics import mean_squared_error&gt;&gt;&gt; mean_squared_error(y_test, y_pred) R² Score 12&gt;&gt;&gt; from sklearn.metrics import r2_score&gt;&gt;&gt; r2_score(y_true, y_pred) Clustering MetricsAdjusted Rand Index 12&gt;&gt;&gt; from sklearn.metrics import adjusted_rand_score&gt;&gt;&gt; adjusted_rand_score(y_true, y_pred) Homogeneity 12&gt;&gt;&gt; from sklearn.metrics import homogeneity_score&gt;&gt;&gt; homogeneity_score(y_true, y_pred) V-measure 12&gt;&gt;&gt; from sklearn.metrics import v_measure_score&gt;&gt;&gt; metrics.v_measure_score(y_true, y_pred) Cross-Validation123&gt;&gt;&gt; from sklearn.cross_validation import cross_val_score&gt;&gt;&gt; print(cross_val_score(knn, X_train, y_train, cv=4))&gt;&gt;&gt; print(cross_val_score(lr, X, y, cv=2)) Tune Your ModelGrid Search123456&gt;&gt;&gt; from sklearn.grid_search import GridSearchCV&gt;&gt;&gt; params = &#123;\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]&#125;&gt;&gt;&gt; grid = GridSearchCV(estimator=knn, param_grid=params)&gt;&gt;&gt; grid.fit(X_train, y_train)&gt;&gt;&gt; print(grid.best_score_)&gt;&gt;&gt; print(grid.best_estimator_.n_neighbors) Randomized Parameter Optimization1234567&gt;&gt;&gt; from sklearn.grid_search import RandomizedSearchCV&gt;&gt;&gt; params = &#123;\"n_neighbors\": range(1,5), \"weights\": [\"uniform\", \"distance\"]&#125;&gt;&gt;&gt; rsearch = RandomizedSearchCV(estimator=knn, param_distributions=params, cv=4, n_iter=8,random_state=5)&gt;&gt;&gt; rsearch.fit(X_train, y_train)&gt;&gt;&gt; print(rsearch.best_score_)","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Data-Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Scikit-Learn","slug":"Scikit-Learn","permalink":"https://stephen-cheng.github.io/tags/Scikit-Learn/"},{"name":"Sklearn","slug":"Sklearn","permalink":"https://stephen-cheng.github.io/tags/Sklearn/"}],"author":"Stephen Cheng"},{"title":"How to Install and Run MongoDB on Mac OS","slug":"Install-MongoDB-on-Mac","date":"2019-03-11T20:33:19.000Z","updated":"2023-11-30T19:56:36.829Z","comments":true,"path":"2019/03/11/Install-MongoDB-on-Mac/","link":"","permalink":"https://stephen-cheng.github.io/2019/03/11/Install-MongoDB-on-Mac/","excerpt":"","text":"&nbsp; Stephen Cheng Intro MongoDB is a document database which belongs to a family of databases called NoSQL - not only SQL. In MongoDB, records are documents which behave a lot like JSON objects in JavaScript. Values in documents can be looked up by their field’s key. Documents can have some fields/keys and not others, which makes Mongo extremely flexible. This is much different than SQL databases like MySQL, where fields correspond to columns in a table and individual records correspond to rows. Install and Run MongoDB with Homebrew Make sure Homebrew already installed on Mac (Homebrew is a package manager for the Mac – it makes installing most open source software). Open the Mac terminal application and type brew update, then type brew install mongodb After MongoDB is downloaded, create a directory to store MongoDB data files, type mkdir -p /data/db Make sure the directory has the right permissions: 12&gt; sudo chown -R `id -un` /data/db&gt; # Enter your psd Run the Mongo daemon by typing mongod in your terminal window. Run the Mongo shell by typing mongo in another terminal window. To exit the Mongo shell run quit(), to stop the Mongo daemon hit ctrl+c Install and Run MongoDB by Downloading it Manually 1) Go to the MongoDB website and download the correct version of MongoDB. 2) After downloading MongoDB, move the gzipped tar file to the folder where you want MongoDB installed by typing commands like these in your terminal: 12&gt; cd Downloads&gt; mv mongodb-macos-x86_64-4.2.2.tgz ~/ 3) Extract MongoDB from the downloaded archive and change the name of the directory to something more concise by following commands: 12&gt; cd ~/ &gt; tar -zxvf mongodb-macos-x86_64-4.2.2.tgz&gt; mv mongodb-macos-x86_64-4.2.2 mongodb 4) Create a directory to store MongoDB data files, type mkdir -p /data/db 5) Make sure the directory has the right permissions: 12&gt; sudo chown -R `id -un` /data/db&gt; # Enter your psd 6) If you can’t create /data/db directory, you can also use other directory to replace it by running command like this: 1~/mongodb/bin/mongod --dbpath ~/mongodb/data then jump to step 8. 7) Run the Mongo daemon by typing ~/mongodb/bin/mongod in your terminal window. 8) Run the Mongo shell by typing ~/mongodb/bin/mongo in another terminal window. 9) To exit the Mongo shell run quit(), to stop the Mongo daemon hit ctrl+c","categories":[{"name":"System","slug":"System","permalink":"https://stephen-cheng.github.io/categories/System/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://stephen-cheng.github.io/tags/MongoDB/"}],"author":"Stephen Cheng"},{"title":"How to Transfer Files & Connect to Jupyter Notebook Between Azure Virtual Machines and Local Systems","slug":"HowtoTransferFiles","date":"2019-01-28T19:02:39.000Z","updated":"2023-11-30T19:56:43.099Z","comments":true,"path":"2019/01/28/HowtoTransferFiles/","link":"","permalink":"https://stephen-cheng.github.io/2019/01/28/HowtoTransferFiles/","excerpt":"","text":"&nbsp; Stephen Cheng IntroRecently, cloud platforms are popular among various companies and conferences. Virtual Machines are one of the main applications provided by cloud platforms. For instance, Microsoft Azure offers Data Science Virtual Machines. Even though we have cloud platforms do us a favour to process hundreds and thousands of data remotely, I do need to upload files or download results from remote server. So how to interact between remote cloud servers and local systems? We’ll take Azure Virtual Machines as a case study. Transfer Files Copy a Local File to a Azure Virtual Machine with the scp Command: 1scp /local/path/file.txt azure_username@azure_host_ip:/remote/directory If SSH on the remote host is listening on a port other than the default 22, then you can specify a port using the -P argument: 1scp -P 1234 /local/path/file.txt azure_username@azure_host_ip:/remote/directory To copy a directory from a local to remote system, we can use the -r option: 1scp -r /local/directory azure_username@azure_host_ip:/remote/directory Copy a Remote File to a Local System using the scp command: 1scp azure_username@azure_host_ip:/remote/file.txt /local/directory Copy a File Between Two Azure Virtual Machines using the scp Command: 1scp azure_username1@azure_host_ip1:/directory/file.txt azure_username2@azure_host_ip2:/directory Connect to Azure Virtual MachineHere, we can use SSH command to connect to the Azure Virtual Machine from local path. 1ssh azure_username@azure_host_ip Connect to Jupyter Notebook applicationHere, we use SSH command to connect to the Jupyter Notebook Application. First, install and start the Jupyter Notebook Application in the Azure Virtual Machines, then open the local terminal and input the following command: 1ssh -L 8000:localhost:8888 azure_username@azure_host_ip Next, entering to the Jupyter Notebook Application using local browser with the url ‘localhost:8000’, and input the Jupyter notebook token from Azure Virtual Machines.","categories":[{"name":"System","slug":"System","permalink":"https://stephen-cheng.github.io/categories/System/"}],"tags":[{"name":"VM","slug":"VM","permalink":"https://stephen-cheng.github.io/tags/VM/"},{"name":"Jupyter","slug":"Jupyter","permalink":"https://stephen-cheng.github.io/tags/Jupyter/"},{"name":"Azure","slug":"Azure","permalink":"https://stephen-cheng.github.io/tags/Azure/"}],"author":"Stephen Cheng"},{"title":"Awesome Programming Skills for Python User","slug":"AwesomeProgramminSkillsforPythonUser","date":"2018-12-24T23:22:38.000Z","updated":"2023-11-30T19:56:57.797Z","comments":true,"path":"2018/12/24/AwesomeProgramminSkillsforPythonUser/","link":"","permalink":"https://stephen-cheng.github.io/2018/12/24/AwesomeProgramminSkillsforPythonUser/","excerpt":"","text":"&nbsp; Stephen Cheng IntroHere are some awesome programming skills shared for Python users. Hopefully it’s useful to you. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126# most frequent element in a lista = [1,2,3,1,2,3,2,2,2,4,5,1]print(max(set(a), key = a.count))# use Counterfrom collections import Countercnt = Counter(a)print(cnt.most_common(3))# check two strings have same charactersfrom collections import Counterstr1 = \"I see him\"str2 = \"him I see\"print(Counter(str1) == Counter(str2))# reverse stringb = 'abcdefghijklmnopqrstuvwxyz'print(b[::-1])for char in reversed(b): print(char)num = 123456789print(int(str(num)[::-1]))# transpose 2d arrayoriginal = [['a','b'], ['1','2'],['A','B']]transposed = zip(*original)print(list(transposed))# call different functions with same argumentsdef product(a,b): return a*bdef add(a,b): return a+bx = Trueprint((product if x else add)(5,7))# a shallow copye = [1,2,3,4,5]d = ed[0] = 10print(d,e)d2 = e[:]d2[0] = 11print(d2,e)# deep copyfrom copy import deepcopyf = [[1,2],[3,4]]f2 = deepcopy(f)f[0] = ['x','y']print(f,f2)# sort a dict by its value with built-in sorted funcg = &#123;'apple':50, 'banana':25, 'orange': 20, 'watermelon':10&#125;print(sorted(g.items(), key = lambda x:x[1]))# use itemgetter instead of a lambdafrom operator import itemgetterprint(sorted(g.items(), key=itemgetter(1)))# sort dict by valueprint(sorted(g, key = g.get))# merge dictd1 = &#123;'x':1&#125;d2 = &#123;'y':2&#125;print(&#123;**d1, **d2&#125;) #python 3.5print(dict(d1.items() | d2.items())) #python 3.5d1.update(d2) #python 3.5 print(d1)# convert list to comma separated stringdata = [1,'re', 3, 'fa', 5]print(','.join(map(str, data)))# find index of min/max elementh = [40, 30, 20, 10, 50]def minIndex(lst): return min(range(len(lst)), key = lst.__getitem__)def maxIndex(lst): return max(range(len(lst)), key = lst.__getitem__)print(minIndex(h))print(maxIndex(h))# remove duplicate items from listi = [6,2,2,3,4,4,4,5]print(list(set(i)))from collections import OrderedDictprint(list(OrderedDict.fromkeys(i).keys()))","categories":[{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/categories/Programming/"}],"tags":[{"name":"Code","slug":"Code","permalink":"https://stephen-cheng.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/tags/Programming/"}],"author":"Stephen Cheng"},{"title":"What Is Bagging and How Does It Work?","slug":"WhatIsBaggingandHowDoesItWork","date":"2018-11-21T18:42:41.000Z","updated":"2023-11-30T19:39:35.175Z","comments":true,"path":"2018/11/21/WhatIsBaggingandHowDoesItWork/","link":"","permalink":"https://stephen-cheng.github.io/2018/11/21/WhatIsBaggingandHowDoesItWork/","excerpt":"","text":"&nbsp; Stephen Cheng IntroBagging is a technique used to reduce the variance of our predictions by combining the result of multiple classifiers modeled on different sub-samples of the same dataset. The following figure will make it clearer. StepsThe steps followed in bagging are: 1) Create Multiple DataSets Sampling is done with replacement on the original data and new datasets are formed. The new data sets can have a fraction of the columns as well as rows, which are generally hyper-parameters in a bagging model. Taking row and column fractions less than 1 helps in making robust models, less prone to overfitting. 2) Build Multiple Classifiers Classifiers are built on each data set. Generally the same classifier is modeled on each dataset and predictions are made. 3) Combine Classifiers The predictions of all the classifiers are combined using a mean, median or mode value depending on the problem at hand. The combined values are generally more robust than a single model. Note that, here the number of models built is not a hyper-parameters. Higher number of models are always better or may give similar performance than lower numbers. It can be theoretically shown that the variance of the combined predictions are reduced to 1/n (n: number of classifiers) of the original variance, under some assumptions.","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Bagging","slug":"Bagging","permalink":"https://stephen-cheng.github.io/tags/Bagging/"},{"name":"Classifier","slug":"Classifier","permalink":"https://stephen-cheng.github.io/tags/Classifier/"}],"author":"Stephen Cheng"},{"title":"What Are Ensemble Methods in Tree Based Modelling?","slug":"WhatAreEnsembleMethodsinTreeBasedModelling","date":"2018-10-10T19:33:00.000Z","updated":"2023-11-30T19:55:12.820Z","comments":true,"path":"2018/10/10/WhatAreEnsembleMethodsinTreeBasedModelling/","link":"","permalink":"https://stephen-cheng.github.io/2018/10/10/WhatAreEnsembleMethodsinTreeBasedModelling/","excerpt":"","text":"&nbsp; Stephen Cheng IntroThe literary meaning of word ‘ensemble’ is group. Ensemble methods involve group of predictive models to achieve a better accuracy and model stability. Ensemble methods are known to impart supreme boost to tree based models. Bias &amp; VarianceLike every other model, a tree based model also suffers from the plague of bias and variance. Bias means, ‘how much on an average are the predicted values different from the actual value.’ Variance means, ‘how different will the predictions of the model be at the same point if different samples are taken from the same population’. You build a small tree and you will get a model with low variance and high bias. How do you manage to balance the trade off between bias and variance ? Normally, as you increase the complexity of your model, you will see a reduction in prediction error due to lower bias in the model. As you continue to make your model more complex, you end up over-fitting your model and your model will start suffering from high variance. A champion model should maintain a balance between these two types of errors. This is known as the trade-off management of bias-variance errors. Ensemble learning is one way to execute this trade off analysis. Some of the commonly used ensemble methods include: Bagging, Boosting and Stacking.","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Ensemble","slug":"Ensemble","permalink":"https://stephen-cheng.github.io/tags/Ensemble/"},{"name":"Bias","slug":"Bias","permalink":"https://stephen-cheng.github.io/tags/Bias/"},{"name":"Variance","slug":"Variance","permalink":"https://stephen-cheng.github.io/tags/Variance/"}],"author":"Stephen Cheng"},{"title":"Decision Trees Implementation in R and Python","slug":"DecisionTreesImplementationinRandPython","date":"2018-08-07T06:58:03.000Z","updated":"2023-11-30T19:56:50.468Z","comments":true,"path":"2018/08/07/DecisionTreesImplementationinRandPython/","link":"","permalink":"https://stephen-cheng.github.io/2018/08/07/DecisionTreesImplementationinRandPython/","excerpt":"","text":"&nbsp; Stephen Cheng IntroFor R users and Python users, decision tree is quite easy to implement. Let’s quickly look at the set of codes which can get you started with this algorithm. For ease of use, I’ve shared standard codes where you’ll need to replace your dataset name and variables to get started. RFor R users, there are multiple packages available to implement decision tree such as ctree, rpart, tree etc. 1234567891011121314&gt; library(rpart)&gt; x &lt;- cbind(x_train,y_train)# grow tree&gt; fit &lt;- rpart(y_train ~ ., data = x,method=\"class\")&gt; summary(fit)#Predict Output&gt; predicted= predict(fit,x_test)&gt; library(rpart)&gt; x &lt;- cbind(x_train,y_train)# grow tree&gt; fit &lt;- rpart(y_train ~ ., data = x,method=\"class\")&gt; summary(fit)#Predict Output&gt; predicted= predict(fit,x_test) In the code above: y_train – represents dependent variable. x_train – represents independent variable x – represents training data. PythonFor Python users, below is the code: 123456789101112#Import necessary libraries like pandas, numpy...from sklearn import tree#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset# Create tree object# for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini model = tree.DecisionTreeClassifier(criterion='gini')# model = tree.DecisionTreeRegressor() for regression# Train the model using the training sets and check scoremodel.fit(X, y)model.score(X, y)#Predict Outputpredicted= model.predict(x_test)","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Tree","slug":"Tree","permalink":"https://stephen-cheng.github.io/tags/Tree/"},{"name":"R","slug":"R","permalink":"https://stephen-cheng.github.io/tags/R/"}],"author":"Stephen Cheng"},{"title":"Are Tree Based Models Better than Linear Models?","slug":"AreTreeBasedModelsBetterThanLinearModels","date":"2018-07-27T16:44:50.000Z","updated":"2023-11-30T19:57:05.376Z","comments":true,"path":"2018/07/27/AreTreeBasedModelsBetterThanLinearModels/","link":"","permalink":"https://stephen-cheng.github.io/2018/07/27/AreTreeBasedModelsBetterThanLinearModels/","excerpt":"","text":"&nbsp; Stephen Cheng Intro“If I can use logistic regression for classification problems and linear regression for regression problems, why is there a need to use trees”? Many of us have this question. And, this is a valid one too. How to choose a proper algorithms?Actually, you can use any algorithm. It is dependent on the type of problem you are solving. Let’s look at some key factors which will help you to decide which algorithm to use: 1) If the relationship between dependent &amp; independent variable is well approximated by a linear model, linear regression will outperform tree based model. 2) If there is a high non-linearity &amp; complex relationship between dependent &amp; independent variables, a tree model will outperform a classical regression method. 3) If you need to build a model which is easy to explain to people, a decision tree model will always do better than a linear model. Decision tree models are even simpler to interpret than linear regression!","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Tree","slug":"Tree","permalink":"https://stephen-cheng.github.io/tags/Tree/"},{"name":"Linear","slug":"Linear","permalink":"https://stephen-cheng.github.io/tags/Linear/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"}],"author":"Stephen Cheng"},{"title":"What Are The Key Parameters of Tree Modelling and How to Avoid Over-fitting in Decision Trees?","slug":"WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees","date":"2018-06-06T14:37:33.000Z","updated":"2023-11-30T19:55:09.076Z","comments":true,"path":"2018/06/06/WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees/","link":"","permalink":"https://stephen-cheng.github.io/2018/06/06/WhatAreTheKeyParametersofTreeModellingandHowtoAvoidOver-fittinginDecisionTrees/","excerpt":"","text":"&nbsp; Stephen Cheng IntroOverfitting is one of the key challenges faced while modeling decision trees. If there is no limit set of a decision tree, it will give you 100% accuracy on training set because in the worse case it will end up making 1 leaf for each observation. Thus, preventing overfitting is pivotal while modeling a decision tree and it can be done in 2 ways: 1) Setting constraints on tree size.2) Tree pruning. Let’s discuss both of these briefly. Setting Constraints on Tree SizeThis can be done by using various parameters which are used to define a tree. First, let‘s look at the general structure of a decision tree. The parameters used for defining a tree are further explained below. The parameters described below are irrespective of tool. It is important to understand the role of parameters used in tree modeling. These parameters are available in R &amp; Python. Minimum samples for a node split 1) Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.2) Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.3) Too high values can lead to under-fitting hence, it should be tuned using CV. Minimum samples for a terminal node (leaf) 1) Defines the minimum samples (or observations) required in a terminal node or leaf.2) Used to control over-fitting similar to min_samples_split.3) Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small. Maximum depth of tree (vertical depth) 1) The maximum depth of a tree.2) Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.3) Should be tuned using CV. Maximum number of terminal nodes 1) The maximum number of terminal nodes or leaves in a tree.2) Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves. Maximum features to consider for split 1) The number of features to consider while searching for a best split. These will be randomly selected.2) As a thumb-rule, square root of the total number of features works great but we should check up to 30-40% of the total number of features.3) Higher values can lead to over-fitting but depends on case to case. Tree PruningAs discussed earlier, the technique of setting constraint is a greedy-approach. In other words, it will check for the best split instantaneously and move forward until one of the specified stopping condition is reached. Let’s consider the following case when you’re driving. There are 2 lanes: 1) A lane with cars moving at 80km/h.2) A lane with trucks moving at 30km/h. At this instant, you are the yellow car and you have 2 choices: 1) Take a left and overtake the other 2 cars quickly.2) Keep moving in the present lane. Let’s analyze these choice. In the former choice, you’ll immediately overtake the car ahead and reach behind the truck and start moving at 30 km/h, looking for an opportunity to move back right. All cars originally behind you move ahead in the meanwhile. This would be the optimum choice if your objective is to maximize the distance covered in next say 10 seconds. In the later choice, you sale through at same speed, cross trucks and then overtake maybe depending on situation ahead. Greedy you! This is exactly the difference between normal decision tree &amp; pruning. A decision tree with constraints won’t see the truck ahead and adopt a greedy approach by taking a left. On the other hand if we use pruning, we in effect look at a few steps ahead and make a choice. How to prune? So we know pruning is better. But how to implement it in decision tree? The idea is simple. 1) We first make the decision tree to a large depth.2) Then we start at the bottom and start removing leaves which are giving us negative returns when compared from the top.3) Suppose a split is giving us a gain of say -10 (loss of 10) and then the next split on that gives us a gain of 20. A simple decision tree will stop at step 1 but in pruning, we will see that the overall gain is +10 and keep both leaves. Note Note that sklearn’s decision tree classifier does not currently support pruning. Advanced packages like xgboost have adopted tree pruning in their implementation. But the library rpart in R, provides a function to prune. Good for R users!","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Tree","slug":"Tree","permalink":"https://stephen-cheng.github.io/tags/Tree/"},{"name":"Overfitting","slug":"Overfitting","permalink":"https://stephen-cheng.github.io/tags/Overfitting/"}],"author":"Stephen Cheng"},{"title":"Merge Sort","slug":"MergeSort","date":"2018-05-19T04:23:47.000Z","updated":"2023-11-30T19:56:27.098Z","comments":true,"path":"2018/05/19/MergeSort/","link":"","permalink":"https://stephen-cheng.github.io/2018/05/19/MergeSort/","excerpt":"","text":"&nbsp; Stephen Cheng IntroIn computer science, merge sort (also commonly spelled mergesort) is an efficient, general-purpose, comparison-based sorting algorithm. Most implementations produce a stable sort, which means that the implementation preserves the input order of equal elements in the sorted output. Mergesort is a divide and conquer algorithm that was invented by John von Neumann in 1945. DefinitionConceptually, a merge sort works as follows: 1) Divide the unsorted list into n sublists, each containing 1 element (a list of 1 element is considered sorted). 2) Repeatedly merge sublists to produce new sorted sublists until there is only 1 sublist remaining. This will be the sorted list. DetailsClass: Sorting algorithmData structure: ArrayWorst-case performance: O(n log n)Best-case performance: O(n log n) typical, O(n) natural variantAverage performance: O(n log n)Worst-case space complexity:&lt;/1b&gt; О(n) total, O(n) auxiliary Figure above, first divide the list into the smallest unit (1 element), then compare each element with the adjacent list to sort and merge the two adjacent lists. Finally all the elements are sorted and merged. CodePython 123456789101112131415from collections import dequedef merge_sort(lst): if len(lst) &lt;= 1: return lst def merge(left, right): merged,left,right = deque(),deque(left),deque(right) while left and right: # deque popleft is also O(1) merged.append(left.popleft() if left[0] &lt;= right[0] else right.popleft()) merged.extend(right if right else left) return list(merged) middle = int(len(lst) // 2) left = merge_sort(lst[:middle]) right = merge_sort(lst[middle:]) return merge(left, right)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Merge","slug":"Merge","permalink":"https://stephen-cheng.github.io/tags/Merge/"},{"name":"Sort","slug":"Sort","permalink":"https://stephen-cheng.github.io/tags/Sort/"}],"author":"Stephen Cheng"},{"title":"Regression Trees vs. Classification Trees","slug":"RegressionTreesvs-ClassificationTrees","date":"2018-05-06T13:52:39.000Z","updated":"2023-11-30T19:56:10.563Z","comments":true,"path":"2018/05/06/RegressionTreesvs-ClassificationTrees/","link":"","permalink":"https://stephen-cheng.github.io/2018/05/06/RegressionTreesvs-ClassificationTrees/","excerpt":"","text":"&nbsp; Stephen Cheng IntroWe all know that the terminal nodes (or leaves) lies at the bottom of the decision tree. This means that decision trees are typically drawn upside down such that leaves are the bottom &amp; roots are the tops (shown below). Both the trees work almost similar to each other, let’s look at the primary differences &amp; similarity between classification and regression trees: 1) Regression trees are used when dependent variable is continuous. Classification trees are used when dependent variable is categorical. 2) In case of regression tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value. 3) In case of classification tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value. 4) Both the trees divide the predictor space (independent variables) into distinct and non-overlapping regions. For the sake of simplicity, you can think of these regions as high dimensional boxes or boxes. 5) Both the trees follow a top-down greedy approach known as recursive binary splitting. We call it as ‘top-down’ because it begins from the top of tree when all the observations are available in a single region and successively splits the predictor space into two new branches down the tree. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree. 6) This splitting process is continued until a user defined stopping criteria is reached. For example: we can tell the algorithm to stop once the number of observations per node becomes less than 50. 7) In both the cases, the splitting process results in fully grown trees until the stopping criteria is reached. But, the fully grown tree is likely to overfit data, leading to poor accuracy on unseen data. This bring ‘pruning’. Pruning is one of the technique used tackle overfitting.","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Regression","slug":"Regression","permalink":"https://stephen-cheng.github.io/tags/Regression/"},{"name":"Classification","slug":"Classification","permalink":"https://stephen-cheng.github.io/tags/Classification/"}],"author":"Stephen Cheng"},{"title":"Levenshtein Distance","slug":"LevenshteinDistance","date":"2018-04-18T22:09:03.000Z","updated":"2023-11-30T19:56:31.976Z","comments":true,"path":"2018/04/18/LevenshteinDistance/","link":"","permalink":"https://stephen-cheng.github.io/2018/04/18/LevenshteinDistance/","excerpt":"","text":"&nbsp; Stephen Cheng IntroLevenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is named after Vladimir Levenshtein, who considered this distance in 1965. Levenshtein distance may also be referred to as edit distance, although that term may also denote a larger family of distance metrics. DefinitionMathematically, the Levenshtein distance between two strings a,b (of length |a| and |b| respectively) is given by lev_a,b(|a|,|b|) where ExampleThe Levenshtein distance between “kitten” and “sitting” is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits: 1) kitten → sitten (substitution of “s” for “k”)2) sitten → sittin (substitution of “i” for “e”)3) sittin → sitting (insertion of “g” at the end) CodePython 12345678910111213141516171819202122232425262728#-*- coding: utf-8 -*-\"\"\"Levenshtein distance for measuring string differenceCreated on Apr. 6th, 2017@author: Stephen\"\"\"import numpy as npclass levenshtein_distance: def le_dis(self, input_x, input_y): xlen = len(input_x) + 1 ylen = len(input_y) + 1 dp = np.zeros(shape=(xlen, ylen), dtype=int) for i in range(0, xlen): dp[i][0] = i for j in range(0, ylen): dp[0][j] = j for i in range(1, xlen): for j in range(1, ylen): if input_x[i - 1] == input_y[j - 1]: dp[i][j] = dp[i - 1][j - 1] else: dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]) return dp[xlen - 1][ylen - 1]if __name__ == '__main__': ld = levenshtein_distance() print(ld.le_dis('abcd', 'abd')) # print out 1 print(ld.le_dis('ace', 'abcd')) # print out 2 print(ld.le_dis('hello world', 'hey word')) # print out 4","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"}],"tags":[{"name":"Levenshtein","slug":"Levenshtein","permalink":"https://stephen-cheng.github.io/tags/Levenshtein/"},{"name":"Distance","slug":"Distance","permalink":"https://stephen-cheng.github.io/tags/Distance/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"}],"author":"Stephen Cheng"},{"title":"What Is A Decision Tree ? How Does It Work ?","slug":"WhatIsADecisionTreeHowDoesItWork","date":"2018-04-15T22:09:03.000Z","updated":"2023-11-30T19:39:47.959Z","comments":true,"path":"2018/04/15/WhatIsADecisionTreeHowDoesItWork/","link":"","permalink":"https://stephen-cheng.github.io/2018/04/15/WhatIsADecisionTreeHowDoesItWork/","excerpt":"","text":"&nbsp; Stephen Cheng IntroDecision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, the population or sample are split into two or more homogeneous sets (or sub-populations) based on most significant splitter differentiator in input variables. ExampleSay we have a sample of 30 students with three variables: Gender (Boy/Girl), Class(IX/X) and Height (5 to 6 ft). 15 out of these 30 play cricket in leisure time. Now, we want to create a model to predict who will play cricket during leisure period? In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three. This is where decision tree helps, it will segregate the students based on all values of three variables and identify the variable, which creates the best homogeneous sets of students (which are heterogeneous to each other). In the snapshot below, you can see that variable Gender is able to identify best homogeneous sets compared to the other two variables. As mentioned above, decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. Now the question which arises is, how does it identify the variable and the split? To do this, decision tree uses various algorithms, which we will shall discuss in the following section. Types of Decision TreesTypes of decision tree are based on the type of target variable we have. It can be of two types: 1) Categorical Variable Decision Tree This type of Decision Tree which has categorical target variable then it called as categorical variable decision tree. E.g., in above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO. 2) Continuous Variable Decision Tree This type of Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree. ExampleLet’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/no). Here we know that income of a customer is a significant variable but insurance company does not have income details for all customers. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, age and various other variables. In this case, we are predicting values for continuous variable. Important TerminologyLet’s look at the basic terminology used with Decision trees: 1) Root Node It represents entire population or sample and this further gets divided into two or more homogeneous sets. 2) Splitting It is a process of dividing a node into two or more sub-nodes. 3) Decision Node When a sub-node splits into further sub-nodes, then it is called decision node. 4) Leaf/Terminal Node Nodes do not split is called Leaf or Terminal node. 5) PruningWhen we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting. 6) Branch/Sub-Tree A sub section of entire tree is called branch or sub-tree. 7) Parent and Child Node A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node. These above are the terms commonly used for decision trees. As we know that every algorithm has advantages and disadvantages, below are the important factors which one should know. Advantages1) Easy to Understand Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Its graphical representation is very intuitive and users can easily relate their hypothesis. 2) Useful in Data Exploration Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. With the help of decision trees, we can create new variables/features that has better power to predict target variable. For example, we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable. 3) Less Data Cleaning Required It requires less data cleaning compared to some other modeling techniques. It is not influenced by outliers and missing values to a fair degree. 4) Data Type Is Not a Constraint It can handle both numerical and categorical variables. 5) Non Parametric Method Decision tree is considered to be a non-parametric method. This means that decision trees have no assumptions about the space distribution and the classifier structure. Disadvantages1) Over Fitting Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning (discussed in detailed below). 2) Not Fit for Continuous Variables While working with continuous numerical variables, decision tree looses information when it categorizes variables in different categories.","categories":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Tree","slug":"Tree","permalink":"https://stephen-cheng.github.io/tags/Tree/"},{"name":"Decision-Tree","slug":"Decision-Tree","permalink":"https://stephen-cheng.github.io/tags/Decision-Tree/"}],"author":"Stephen Cheng"}],"categories":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/categories/SQL/"},{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/categories/Programming/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/categories/Data-Science/"},{"name":"System","slug":"System","permalink":"https://stephen-cheng.github.io/categories/System/"},{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/categories/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/categories/Algorithm/"},{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/categories/Computer-Vision/"},{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/categories/Natural-Language-Processing/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/categories/Deep-Learning/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/categories/Machine-Learning/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://stephen-cheng.github.io/tags/SQL/"},{"name":"Interview","slug":"Interview","permalink":"https://stephen-cheng.github.io/tags/Interview/"},{"name":"Database","slug":"Database","permalink":"https://stephen-cheng.github.io/tags/Database/"},{"name":"Python","slug":"Python","permalink":"https://stephen-cheng.github.io/tags/Python/"},{"name":"Programming","slug":"Programming","permalink":"https://stephen-cheng.github.io/tags/Programming/"},{"name":"Computer Science","slug":"Computer-Science","permalink":"https://stephen-cheng.github.io/tags/Computer-Science/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"},{"name":"Regularization","slug":"Regularization","permalink":"https://stephen-cheng.github.io/tags/Regularization/"},{"name":"Gradient Descent","slug":"Gradient-Descent","permalink":"https://stephen-cheng.github.io/tags/Gradient-Descent/"},{"name":"Optimization Algorithms","slug":"Optimization-Algorithms","permalink":"https://stephen-cheng.github.io/tags/Optimization-Algorithms/"},{"name":"Neural Networks","slug":"Neural-Networks","permalink":"https://stephen-cheng.github.io/tags/Neural-Networks/"},{"name":"Backpropagation","slug":"Backpropagation","permalink":"https://stephen-cheng.github.io/tags/Backpropagation/"},{"name":"DBSCAN","slug":"DBSCAN","permalink":"https://stephen-cheng.github.io/tags/DBSCAN/"},{"name":"Clustering","slug":"Clustering","permalink":"https://stephen-cheng.github.io/tags/Clustering/"},{"name":"Kmeans","slug":"Kmeans","permalink":"https://stephen-cheng.github.io/tags/Kmeans/"},{"name":"Classification","slug":"Classification","permalink":"https://stephen-cheng.github.io/tags/Classification/"},{"name":"Evaluation Metrics","slug":"Evaluation-Metrics","permalink":"https://stephen-cheng.github.io/tags/Evaluation-Metrics/"},{"name":"Cross Validation","slug":"Cross-Validation","permalink":"https://stephen-cheng.github.io/tags/Cross-Validation/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Pipeline","slug":"Pipeline","permalink":"https://stephen-cheng.github.io/tags/Pipeline/"},{"name":"Data Collection","slug":"Data-Collection","permalink":"https://stephen-cheng.github.io/tags/Data-Collection/"},{"name":"R","slug":"R","permalink":"https://stephen-cheng.github.io/tags/R/"},{"name":"Text","slug":"Text","permalink":"https://stephen-cheng.github.io/tags/Text/"},{"name":"Data Visualization","slug":"Data-Visualization","permalink":"https://stephen-cheng.github.io/tags/Data-Visualization/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://stephen-cheng.github.io/tags/ggplot2/"},{"name":"Linux","slug":"Linux","permalink":"https://stephen-cheng.github.io/tags/Linux/"},{"name":"File Systems","slug":"File-Systems","permalink":"https://stephen-cheng.github.io/tags/File-Systems/"},{"name":"Computer Systems","slug":"Computer-Systems","permalink":"https://stephen-cheng.github.io/tags/Computer-Systems/"},{"name":"Virtual Environment","slug":"Virtual-Environment","permalink":"https://stephen-cheng.github.io/tags/Virtual-Environment/"},{"name":"Django","slug":"Django","permalink":"https://stephen-cheng.github.io/tags/Django/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://stephen-cheng.github.io/tags/Algorithm/"},{"name":"Binary Trees","slug":"Binary-Trees","permalink":"https://stephen-cheng.github.io/tags/Binary-Trees/"},{"name":"Hash Set","slug":"Hash-Set","permalink":"https://stephen-cheng.github.io/tags/Hash-Set/"},{"name":"Hash Table","slug":"Hash-Table","permalink":"https://stephen-cheng.github.io/tags/Hash-Table/"},{"name":"Linked List","slug":"Linked-List","permalink":"https://stephen-cheng.github.io/tags/Linked-List/"},{"name":"Sort","slug":"Sort","permalink":"https://stephen-cheng.github.io/tags/Sort/"},{"name":"Quicksort","slug":"Quicksort","permalink":"https://stephen-cheng.github.io/tags/Quicksort/"},{"name":"Classifier","slug":"Classifier","permalink":"https://stephen-cheng.github.io/tags/Classifier/"},{"name":"Estimator","slug":"Estimator","permalink":"https://stephen-cheng.github.io/tags/Estimator/"},{"name":"Data","slug":"Data","permalink":"https://stephen-cheng.github.io/tags/Data/"},{"name":"Bagging Classifier","slug":"Bagging-Classifier","permalink":"https://stephen-cheng.github.io/tags/Bagging-Classifier/"},{"name":"Bootstrap Aggregation","slug":"Bootstrap-Aggregation","permalink":"https://stephen-cheng.github.io/tags/Bootstrap-Aggregation/"},{"name":"Object-Detection","slug":"Object-Detection","permalink":"https://stephen-cheng.github.io/tags/Object-Detection/"},{"name":"Table-Detection","slug":"Table-Detection","permalink":"https://stephen-cheng.github.io/tags/Table-Detection/"},{"name":"Grammatical-Error-Correction","slug":"Grammatical-Error-Correction","permalink":"https://stephen-cheng.github.io/tags/Grammatical-Error-Correction/"},{"name":"BERT","slug":"BERT","permalink":"https://stephen-cheng.github.io/tags/BERT/"},{"name":"Transformers","slug":"Transformers","permalink":"https://stephen-cheng.github.io/tags/Transformers/"},{"name":"Spelling-Correction","slug":"Spelling-Correction","permalink":"https://stephen-cheng.github.io/tags/Spelling-Correction/"},{"name":"Natural-Language-Processing","slug":"Natural-Language-Processing","permalink":"https://stephen-cheng.github.io/tags/Natural-Language-Processing/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://stephen-cheng.github.io/tags/PyTorch/"},{"name":"TenforFlow","slug":"TenforFlow","permalink":"https://stephen-cheng.github.io/tags/TenforFlow/"},{"name":"Pre-trained-Model","slug":"Pre-trained-Model","permalink":"https://stephen-cheng.github.io/tags/Pre-trained-Model/"},{"name":"Hierarchical-Clustering","slug":"Hierarchical-Clustering","permalink":"https://stephen-cheng.github.io/tags/Hierarchical-Clustering/"},{"name":"Silhouette","slug":"Silhouette","permalink":"https://stephen-cheng.github.io/tags/Silhouette/"},{"name":"Computer-Vision","slug":"Computer-Vision","permalink":"https://stephen-cheng.github.io/tags/Computer-Vision/"},{"name":"OCR","slug":"OCR","permalink":"https://stephen-cheng.github.io/tags/OCR/"},{"name":"PyCharm","slug":"PyCharm","permalink":"https://stephen-cheng.github.io/tags/PyCharm/"},{"name":"Shortcuts","slug":"Shortcuts","permalink":"https://stephen-cheng.github.io/tags/Shortcuts/"},{"name":"Data-Science","slug":"Data-Science","permalink":"https://stephen-cheng.github.io/tags/Data-Science/"},{"name":"Keras","slug":"Keras","permalink":"https://stephen-cheng.github.io/tags/Keras/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://stephen-cheng.github.io/tags/Deep-Learning/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://stephen-cheng.github.io/tags/Machine-Learning/"},{"name":"Scikit-Learn","slug":"Scikit-Learn","permalink":"https://stephen-cheng.github.io/tags/Scikit-Learn/"},{"name":"Sklearn","slug":"Sklearn","permalink":"https://stephen-cheng.github.io/tags/Sklearn/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://stephen-cheng.github.io/tags/MongoDB/"},{"name":"VM","slug":"VM","permalink":"https://stephen-cheng.github.io/tags/VM/"},{"name":"Jupyter","slug":"Jupyter","permalink":"https://stephen-cheng.github.io/tags/Jupyter/"},{"name":"Azure","slug":"Azure","permalink":"https://stephen-cheng.github.io/tags/Azure/"},{"name":"Code","slug":"Code","permalink":"https://stephen-cheng.github.io/tags/Code/"},{"name":"Bagging","slug":"Bagging","permalink":"https://stephen-cheng.github.io/tags/Bagging/"},{"name":"Ensemble","slug":"Ensemble","permalink":"https://stephen-cheng.github.io/tags/Ensemble/"},{"name":"Bias","slug":"Bias","permalink":"https://stephen-cheng.github.io/tags/Bias/"},{"name":"Variance","slug":"Variance","permalink":"https://stephen-cheng.github.io/tags/Variance/"},{"name":"Tree","slug":"Tree","permalink":"https://stephen-cheng.github.io/tags/Tree/"},{"name":"Linear","slug":"Linear","permalink":"https://stephen-cheng.github.io/tags/Linear/"},{"name":"Overfitting","slug":"Overfitting","permalink":"https://stephen-cheng.github.io/tags/Overfitting/"},{"name":"Merge","slug":"Merge","permalink":"https://stephen-cheng.github.io/tags/Merge/"},{"name":"Regression","slug":"Regression","permalink":"https://stephen-cheng.github.io/tags/Regression/"},{"name":"Levenshtein","slug":"Levenshtein","permalink":"https://stephen-cheng.github.io/tags/Levenshtein/"},{"name":"Distance","slug":"Distance","permalink":"https://stephen-cheng.github.io/tags/Distance/"},{"name":"Decision-Tree","slug":"Decision-Tree","permalink":"https://stephen-cheng.github.io/tags/Decision-Tree/"}]}