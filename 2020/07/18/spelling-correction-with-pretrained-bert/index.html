<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Spelling Correction with The Pretrained BERT Model | Stephen Cheng</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="&amp;nbsp; Stephen Cheng   Intro BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by">
<meta property="og:type" content="article">
<meta property="og:title" content="Spelling Correction with The Pretrained BERT Model">
<meta property="og:url" content="https://stephen-cheng.github.io/2020/07/18/spelling-correction-with-pretrained-bert/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:description" content="&amp;nbsp; Stephen Cheng   Intro BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png">
<meta property="og:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/1.png">
<meta property="article:published_time" content="2020-07-18T14:47:52.000Z">
<meta property="article:modified_time" content="2023-11-30T19:55:38.898Z">
<meta property="article:author" content="Stephen Cheng">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="Spelling-Correction">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Stephen Cheng</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">AI | Tech</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
          <a class="main-nav-link" href="/">Home</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://stephen-cheng.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spelling-correction-with-pretrained-bert" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/18/spelling-correction-with-pretrained-bert/" class="article-date">
  <time datetime="2020-07-18T14:47:52.000Z" itemprop="datePublished">2020-07-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spelling Correction with The Pretrained BERT Model
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png" alt=""></p>
<p>BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering, Natural Language Inference, and others. BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models.</p>
<p>BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).</p>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><ul>
<li>Import necessary libraris</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pytesseract <span class="keyword">import</span> image_to_string</span><br><span class="line"><span class="keyword">from</span> enchant.checker <span class="keyword">import</span> SpellChecker</span><br><span class="line"><span class="keyword">from</span> difflib <span class="keyword">import</span> SequenceMatcher</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForMaskedLM</span><br></pre></td></tr></table></figure>

<ul>
<li>Process images by using OCR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">imagename = <span class="string">'1.png'</span></span><br><span class="line">pil_img = Image.open(imagename)</span><br><span class="line">text = image_to_string(pil_img)</span><br><span class="line">text_original = str(text)</span><br><span class="line"></span><br><span class="line">print(text)</span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.imshow(np.asarray(pil_img))</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/1.png" alt=""></p>
<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as con@gmer spending</span><br><span class="line">Strengthened, manufacturing activity cont@™ed to rise, and producers</span><br><span class="line">scheduled more investment in plant and equipment.</span><br></pre></td></tr></table></figure>

<ul>
<li>Process text and mask incorrect words</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># text cleanup</span></span><br><span class="line">rep = &#123;<span class="string">'\n'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\\'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\"'</span>: <span class="string">'"'</span>,</span><br><span class="line">       <span class="string">'-'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'"'</span>: <span class="string">' " '</span>,</span><br><span class="line">       <span class="string">','</span>:<span class="string">' , '</span>,</span><br><span class="line">       <span class="string">'.'</span>:<span class="string">' . '</span>,</span><br><span class="line">       <span class="string">'!'</span>:<span class="string">' ! '</span>,</span><br><span class="line">       <span class="string">'?'</span>:<span class="string">' ? '</span>,</span><br><span class="line">       <span class="string">"n't"</span>: <span class="string">" not"</span>,</span><br><span class="line">       <span class="string">"'ll"</span>: <span class="string">" will"</span>,</span><br><span class="line">       <span class="string">'*'</span>:<span class="string">' * '</span>,</span><br><span class="line">       <span class="string">'('</span>: <span class="string">' ( '</span>,</span><br><span class="line">       <span class="string">')'</span>: <span class="string">' ) '</span>,</span><br><span class="line">       <span class="string">"s'"</span>: <span class="string">"s '"</span>&#125;</span><br><span class="line"></span><br><span class="line">rep = dict((re.escape(k), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> rep.items())</span><br><span class="line">pattern = re.compile(<span class="string">"|"</span>.join(rep.keys()))</span><br><span class="line">text = pattern.sub(<span class="keyword">lambda</span> m: rep[re.escape(m.group(<span class="number">0</span>))], text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_personslist</span><span class="params">(text)</span>:</span></span><br><span class="line">    personslist = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> nltk.sent_tokenize(text):</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):</span><br><span class="line">            <span class="keyword">if</span> isinstance(chunk, nltk.tree.Tree) <span class="keyword">and</span> chunk.label() == <span class="string">'PERSON'</span>:</span><br><span class="line">                personslist.insert(<span class="number">0</span>, (chunk.leaves()[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> list(set(personslist))</span><br><span class="line">personslist = get_personslist(text)</span><br><span class="line">ignorewords = personslist + [<span class="string">"!"</span>, <span class="string">","</span>, <span class="string">"."</span>, <span class="string">"\""</span>, <span class="string">"?"</span>, <span class="string">'('</span>, <span class="string">')'</span>, <span class="string">'*'</span>, <span class="string">"''"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to find incorrect words</span></span><br><span class="line">d = SpellChecker(<span class="string">"en_US"</span>)</span><br><span class="line">words = text.split()</span><br><span class="line">incorrectwords = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> <span class="keyword">not</span> d.check(w) <span class="keyword">and</span> w <span class="keyword">not</span> <span class="keyword">in</span> ignorewords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to get suggested replacements</span></span><br><span class="line">suggestedwords = [d.suggest(w) <span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># replace incorrect words with [MASK]</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords:</span><br><span class="line">    text = text.replace(w, <span class="string">'[MASK]'</span>)</span><br><span class="line"></span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as [MASK] spending Strengthened ,  manufacturing activity [MASK] to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

<h3 id="Use-the-pretrained-BERT-model-to-predict-words"><a href="#Use-the-pretrained-BERT-model-to-predict-words" class="headerlink" title="Use the pretrained BERT model to predict words"></a>Use the pretrained BERT model to predict words</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenize text</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">tokenized_text = tokenizer.tokenize(text)</span><br><span class="line">indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)</span><br><span class="line">MASKIDS = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">'[MASK]'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the segments tensors</span></span><br><span class="line">segs = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">"."</span>]</span><br><span class="line">segments_ids = []</span><br><span class="line">prev = <span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> k, s <span class="keyword">in</span> enumerate(segs):</span><br><span class="line">    segments_ids = segments_ids + [k] * (s-prev)</span><br><span class="line">    prev = s</span><br><span class="line">segments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))</span><br><span class="line">segments_tensors = torch.tensor([segments_ids])</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare Torch inputs</span></span><br><span class="line">tokens_tensors = torch.tensor([indexed_tokens])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load pre-trained model</span></span><br><span class="line">model = BertForMaskedLM.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict all tokens</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    predictions = model(tokens_tensors, segments_tensors)</span><br></pre></td></tr></table></figure>

<ul>
<li>Match with proposals from SpellChecker</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_word</span><span class="params">(text_original, predictions, MASKIDS)</span>:</span></span><br><span class="line">    pred_words = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(MASKIDS)):</span><br><span class="line">        preds = torch.topk(predictions[<span class="number">0</span>, MASKIDS[i]], k=<span class="number">50</span>)</span><br><span class="line">        indices = preds.indices.tolist()</span><br><span class="line">        pred_list = tokenizer.convert_ids_to_tokens(indices)</span><br><span class="line">        sugg_list = suggestedwords[i]</span><br><span class="line">        sim_max = <span class="number">0</span></span><br><span class="line">        predicted_token = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> word1 <span class="keyword">in</span> pred_list:</span><br><span class="line">            <span class="keyword">for</span> word2 <span class="keyword">in</span> sugg_list:</span><br><span class="line">                s = SequenceMatcher(<span class="literal">None</span>, word1, word2).ratio()</span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> s &gt; sim_max:</span><br><span class="line">                    sim_max = s</span><br><span class="line">                    predicted_token = word1</span><br><span class="line">        text_original = text_original.replace(<span class="string">'[MASK]'</span>, predicted_token, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> text_original</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text_refined = predict_word(text, predictions, MASKIDS)</span><br><span class="line">print(text_refined)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as consumer spending Strengthened ,  manufacturing activity continued to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://stephen-cheng.github.io/2020/07/18/spelling-correction-with-pretrained-bert/" data-id="clpllv7wk001mt4xv1uk656s5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/08/16/spelling-correction-with-python-spellchecker/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Spelling Correction with Python Spellchecker
        
      </div>
    </a>
  
  
    <a href="/2020/06/19/Spelling-Corrector-from-Scratch/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Spelling Corrector from Scratch</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer-Vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine-Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/System/">System</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azure/" rel="tag">Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bagging/" rel="tag">Bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bias/" rel="tag">Bias</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classification/" rel="tag">Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classifier/" rel="tag">Classifier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code/" rel="tag">Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer-Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/" rel="tag">Data-Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision-Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distance/" rel="tag">Distance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble/" rel="tag">Ensemble</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grammatical-Error-Correction/" rel="tag">Grammatical-Error-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hierarchical-Clustering/" rel="tag">Hierarchical-Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter/" rel="tag">Jupyter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/" rel="tag">Keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Levenshtein/" rel="tag">Levenshtein</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear/" rel="tag">Linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Merge/" rel="tag">Merge</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/" rel="tag">MongoDB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OCR/" rel="tag">OCR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Overfitting/" rel="tag">Overfitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pre-trained-Model/" rel="tag">Pre-trained-Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Programming/" rel="tag">Programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyCharm/" rel="tag">PyCharm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regression/" rel="tag">Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scikit-Learn/" rel="tag">Scikit-Learn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shortcuts/" rel="tag">Shortcuts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Silhouette/" rel="tag">Silhouette</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sklearn/" rel="tag">Sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sort/" rel="tag">Sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spelling-Correction/" rel="tag">Spelling-Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Table-Detection/" rel="tag">Table-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TenforFlow/" rel="tag">TenforFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformers/" rel="tag">Transformers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tree/" rel="tag">Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VM/" rel="tag">VM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Variance/" rel="tag">Variance</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Stephen Cheng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/" class="mobile-nav-link">Home</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>