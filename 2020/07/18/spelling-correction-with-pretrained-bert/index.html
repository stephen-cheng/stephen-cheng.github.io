<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Spelling Correction with The Pretrained BERT Model - Stephen Cheng</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="Personal sharings about Tech & Work.">



<meta name="keywords" content="AI, Tech, CS">



    <meta name="description" content="&amp;nbsp; Stephen Cheng   Intro BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by">
<meta property="og:type" content="article">
<meta property="og:title" content="Spelling Correction with The Pretrained BERT Model">
<meta property="og:url" content="https://stephen-cheng.github.io/2020/07/18/spelling-correction-with-pretrained-bert/index.html">
<meta property="og:site_name" content="Stephen Cheng">
<meta property="og:description" content="&amp;nbsp; Stephen Cheng   Intro BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png">
<meta property="og:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/1.png">
<meta property="article:published_time" content="2020-07-18T14:47:52.000Z">
<meta property="article:modified_time" content="2023-11-30T19:55:38.898Z">
<meta property="article:author" content="Stephen Cheng">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="Spelling-Correction">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 4.2.1"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            Spelling Correction with The Pretrained BERT Model
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-07-18T14:47:52.000Z" itemprop="datePublished">Jul 18 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural-Language-Processing</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            5 minutes read (About 809 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/0.png" alt=""></p>
<p>BERT (Bidirectional Encoder Representations from Transformers) is published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering, Natural Language Inference, and others. BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models.</p>
<p>BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).</p>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><ul>
<li>Import necessary libraris</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pytesseract <span class="keyword">import</span> image_to_string</span><br><span class="line"><span class="keyword">from</span> enchant.checker <span class="keyword">import</span> SpellChecker</span><br><span class="line"><span class="keyword">from</span> difflib <span class="keyword">import</span> SequenceMatcher</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForMaskedLM</span><br></pre></td></tr></table></figure>

<ul>
<li>Process images by using OCR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">imagename = <span class="string">'1.png'</span></span><br><span class="line">pil_img = Image.open(imagename)</span><br><span class="line">text = image_to_string(pil_img)</span><br><span class="line">text_original = str(text)</span><br><span class="line"></span><br><span class="line">print(text)</span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.imshow(np.asarray(pil_img))</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202007/20200718/1.png" alt=""></p>
<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as con@gmer spending</span><br><span class="line">Strengthened, manufacturing activity cont@™ed to rise, and producers</span><br><span class="line">scheduled more investment in plant and equipment.</span><br></pre></td></tr></table></figure>

<ul>
<li>Process text and mask incorrect words</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># text cleanup</span></span><br><span class="line">rep = &#123;<span class="string">'\n'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\\'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'\"'</span>: <span class="string">'"'</span>,</span><br><span class="line">       <span class="string">'-'</span>: <span class="string">' '</span>,</span><br><span class="line">       <span class="string">'"'</span>: <span class="string">' " '</span>,</span><br><span class="line">       <span class="string">','</span>:<span class="string">' , '</span>,</span><br><span class="line">       <span class="string">'.'</span>:<span class="string">' . '</span>,</span><br><span class="line">       <span class="string">'!'</span>:<span class="string">' ! '</span>,</span><br><span class="line">       <span class="string">'?'</span>:<span class="string">' ? '</span>,</span><br><span class="line">       <span class="string">"n't"</span>: <span class="string">" not"</span>,</span><br><span class="line">       <span class="string">"'ll"</span>: <span class="string">" will"</span>,</span><br><span class="line">       <span class="string">'*'</span>:<span class="string">' * '</span>,</span><br><span class="line">       <span class="string">'('</span>: <span class="string">' ( '</span>,</span><br><span class="line">       <span class="string">')'</span>: <span class="string">' ) '</span>,</span><br><span class="line">       <span class="string">"s'"</span>: <span class="string">"s '"</span>&#125;</span><br><span class="line"></span><br><span class="line">rep = dict((re.escape(k), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> rep.items())</span><br><span class="line">pattern = re.compile(<span class="string">"|"</span>.join(rep.keys()))</span><br><span class="line">text = pattern.sub(<span class="keyword">lambda</span> m: rep[re.escape(m.group(<span class="number">0</span>))], text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_personslist</span><span class="params">(text)</span>:</span></span><br><span class="line">    personslist = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> nltk.sent_tokenize(text):</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):</span><br><span class="line">            <span class="keyword">if</span> isinstance(chunk, nltk.tree.Tree) <span class="keyword">and</span> chunk.label() == <span class="string">'PERSON'</span>:</span><br><span class="line">                personslist.insert(<span class="number">0</span>, (chunk.leaves()[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> list(set(personslist))</span><br><span class="line">personslist = get_personslist(text)</span><br><span class="line">ignorewords = personslist + [<span class="string">"!"</span>, <span class="string">","</span>, <span class="string">"."</span>, <span class="string">"\""</span>, <span class="string">"?"</span>, <span class="string">'('</span>, <span class="string">')'</span>, <span class="string">'*'</span>, <span class="string">"''"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to find incorrect words</span></span><br><span class="line">d = SpellChecker(<span class="string">"en_US"</span>)</span><br><span class="line">words = text.split()</span><br><span class="line">incorrectwords = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> <span class="keyword">not</span> d.check(w) <span class="keyword">and</span> w <span class="keyword">not</span> <span class="keyword">in</span> ignorewords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># use SpellChecker to get suggested replacements</span></span><br><span class="line">suggestedwords = [d.suggest(w) <span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords]</span><br><span class="line"></span><br><span class="line"><span class="comment"># replace incorrect words with [MASK]</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> incorrectwords:</span><br><span class="line">    text = text.replace(w, <span class="string">'[MASK]'</span>)</span><br><span class="line"></span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as [MASK] spending Strengthened ,  manufacturing activity [MASK] to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

<h3 id="Use-the-pretrained-BERT-model-to-predict-words"><a href="#Use-the-pretrained-BERT-model-to-predict-words" class="headerlink" title="Use the pretrained BERT model to predict words"></a>Use the pretrained BERT model to predict words</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenize text</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">tokenized_text = tokenizer.tokenize(text)</span><br><span class="line">indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)</span><br><span class="line">MASKIDS = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">'[MASK]'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the segments tensors</span></span><br><span class="line">segs = [i <span class="keyword">for</span> i, e <span class="keyword">in</span> enumerate(tokenized_text) <span class="keyword">if</span> e == <span class="string">"."</span>]</span><br><span class="line">segments_ids = []</span><br><span class="line">prev = <span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> k, s <span class="keyword">in</span> enumerate(segs):</span><br><span class="line">    segments_ids = segments_ids + [k] * (s-prev)</span><br><span class="line">    prev = s</span><br><span class="line">segments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))</span><br><span class="line">segments_tensors = torch.tensor([segments_ids])</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare Torch inputs</span></span><br><span class="line">tokens_tensors = torch.tensor([indexed_tokens])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load pre-trained model</span></span><br><span class="line">model = BertForMaskedLM.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict all tokens</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    predictions = model(tokens_tensors, segments_tensors)</span><br></pre></td></tr></table></figure>

<ul>
<li>Match with proposals from SpellChecker</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_word</span><span class="params">(text_original, predictions, MASKIDS)</span>:</span></span><br><span class="line">    pred_words = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(MASKIDS)):</span><br><span class="line">        preds = torch.topk(predictions[<span class="number">0</span>, MASKIDS[i]], k=<span class="number">50</span>)</span><br><span class="line">        indices = preds.indices.tolist()</span><br><span class="line">        pred_list = tokenizer.convert_ids_to_tokens(indices)</span><br><span class="line">        sugg_list = suggestedwords[i]</span><br><span class="line">        sim_max = <span class="number">0</span></span><br><span class="line">        predicted_token = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> word1 <span class="keyword">in</span> pred_list:</span><br><span class="line">            <span class="keyword">for</span> word2 <span class="keyword">in</span> sugg_list:</span><br><span class="line">                s = SequenceMatcher(<span class="literal">None</span>, word1, word2).ratio()</span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> s &gt; sim_max:</span><br><span class="line">                    sim_max = s</span><br><span class="line">                    predicted_token = word1</span><br><span class="line">        text_original = text_original.replace(<span class="string">'[MASK]'</span>, predicted_token, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> text_original</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text_refined = predict_word(text, predictions, MASKIDS)</span><br><span class="line">print(text_refined)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">national economy gained momentum in recent weeks as consumer spending Strengthened ,  manufacturing activity continued to rise ,  and producers  scheduled more investment in plant and equipment .</span><br></pre></td></tr></table></figure>

    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/BERT/">#BERT</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/Spelling-Correction/">#Spelling-Correction</a></span>
    
    </div>
    
    
    <div class="columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2020/08/16/spelling-correction-with-python-spellchecker/">Spelling Correction with Python Spellchecker</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2020/06/19/Spelling-Corrector-from-Scratch/">Spelling Corrector from Scratch</a>
            
        </span>
    </div>
    
</article>


<div class="sharebox">
    
<div class="notification is-danger">
    You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.
</div>

</div>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<div id="disqus_thread">
    
    <div class="notification is-danger">
        You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.
    </div>
    
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</div>
</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 Stephen Cheng&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/stephen-cheng" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery > p > .gallery-item').unwrap();
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>