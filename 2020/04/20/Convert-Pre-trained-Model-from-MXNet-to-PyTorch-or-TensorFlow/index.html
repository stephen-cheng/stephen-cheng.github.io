<!doctype html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;center&gt;Stephen Cheng&lt;/center&gt;


&lt;h3 id=&#34;Intro&#34;&gt;&lt;a href=&#34;#Intro&#34; class=&#34;headerlink&#34; title=&#34;Intro&#34;&gt;&lt;/a&gt;Intro&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/steven-cheng-com/images/mas">
  <meta name="viewport" content="width=device-width, height=device-height, initial-scale=1.0, user-scalable=yes">
  <title>Convert Pre-trained Model from MXNet to PyTorch or TensorFlow | Stephen Cheng</title>

  <link rel="stylesheet" id="chosen-theme" href="https://rawgit.com/fiatjaf/classless/master/themes/plain/theme.css">
  <script>
let link = document.getElementById('chosen-theme')
let widget = document.createElement('div')
widget.style.position = 'absolute'
widget.style.right = '5px'
widget.style.top = '2px'
widget.style.background = 'beige'
widget.style.color = '#444'
widget.style.zIndex = 99
widget.style.padding = '4px 8px'
widget.innerHTML = `
<label>
  <p>No theme was set on <code>theme_config</code>.<br>
     Choose a theme from the list to experiment with it:</p>
  <select></select>
</label>
`
fetch('https://api.github.com/repos/fiatjaf/classless/contents/themes')
  .then(r => r.json())
  .then(files => {
    document.body.appendChild(widget)
    let select = document.querySelector('select')
    files
      .filter(f => f.type === 'dir')
      .forEach(f => {
        let option = document.createElement('option')
        option.value = f.name
        option.innerHTML = f.name
        select.appendChild(option)
      })
    let options = Array.from(select.querySelectorAll('option'))
    let chosen = options[parseInt(Math.random() * options.length)]
    chosen.selected = true
    link.href = link.href.replace(/themes\/[^\/]+/, `themes/${chosen.value}`)
    select.addEventListener('change', e => {
      let chosen = e.target.value
      link.href = link.href.replace(/themes\/[^\/]+/, `themes/${chosen}`)
    })
  })
  .catch(console.log)
  </script>

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <header role="banner">
      <a href="/">
        
          <img src="https://picsum.photos/640/480">
        
      </a>  
    <h1>
      <a href="/">Stephen Cheng</a>
    </h1>
    <aside>
      <p></p>
    </aside>
  </header>
  
  <main>
    <article>
  <header>
  
  <h1><a href="https://stephen-cheng.github.io/2020/04/20/Convert-Pre-trained-Model-from-MXNet-to-PyTorch-or-TensorFlow/">Convert Pre-trained Model from MXNet to PyTorch or TensorFlow</a></h1>
  <aside>
    
    <time datetime="202020-04-20">
      April 20th 2020
    </time>
    
    <ul>
    
      <li><a href="/tags/PyTorch/">PyTorch</a></li>
    
      <li><a href="/tags/TenforFlow/">TenforFlow</a></li>
    
      <li><a href="/tags/Pre-trained-Model/">Pre-trained-Model</a></li>
    
    </ul>
  </aside>
</header>

  <div><p>&nbsp;</p>
<center>Stephen Cheng</center>


<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/0.png" alt=""></p>
<p>Currently there are many available deep learning frameworks for researchers and engineers to implement their desired deep models. Sometimes, when you find a fantastic GitHub repository which share a pre-trained model on a framework which you are not familiar with. For example, you are an expert PyTorch deep learning code developer, meanwhile you find a great code with its pre-trained model on MXNet; and you want to modify this model according to your needs. Thus, deep learning model conversion tools are extremely needed. As each framework has its own structure, converting a model between two different frameworks requires a great knowledge of both of them. However, There are many fantastic model conversion tools such as <a href="https://onnx.ai/" target="_blank" rel="noopener">ONNX</a>, <a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a>, and etc. for converting and visualizing deep models between a wide collection of frameworks.  </p>
<h3 id="Model-Convertors"><a href="#Model-Convertors" class="headerlink" title="Model Convertors"></a>Model Convertors</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/1.jpg" alt=""></p>
<ul>
<li>ONNX</li>
</ul>
<p><a href="http://onnx.ai/" target="_blank" rel="noopener">ONNX</a> is an effort to unify converters for neural networks in order to bring some sanity to the NN world. Released by Facebook and Microsoft.</p>
<ul>
<li>MMdnn</li>
</ul>
<p><a href="https://github.com/Microsoft/MMdnn" target="_blank" rel="noopener">MMdnn</a> (Model Management Deep Neural Network) is supported by Microsoft, By using MMdnn, one can convert each model from the origin framework to a standard Intermediate Representation (IR), and then convert the IR format to the target framework structure. It can convert models between CaffeEmit, CNTK, CoreML, Keras, MXNet, ONNX, PyTorch and TensorFlow.</p>
<ul>
<li>PyTorch convertor  </li>
</ul>
<p><a href="https://github.com/ruotianluo/pytorch-resnet" target="_blank" rel="noopener">PyTorch convertor</a> can convert models to PyTorch model.</p>
<ul>
<li>TensorFlow convertor  </li>
</ul>
<p><a href="https://github.com/goranrauker/convert-to-tensorflow" target="_blank" rel="noopener">TensorFlow convertor</a> can convert models to TensorFlow model.</p>
<ul>
<li>Keras convertor  </li>
</ul>
<p><a href="https://github.com/qxcv/caffe2keras" target="_blank" rel="noopener">Keras convertor</a> can convert models to Keras model.</p>
<ul>
<li>MXNet convertor</li>
</ul>
<p><a href="https://github.com/nicklhy/ResNet_caffe2mxnet" target="_blank" rel="noopener">MXNet convertor</a> can convert models to MXNet model.</p>
<ul>
<li>Caffe convertor</li>
</ul>
<p><a href="https://github.com/longcw/pytorch2caffe" target="_blank" rel="noopener">Caffe convertor</a> can convert models to Caffe model.</p>
<ul>
<li>Caffe2 convertor</li>
</ul>
<p><a href="https://caffe2.ai/docs/caffe-migration.html#caffe-to-caffe2" target="_blank" rel="noopener">Caffe2 convertor</a> can convert models to Caffe2 model.</p>
<ul>
<li>CNTK convertor</li>
</ul>
<p><a href="https://github.com/Microsoft/CNTK/tree/master/bindings/python/cntk/contrib/crosstalkcaffe" target="_blank" rel="noopener">CNTK convertor</a> can convert models to CNTK model.</p>
<ul>
<li>Theano/Lasagne convertor</li>
</ul>
<p><a href="https://github.com/an-kumar/caffe-theano-conversion" target="_blank" rel="noopener">Theano/Lasagne convertor</a> can convert models to Theano/Lasagne model.</p>
<ul>
<li>Darknet convertor  </li>
</ul>
<p><a href="https://github.com/marvis/pytorch-caffe-darknet-convert" target="_blank" rel="noopener">Darknet convertor</a> can convert models to Darknet model.</p>
<ul>
<li>Torch convertor  </li>
</ul>
<p><a href="https://github.com/kmatzen/googlenet-caffe2torch" target="_blank" rel="noopener">Torch convertor</a> can convert models to Torch model.</p>
<ul>
<li>Neon convertor  </li>
</ul>
<p><a href="https://github.com/NervanaSystems/caffe2neon" target="_blank" rel="noopener">Neon convertor</a> can convert models to Neon model.</p>
<ul>
<li>CoreML convertor</li>
</ul>
<p><a href="https://developer.apple.com/documentation/coreml" target="_blank" rel="noopener">CoreML convertor</a> can convert models to coreML model.</p>
<ul>
<li>Paddle convertor  </li>
</ul>
<p><a href="https://github.com/PaddlePaddle/X2Paddle" target="_blank" rel="noopener">Paddle convertor</a> can convert models to Paddle model.</p>
<ul>
<li>Chainer convertor  </li>
</ul>
<p>Chainer convertor can convert models to Chainer model.</p>
<h3 id="A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch"><a href="#A-Demo-of-Model-Convertion-from-MXNet-to-PyTorch" class="headerlink" title="A Demo of Model Convertion from MXNet to PyTorch"></a>A Demo of Model Convertion from MXNet to PyTorch</h3><p><img src="https://raw.githubusercontent.com/steven-cheng-com/images/master/blog/2020/202004/20200420/2.png" alt=""></p>
<p>Here is an appropriate example to convert the Full ImageNet pre-trained model from MXNet to PyTorch via MMdnn convertor. ImageNet is an image database organized according to the WordNet hierarchy, in which each node of the hierarchy is depicted by hundreds and thousands of images. Since 2010, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a competition where research teams evaluate their algorithms on the given data set, and compete to achieve higher accuracy on several visual recognition tasks. A common reason to train a network on ImageNet data is to use it for transfer learning (including feature extraction or fine-tuning other models). Having a pre-trained model which is trained on such a huge training data set (i.e., full ImageNet), would be a really valuable network. It can speed up the convergence early in the training phase, and also improves the target task accuracy in some scenarios.</p>
<ul>
<li>Prerequisites:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade mmdnn</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install --upgrade torch torchvision</span><br></pre></td></tr></table></figure>

<ul>
<li>Download pre-trained models:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_base_model_url = <span class="string">'http://data.mxnet.io/models/'</span></span><br><span class="line">_default_model_info = &#123;</span><br><span class="line">    <span class="string">'imagenet11k-resnet-152'</span>: &#123;<span class="string">'symbol'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-symbol.json'</span>,</span><br><span class="line">                             <span class="string">'params'</span>:_base_model_url+<span class="string">'imagenet-11k/resnet-152/resnet-152-0000.params'</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_file</span><span class="params">(url, local_fname=None, force_write=False)</span>:</span></span><br><span class="line">    <span class="comment"># requests is not default installed</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="keyword">if</span> local_fname <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        local_fname = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> force_write <span class="keyword">and</span> os.path.exists(local_fname):</span><br><span class="line">        <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line">    dir_name = os.path.dirname(local_fname)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dir_name != <span class="string">""</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_name):</span><br><span class="line">            <span class="keyword">try</span>:  <span class="comment"># try to create the directory if it doesn't exists</span></span><br><span class="line">                os.makedirs(dir_name)</span><br><span class="line">            <span class="keyword">except</span> OSError <span class="keyword">as</span> exc:</span><br><span class="line">                <span class="keyword">if</span> exc.errno != errno.EEXIST:</span><br><span class="line">                    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    r = requests.get(url, stream=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">assert</span> r.status_code == <span class="number">200</span>, <span class="string">"failed to open %s"</span> % url</span><br><span class="line">    <span class="keyword">with</span> open(local_fname, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size=<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">if</span> chunk:  <span class="comment"># filter out keep-alive new chunks</span></span><br><span class="line">                f.write(chunk)</span><br><span class="line">    <span class="keyword">return</span> local_fname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_model</span><span class="params">(model_name, dst_dir=<span class="string">'./'</span>, meta_info=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> meta_info <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        meta_info = _default_model_info</span><br><span class="line">    meta_info = dict(meta_info)</span><br><span class="line">    <span class="keyword">if</span> model_name <span class="keyword">not</span> <span class="keyword">in</span> meta_info:</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">None</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_dir):</span><br><span class="line">        os.mkdir(dst_dir)</span><br><span class="line">    meta = dict(meta_info[model_name])</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'symbol'</span> <span class="keyword">in</span> meta, <span class="string">"missing symbol url"</span></span><br><span class="line">    model_name = os.path.join(dst_dir, model_name)</span><br><span class="line">    download_file(meta[<span class="string">'symbol'</span>], model_name+<span class="string">'-symbol.json'</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'params'</span> <span class="keyword">in</span> meta, <span class="string">"mssing parameter file url"</span></span><br><span class="line">    download_file(meta[<span class="string">'params'</span>], model_name+<span class="string">'-0000.params'</span>)</span><br><span class="line">    <span class="keyword">return</span> (model_name, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># ***** Download synset (i.e., Synonym Set):</span></span><br><span class="line">    synset_url = <span class="string">'http://data.mxnet.io.s3-website-us-west-1.amazonaws.com/models/imagenet-11k/synset.txt'</span></span><br><span class="line">    download_file(synset_url, <span class="string">'synset.txt'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ***** Download Model:</span></span><br><span class="line">    download_model(<span class="string">'imagenet11k-resnet-152'</span>, dst_dir=<span class="string">'./'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>Converting Full ImageNet Pre-trained Model from MXNet to PyTorch:</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.convertToIR -f mxnet -n imagenet11k-resnet-152-symbol.json -w imagenet11k-resnet-152-0000.params -d resnet152 --inputShape 3,224,224</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion._script.IRToCode -f pytorch --IRModelPath resnet152.pb --dstModelPath kit_imagenet.py --IRWeightPath resnet152.npy -dw kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m mmdnn.conversion.examples.pytorch.imagenet_test --dump resnet152Full.pth -n kit_imagenet.py -w kit_pytorch.npy</span><br></pre></td></tr></table></figure>

<ul>
<li>Testing the Converted Model:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.keras.api.keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ************** Parameters:</span></span><br><span class="line">num_predictions = <span class="number">5</span>  <span class="comment"># Top-k Results</span></span><br><span class="line">model_address = <span class="string">'resnet152Full.pth'</span>  <span class="comment"># for loading models</span></span><br><span class="line">lexicon_address = <span class="string">'synset.txt'</span></span><br><span class="line">test_image_address = <span class="string">'seagull.jpg'</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Converted Model:</span></span><br><span class="line">model = torch.load(model_address).to(device)</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read Input Image and Apply Pre-process:</span></span><br><span class="line">img = image.load_img(test_image_address, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x[..., ::<span class="number">-1</span>]  <span class="comment"># transform image from RGB to BGR</span></span><br><span class="line">x = np.transpose(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">x = np.expand_dims(x, <span class="number">0</span>).copy()</span><br><span class="line">x = torch.from_numpy(x)</span><br><span class="line">x = x.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Full-ImageNet Dictionary (i.e., lexicon):</span></span><br><span class="line"><span class="keyword">with</span> open(lexicon_address, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    labels = [l.rstrip() <span class="keyword">for</span> l <span class="keyword">in</span> f]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make prediction (forward pass):</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(x)</span><br><span class="line">max, argmax = output.data.squeeze().max(<span class="number">0</span>)</span><br><span class="line">class_id = argmax.item()</span><br><span class="line">class_name = labels[class_id]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the top-5 Results:</span></span><br><span class="line">h_x = output.data.squeeze()</span><br><span class="line">probs, idx = h_x.sort(<span class="number">0</span>, <span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'Top-5 Results: '</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_predictions):</span><br><span class="line">    print(<span class="string">'&#123;:.2f&#125;% -&gt; &#123;&#125;'</span>.format(probs[i] * <span class="number">100.0</span>, labels[idx[i]]))</span><br><span class="line">str_final_label = <span class="string">'The Image is a '</span> + class_name[<span class="number">10</span>:] + <span class="string">'.'</span></span><br><span class="line">print(str_final_label)</span><br></pre></td></tr></table></figure>
</div>
</article>

  </main>
  <aside>
    <p>This is an `aside`, a useful place to put information of any kind: metadata about the site author (with or without pictures), brief information about the purposes of the site, a static collection of external links or anything else.</p>
<p>For some Classless themes pictures and data about the author may suit better in the `cover` and `description` site attributes (see `config.toml`), but most of the times that kind of information will fit here better.</p>

  </aside>
  <footer role="contentinfo">
    <p>A default site footer. If you don't know what to place here maybe you should just write your name plus the current year?</p>
<p>If you want to have a sitemap, a contact form or other complex stuff, most Classless themes will also handle it nicely. Or you can take a look at the <code>aside.html</code> partial.</p>

  </footer>
</body>
